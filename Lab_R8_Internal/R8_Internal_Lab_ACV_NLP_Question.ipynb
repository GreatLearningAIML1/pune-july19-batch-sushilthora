{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R8_Internal_Lab_ACV_NLP_Question.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOVYOb4nDYea",
        "colab_type": "code",
        "outputId": "05fdec14-12e9-4391-a673-7410465e059a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7kxwViglXkv",
        "colab_type": "text"
      },
      "source": [
        "# CV and Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeYGSjUKll8U",
        "colab_type": "text"
      },
      "source": [
        "Q1. Import tensorflow (2.x Mandatory)\n",
        "\n",
        "*   Import other required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or2c_abbl8rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGrQe1WUl1SZ",
        "colab_type": "text"
      },
      "source": [
        "Q2. Load CIFAR10 dataset from keras and split into train and test\n",
        "*    Identify shape of x_train and y_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIA_FBhPminY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainX, trainY), (testX, testY) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBsGsOdeTttT",
        "colab_type": "code",
        "outputId": "43b148d1-30e6-4e0a-9442-5a4324966b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb7_ZSJlHhDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 20\n",
        "num_classes = 10\n",
        "model_name = 'keras_cifar10_trained_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPQswTTmhOrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrk2ohBxmmTx",
        "colab_type": "text"
      },
      "source": [
        "Q3.\n",
        "\n",
        "*   Transform x_train and x_test on scale of 0-1\n",
        "*   Transform y_train and y_test to categories\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gFXxAJe41Pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = trainX.astype('float32')\n",
        "testX = testX.astype('float32')\n",
        "trainX /= 255\n",
        "testX /= 255\n",
        "y_train = to_categorical(trainY, num_classes=num_classes)\n",
        "y_test = to_categorical(testY, num_classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP5j5MhDzuYc",
        "colab_type": "text"
      },
      "source": [
        "Q4. Import necessary packages required for Model building\n",
        "*   Conv2D, Dense, Flatten, Dropout, MaxPooling2D etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSgCiFid5eb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, Reshape, MaxPool2D, Flatten, Dense, Dropout,Activation, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQBgmSJdz1fq",
        "colab_type": "text"
      },
      "source": [
        "Q5. Prepare a CNN\n",
        " \n",
        "*   Which will include above layers\n",
        "*   Freely create your own Architecture and Arguments\n",
        "*   Print Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IXruOry648i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=trainX.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-xhyA2-iQ0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98nHNv7oL71N",
        "colab_type": "code",
        "outputId": "ac736ed3-4d4c-403c-fd9e-2ae266dc4b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 554,794\n",
            "Trainable params: 554,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93XJL60wIKCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        fill_mode='nearest',\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(trainX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyZhZciC0qvw",
        "colab_type": "text"
      },
      "source": [
        "Q6. Train the CNN\n",
        "\n",
        "*   Compile the model\n",
        "*   Fit the model (10 epochs, 32 batch size)\n",
        "*   Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA5oFggaL1ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_checkpoint=tf.keras.callbacks.ModelCheckpoint('flowers_cnn.h5', save_best_only=True, monitor='val_acc', \n",
        "                                                    mode='max', \n",
        "                                                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApU5xo7h6rxL",
        "colab_type": "code",
        "outputId": "2e9a9bf3-c590-49a1-a49d-7b50665576ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model.fit(datagen.flow(trainX, y_train,\n",
        "            batch_size=batch_size),\n",
        "            epochs=epochs,\n",
        "            validation_data=(testX, y_test),\n",
        "            workers=4,\n",
        "            callbacks = [model_checkpoint])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 1563 steps, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.4076 - accuracy: 0.4869WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.4074 - accuracy: 0.4869 - val_loss: 1.2820 - val_accuracy: 0.5308\n",
            "Epoch 2/20\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 1.3475 - accuracy: 0.5139WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 34s 22ms/step - loss: 1.3473 - accuracy: 0.5140 - val_loss: 1.2370 - val_accuracy: 0.5459\n",
            "Epoch 3/20\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.3060 - accuracy: 0.5320WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.3059 - accuracy: 0.5321 - val_loss: 1.2570 - val_accuracy: 0.5523\n",
            "Epoch 4/20\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 1.2684 - accuracy: 0.5458WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.2685 - accuracy: 0.5458 - val_loss: 1.2525 - val_accuracy: 0.5524\n",
            "Epoch 5/20\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 1.2434 - accuracy: 0.5541WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.2430 - accuracy: 0.5542 - val_loss: 1.1306 - val_accuracy: 0.5917\n",
            "Epoch 6/20\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 1.2193 - accuracy: 0.5662WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.2194 - accuracy: 0.5662 - val_loss: 1.1416 - val_accuracy: 0.5897\n",
            "Epoch 7/20\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 1.1965 - accuracy: 0.5747WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.1963 - accuracy: 0.5747 - val_loss: 1.0663 - val_accuracy: 0.6190\n",
            "Epoch 8/20\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 1.1773 - accuracy: 0.5830WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 35s 22ms/step - loss: 1.1774 - accuracy: 0.5829 - val_loss: 1.1224 - val_accuracy: 0.6012\n",
            "Epoch 9/20\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 1.1722 - accuracy: 0.5853WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.1723 - accuracy: 0.5853 - val_loss: 1.0787 - val_accuracy: 0.6146\n",
            "Epoch 10/20\n",
            "1558/1563 [============================>.] - ETA: 0s - loss: 1.1616 - accuracy: 0.5865WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.1616 - accuracy: 0.5864 - val_loss: 1.1677 - val_accuracy: 0.5881\n",
            "Epoch 11/20\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 1.1450 - accuracy: 0.5956WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.1454 - accuracy: 0.5955 - val_loss: 1.0756 - val_accuracy: 0.6205\n",
            "Epoch 12/20\n",
            "1558/1563 [============================>.] - ETA: 0s - loss: 1.1356 - accuracy: 0.5974WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.1350 - accuracy: 0.5976 - val_loss: 1.0326 - val_accuracy: 0.6289\n",
            "Epoch 13/20\n",
            "1560/1563 [============================>.] - ETA: 0s - loss: 1.1278 - accuracy: 0.6007WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.1277 - accuracy: 0.6007 - val_loss: 1.0651 - val_accuracy: 0.6221\n",
            "Epoch 14/20\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 1.1161 - accuracy: 0.6072WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.1159 - accuracy: 0.6073 - val_loss: 1.0379 - val_accuracy: 0.6254\n",
            "Epoch 15/20\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.1071 - accuracy: 0.6088WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.1071 - accuracy: 0.6089 - val_loss: 1.0335 - val_accuracy: 0.6357\n",
            "Epoch 16/20\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.1083 - accuracy: 0.6107WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.1083 - accuracy: 0.6107 - val_loss: 1.1138 - val_accuracy: 0.6056\n",
            "Epoch 17/20\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 1.0910 - accuracy: 0.6161WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.0909 - accuracy: 0.6162 - val_loss: 1.0160 - val_accuracy: 0.6383\n",
            "Epoch 18/20\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 1.0938 - accuracy: 0.6159WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.0940 - accuracy: 0.6159 - val_loss: 0.9566 - val_accuracy: 0.6551\n",
            "Epoch 19/20\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.0822 - accuracy: 0.6216WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.0821 - accuracy: 0.6216 - val_loss: 1.0109 - val_accuracy: 0.6361\n",
            "Epoch 20/20\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.0798 - accuracy: 0.6228WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.0799 - accuracy: 0.6227 - val_loss: 0.9492 - val_accuracy: 0.6625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f71285a6a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP9bJnYAOQ2c",
        "colab_type": "code",
        "outputId": "4e4e1d8a-f19b-49e5-f677-a1a0a63775a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvxgBnGI4d4E",
        "colab_type": "code",
        "outputId": "ff53bab1-d135-4f7d-934d-8dae4beb071e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(model.predict_classes(testX), testY))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.73      0.71       943\n",
            "           1       0.86      0.83      0.85      1032\n",
            "           2       0.40      0.66      0.50       611\n",
            "           3       0.37      0.43      0.40       879\n",
            "           4       0.64      0.59      0.61      1088\n",
            "           5       0.40      0.73      0.52       543\n",
            "           6       0.87      0.55      0.67      1570\n",
            "           7       0.70      0.70      0.70       995\n",
            "           8       0.83      0.73      0.78      1134\n",
            "           9       0.87      0.72      0.79      1205\n",
            "\n",
            "    accuracy                           0.66     10000\n",
            "   macro avg       0.66      0.67      0.65     10000\n",
            "weighted avg       0.71      0.66      0.67     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu_Gno-z11dP",
        "colab_type": "text"
      },
      "source": [
        "Q7. Import packages required for VGG16\n",
        "\n",
        "*   `tf.keras.application`\n",
        "> VGG16, preprocess_input, decode_predictions\n",
        "*   `tf.keras.preprocessing`\n",
        "> load_img, img_to_array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wcwJQbZRVeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlfH3ImV2C6i",
        "colab_type": "text"
      },
      "source": [
        "Q8. Load image\n",
        "\n",
        "\n",
        "*   Mount Google Drive\n",
        "*   Navigate to image location (use `os`)\n",
        "*   Load image and assign a variable (use `load_img`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1QQhRs99UWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dir = os.path.join(os.getcwd(), '/content/drive/My Drive/Colab Notebooks/images/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR_m7xiFZtPV",
        "colab_type": "code",
        "outputId": "f46b32ee-7eef-439f-efdd-694404dd0b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "os.listdir(image_dir)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['4994221690_d070e8a355_c.jpg',\n",
              " '49438170746_8378201627_c.jpg',\n",
              " '49441887332_107afa786d_c.jpg',\n",
              " '49436743043_2441587ab9_c.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rK0I_E3-tLi",
        "colab_type": "text"
      },
      "source": [
        "Q9. Preprocess the image\n",
        "\n",
        "\n",
        "*   Convert image into array (use `img_to_array`)\n",
        "*   Check shape of image\n",
        "*   Reshape image into 4 dimensional format (use `reshape`)\n",
        "*   Prepare the image for VGG16 (Use `preprocess_input()`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_otMV-qwau4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_array = []\n",
        "for image_path in os.listdir(image_dir):\n",
        "    images_array.append(load_img(image_dir + image_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F83jZo7XbcCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image_index in range(len(images_array)):\n",
        "    model_input = images_array[image_index].resize((224,224))\n",
        "    model_input = img_to_array(model_input)\n",
        "    #Image array should be normalized in same way as was done for VGG training\n",
        "    model_input = vgg16.preprocess_input(model_input)\n",
        "    #Add a dimension to input data to make it a 4D input as required by model\n",
        "    model_input = np.expand_dims(model_input, axis=0)\n",
        "    images_array[image_index] = model_input\n",
        "\n",
        "#We can also write only one for loop for above process."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8GCuI6b3VWA",
        "colab_type": "text"
      },
      "source": [
        "Q10. Predict the Class of image\n",
        "\n",
        "\n",
        "*   Use `predict()` to calculate probabilities (Assign a variable)\n",
        "*   Convert the probabilities to class labels (Use `decode_predictions`)(Assign a variable)\n",
        "*   Print the classification results\n",
        "\n",
        "\n",
        "> Use \n",
        ">*  label = label[0][0]\n",
        ">*   print('%s (%.2f%%)' % (label[1], label[2]*100))\n",
        ">*(where label is variable assigned for `decode_predictions` )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVTFoy3B9U35",
        "colab_type": "code",
        "outputId": "a1e1fe26-4209-47dd-bb95-7a2ca90ecff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Load VGG Model\n",
        "model = vgg16.VGG16(include_top=True, #Should we include classification Layers\n",
        "                    weights='imagenet', #Load imagenet weights, 'None' will load random weights\n",
        "                    input_shape=(224,224,3)) #Input image size"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqE5FzXZf-op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import decode_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdpZWegdBy6d",
        "colab_type": "code",
        "outputId": "12362ca8-4152-40d2-cbfb-a48dffbc3d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Predict\n",
        "for index in range(4):\n",
        "    prediction = model.predict(images_array[index])\n",
        "    print(decode_predictions(prediction, top=2)[0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "[('n03063599', 'coffee_mug', 0.7589643), ('n07930864', 'cup', 0.07653624)]\n",
            "[('n03393912', 'freight_car', 0.3433729), ('n04467665', 'trailer_truck', 0.23375992)]\n",
            "[('n02279972', 'monarch', 0.99720985), ('n02281406', 'sulphur_butterfly', 0.0020955447)]\n",
            "[('n01833805', 'hummingbird', 0.36529157), ('n01828970', 'bee_eater', 0.3073225)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtTaFXdhLeRa",
        "colab_type": "text"
      },
      "source": [
        "#NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdGoZI6GPiMa",
        "colab_type": "text"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxuOeh7gLjsg",
        "colab_type": "text"
      },
      "source": [
        "Read file 'tweets.csv'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvJO8PJjhDHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrBDwzPLOz5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/tweets.csv', encoding='mac_roman')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyGW8vBGm2W6",
        "colab_type": "code",
        "outputId": "df7fc5b1-4d18-48c6-f924-4ae41762e6fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "tweets_df.sample(10)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>Lovin the digital! @mention band sings into iP...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>Arriving at Google party at #SXSW. Small queue...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No emotion toward brand or product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7607</th>\n",
              "      <td>If you were able to afford to attend #sxsw or ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No emotion toward brand or product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>Google to Launch Major New Social Network Call...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No emotion toward brand or product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3181</th>\n",
              "      <td>Grab one for my twin-girls? #sxswnl RT @mentio...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No emotion toward brand or product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5615</th>\n",
              "      <td>RT @mention Check out Your Mom Has an iPad: De...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No emotion toward brand or product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>All this #sxsw gadget lust is rubbing off on m...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8815</th>\n",
              "      <td>Took a few days off (unplugged) to visit famil...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No emotion toward brand or product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5754</th>\n",
              "      <td>RT @mention Full #SXSW #touchingstories presen...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No emotion toward brand or product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3696</th>\n",
              "      <td>Mad mad lines still at the #SXSW Apple pop up ...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "440   Lovin the digital! @mention band sings into iP...  ...                                   Positive emotion\n",
              "2138  Arriving at Google party at #SXSW. Small queue...  ...                 No emotion toward brand or product\n",
              "7607  If you were able to afford to attend #sxsw or ...  ...                 No emotion toward brand or product\n",
              "757   Google to Launch Major New Social Network Call...  ...                 No emotion toward brand or product\n",
              "3181  Grab one for my twin-girls? #sxswnl RT @mentio...  ...                 No emotion toward brand or product\n",
              "5615  RT @mention Check out Your Mom Has an iPad: De...  ...                 No emotion toward brand or product\n",
              "1715  All this #sxsw gadget lust is rubbing off on m...  ...                                   Positive emotion\n",
              "8815  Took a few days off (unplugged) to visit famil...  ...                 No emotion toward brand or product\n",
              "5754  RT @mention Full #SXSW #touchingstories presen...  ...                 No emotion toward brand or product\n",
              "3696  Mad mad lines still at the #SXSW Apple pop up ...  ...                                   Negative emotion\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9erLqL-bo47g",
        "colab_type": "code",
        "outputId": "62621d04-35b5-4c70-ad0d-bb6f376a500c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "tweets_df.info()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9093 entries, 0 to 9092\n",
            "Data columns (total 3 columns):\n",
            "tweet_text                                            9092 non-null object\n",
            "emotion_in_tweet_is_directed_at                       3291 non-null object\n",
            "is_there_an_emotion_directed_at_a_brand_or_product    9093 non-null object\n",
            "dtypes: object(3)\n",
            "memory usage: 213.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGKTjeY0Owyc",
        "colab_type": "text"
      },
      "source": [
        "**Drop null values**\n",
        "\n",
        "*   Drop all the rows with null values\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCEMFY5BPFWa",
        "colab_type": "code",
        "outputId": "dcf6f7c1-1e8b-4278-f5e5-37af1b0de286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "tweets_df.isna().any().describe()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count        3\n",
              "unique       2\n",
              "top       True\n",
              "freq         2\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHT9dSYiO7zo",
        "colab_type": "code",
        "outputId": "97fa796f-9c57-4541-ca2a-1c865b50c46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "tweets_df.isna().sum()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_text                                               1\n",
              "emotion_in_tweet_is_directed_at                       5802\n",
              "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JILOg2-0O8t6",
        "colab_type": "text"
      },
      "source": [
        "**Print the dataframe**\n",
        "*   print initial 5 rows of the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6VLTLbtPQKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_df.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q94-e47ho_0R",
        "colab_type": "code",
        "outputId": "0db77b96-8799-484a-df7f-51c6aa05f55f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "tweets_df.isna().any().describe()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count         3\n",
              "unique        1\n",
              "top       False\n",
              "freq          3\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQiuHNH_pGpG",
        "colab_type": "code",
        "outputId": "152089ee-c9a6-4748-a7f1-21905601b36b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "tweets_df.isna().sum()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_text                                            0\n",
              "emotion_in_tweet_is_directed_at                       0\n",
              "is_there_an_emotion_directed_at_a_brand_or_product    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsExC8JmpJMq",
        "colab_type": "code",
        "outputId": "17448376-b1e4-427d-d8ec-b960f96a7b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "tweets_df.info()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3291 entries, 0 to 9088\n",
            "Data columns (total 3 columns):\n",
            "tweet_text                                            3291 non-null object\n",
            "emotion_in_tweet_is_directed_at                       3291 non-null object\n",
            "is_there_an_emotion_directed_at_a_brand_or_product    3291 non-null object\n",
            "dtypes: object(3)\n",
            "memory usage: 102.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLdX9oROpWxV",
        "colab_type": "code",
        "outputId": "3392b452-6de3-443f-a7c3-466c89d5acf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "tweets_df.sample(5)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3410</th>\n",
              "      <td>To be enchanting, offer the likeability of Vir...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4644</th>\n",
              "      <td>@mention Nice #SXSW song @mention  Donâ€™t hac...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6428</th>\n",
              "      <td>RT @mention Over 300 people in line at Apple s...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1338</th>\n",
              "      <td>Ouch! Who won Google v Bing? @mention with all...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8727</th>\n",
              "      <td>Stellar customer service at the #apple store. ...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "3410  To be enchanting, offer the likeability of Vir...  ...                                   Positive emotion\n",
              "4644  @mention Nice #SXSW song @mention  Donâ€™t hac...  ...                                   Negative emotion\n",
              "6428  RT @mention Over 300 people in line at Apple s...  ...                                   Positive emotion\n",
              "1338  Ouch! Who won Google v Bing? @mention with all...  ...                                   Positive emotion\n",
              "8727  Stellar customer service at the #apple store. ...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPJR8H6SPQqi",
        "colab_type": "text"
      },
      "source": [
        "##Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUX0tTpDQZLo",
        "colab_type": "text"
      },
      "source": [
        "**Preprocess data**\n",
        "\n",
        "\n",
        "*   convert all text to lowercase - use .lower()\n",
        "*   select only numbers, alphabets, and #+_ from text - use re.sub()\n",
        "*   strip all the text - use .strip() [To remove extra spaces]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXY_INTqqJkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMOoHrcuQzBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_df['tweet_text'] = tweets_df['tweet_text'].apply(lambda s: re.sub('[^0-9a-z #+_]','',s))\n",
        "tweets_df['tweet_text'] = tweets_df['tweet_text'].apply(lambda s: s.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emqomK6Uqs_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_df['tweet_text'] = tweets_df['tweet_text'].str.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os_is_IoQzbH",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRI31RfMRG40",
        "colab_type": "text"
      },
      "source": [
        "**Preprocess data**\n",
        "\n",
        "\n",
        "*   in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
        "select only those rows where value equal to \"positive emotion\" or \"negative emotion\"\n",
        "*   find the value counts of \"positive emotion\" and \"negative emotion\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkCmfmPPQ7R6",
        "colab_type": "code",
        "outputId": "61ab8067-8bc3-4d47-941d-8fd22d4d910d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "tweets_df['emotion_in_tweet_is_directed_at'].value_counts()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "iPad                               946\n",
              "Apple                              661\n",
              "iPad or iPhone App                 470\n",
              "Google                             430\n",
              "iPhone                             297\n",
              "Other Google product or service    293\n",
              "Android App                         81\n",
              "Android                             78\n",
              "Other Apple product or service      35\n",
              "Name: emotion_in_tweet_is_directed_at, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7BBDdTTsSgV",
        "colab_type": "code",
        "outputId": "f47dafd1-6876-4a7c-f8db-ac585fd8c650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "tweets_df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive emotion                      2672\n",
              "Negative emotion                       519\n",
              "No emotion toward brand or product      91\n",
              "I can't tell                             9\n",
              "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HKTlQcZsgFs",
        "colab_type": "code",
        "outputId": "4977dbb1-f705-40d2-cf8c-18ec5220f71d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_positive_negative = tweets_df[(tweets_df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion') |\n",
        "          (tweets_df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Negative emotion')]\n",
        "\n",
        "df_positive_negative.head(5)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wesley83  have a 3 ihone fter 3 hrs tweeting a...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee now about fludapp  wesome iadihone ap...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin an not wait for #iad 2 also hey sho...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sxsw  hope this years festival isnt as crashy ...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sxtxstate great stuff on ri # arissa ayer oogl...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  wesley83  have a 3 ihone fter 3 hrs tweeting a...  ...                                   Negative emotion\n",
              "1  jessedee now about fludapp  wesome iadihone ap...  ...                                   Positive emotion\n",
              "2  swonderlin an not wait for #iad 2 also hey sho...  ...                                   Positive emotion\n",
              "3  sxsw  hope this years festival isnt as crashy ...  ...                                   Negative emotion\n",
              "4  sxtxstate great stuff on ri # arissa ayer oogl...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfLi298jtZd6",
        "colab_type": "code",
        "outputId": "8ff880a6-04dd-4c68-f164-84e974b319ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "df_positive_negative['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive emotion    2672\n",
              "Negative emotion     519\n",
              "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_L3AabRRZvq",
        "colab_type": "text"
      },
      "source": [
        "##Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQMO-RQURdUI",
        "colab_type": "text"
      },
      "source": [
        "### Encode labels\n",
        "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
        "    - change \"positive emotion\" to 1\n",
        "    - change \"negative emotion\" to 0\n",
        "- use map function to replace values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P22L1tYlxHc4",
        "colab_type": "code",
        "outputId": "e972ee24-c175-461f-e4ec-ceee3e6f5b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "df_positive_negative['emotion_encoded'] = df_positive_negative['is_there_an_emotion_directed_at_a_brand_or_product'].map({\n",
        "    'Positive emotion': 1, \n",
        "    'Negative emotion': 0\n",
        "    })"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec7kw9n1Rjdc",
        "colab_type": "code",
        "outputId": "fdc779d7-1bc7-4f05-9452-40a8870d8b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_positive_negative.head()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "      <th>emotion_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wesley83  have a 3 ihone fter 3 hrs tweeting a...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee now about fludapp  wesome iadihone ap...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin an not wait for #iad 2 also hey sho...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sxsw  hope this years festival isnt as crashy ...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sxtxstate great stuff on ri # arissa ayer oogl...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... emotion_encoded\n",
              "0  wesley83  have a 3 ihone fter 3 hrs tweeting a...  ...               0\n",
              "1  jessedee now about fludapp  wesome iadihone ap...  ...               1\n",
              "2  swonderlin an not wait for #iad 2 also hey sho...  ...               1\n",
              "3  sxsw  hope this years festival isnt as crashy ...  ...               0\n",
              "4  sxtxstate great stuff on ri # arissa ayer oogl...  ...               1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIy_xlRbRj_H",
        "colab_type": "text"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKuiAcwhRmhz",
        "colab_type": "text"
      },
      "source": [
        "### Get feature and label\n",
        "- get column \"tweet_text\" as feature\n",
        "- get column \"is_there_an_emotion_directed_at_a_brand_or_product\" as label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV3WlXurRokY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature\n",
        "X = df_positive_negative['tweet_text']\n",
        "\n",
        "# target\n",
        "y = df_positive_negative['emotion_encoded']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F4UCW9IRpWL",
        "colab_type": "text"
      },
      "source": [
        "### Create train and test data\n",
        "- use train_test_split to get train and test set\n",
        "- set a random_state\n",
        "- test_size: 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWF9LBDGRsKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dapR4O8vP3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM4xxNXYRsq-",
        "colab_type": "text"
      },
      "source": [
        "## Question 6\n",
        "\n",
        "### Vectorize data\n",
        "- create document-term matrix\n",
        "- use CountVectorizer()\n",
        "    - ngram_range: (1, 2)\n",
        "    - stop_words: 'english'\n",
        "    - min_df: 2   \n",
        "- do fit_transform on X_train\n",
        "- do transform on X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1l9btlNRwfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# instantiate the vectorizer\n",
        "vect = CountVectorizer(ngram_range=(1,2), stop_words='english', min_df=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCuxisfTyubw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn training data vocabulary, then use it to create a document-term matrix\n",
        "vect.fit(X_train)\n",
        "X_train_dtm = vect.transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX7yWam4yuW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# equivalently: combine fit and transform into a single step\n",
        "X_train_dtm = vect.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv8ZCYwfyyDe",
        "colab_type": "code",
        "outputId": "d755a0ed-d457-408c-cc76-18a4f044bce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# examine the document-term matrix\n",
        "X_train_dtm"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2393x5489 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 33095 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_FrWx_OyyAT",
        "colab_type": "code",
        "outputId": "65c41d4e-cea4-444e-89ea-68602e47e691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
        "X_test_dtm = vect.transform(X_test)\n",
        "X_test_dtm"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<798x5489 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 9131 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6AzeV5ZRxZD",
        "colab_type": "text"
      },
      "source": [
        "## Question 7\n",
        "\n",
        "### Select classifier logistic regression\n",
        "- use logistic regression for predicting sentiment of the given tweet\n",
        "- initialize classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rb4NWC5R0lV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnIVaronR1MS",
        "colab_type": "text"
      },
      "source": [
        "### Fit the classifer\n",
        "- fit logistic regression classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fwF08J2R4Og",
        "colab_type": "code",
        "outputId": "e50d2217-4672-4a82-8adf-cd685dc4d700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# train the model using X_train_dtm\n",
        "logreg.fit(X_train_dtm, y_train)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7k4abGDR4oR",
        "colab_type": "text"
      },
      "source": [
        "## Question 8\n",
        "\n",
        "### Select classifier naive bayes\n",
        "- use naive bayes for predicting sentiment of the given tweet\n",
        "- initialize classifier\n",
        "- use MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiWWDTj8R8b9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import and instantiate a Multinomial Naive Bayes model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb = MultinomialNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yONFSFc_R9FF",
        "colab_type": "text"
      },
      "source": [
        "### Fit the classifer\n",
        "- fit naive bayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPFTYhNBSA1N",
        "colab_type": "code",
        "outputId": "dbe12f4a-7261-4d49-ad4a-8857c84d05c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# train the model using X_train_dtm\n",
        "nb.fit(X_train_dtm, y_train)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSTMQEVhSJ04",
        "colab_type": "text"
      },
      "source": [
        "## Question 9\n",
        "\n",
        "### Make predictions on logistic regression\n",
        "- use your trained logistic regression model to make predictions on X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb4xte6vSVas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make class predictions for X_test_dtm\n",
        "y_pred_class_log = logreg.predict(X_test_dtm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZqjZJiXR_6x",
        "colab_type": "text"
      },
      "source": [
        "### Make predictions on naive bayes\n",
        "- use your trained naive bayes model to make predictions on X_test\n",
        "- use a different variable name to store predictions so that they are kept separately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoClZXgTSVAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make class predictions for X_test_dtm\n",
        "y_pred_class_naive = nb.predict(X_test_dtm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHZ_D-zsSXR7",
        "colab_type": "text"
      },
      "source": [
        "## Question 10\n",
        "\n",
        "### Calculate accuracy of logistic regression\n",
        "- check accuracy of logistic regression classifer\n",
        "- use sklearn.metrics.accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GXsX53I0F4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate accuracy of class predictions\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1luBwomSZ7w",
        "colab_type": "code",
        "outputId": "d70a0d5d-4512-4004-9849-7f7467132cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Score logistic model\n",
        "metrics.accuracy_score(y_test, y_pred_class_log)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8734335839598998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc9l9vNbSas-",
        "colab_type": "text"
      },
      "source": [
        "### Calculate accuracy of naive bayes\n",
        "- check accuracy of naive bayes classifer\n",
        "- use sklearn.metrics.accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvfXGyPNSdC5",
        "colab_type": "code",
        "outputId": "f692bfca-0a52-4c39-fedf-081c1f3d8f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Score naive model\n",
        "metrics.accuracy_score(y_test, y_pred_class_naive)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8784461152882206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLTYi8cK3Gfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzIQZWOw0zKQ",
        "colab_type": "code",
        "outputId": "0fef3d4b-799e-424e-f919-bed419ab890d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Trying some experiment with logistic model\n",
        "logreg_weighted = LogisticRegression(class_weight={\n",
        "    0: 5, 1: 1\n",
        "})\n",
        "\n",
        "logreg_weighted.fit(X_train_dtm, y_train)\n",
        "\n",
        "# make class predictions for X_test_dtm\n",
        "y_pred_class_log_weighted = logreg_weighted.predict(X_test_dtm)\n",
        "\n",
        "# Score logistic weighted model\n",
        "metrics.accuracy_score(y_test, y_pred_class_log_weighted)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.849624060150376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJhOzJdR1CRx",
        "colab_type": "code",
        "outputId": "c402cd51-f409-4963-fbc5-ad461a8f428d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "print(metrics.classification_report(y_test, y_pred_class_log_weighted))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.58      0.56       130\n",
            "           1       0.92      0.90      0.91       668\n",
            "\n",
            "    accuracy                           0.85       798\n",
            "   macro avg       0.73      0.74      0.73       798\n",
            "weighted avg       0.85      0.85      0.85       798\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nxBW9zN1CU3",
        "colab_type": "code",
        "outputId": "a99c1c65-8361-4ae8-af58-04c245424884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "print(metrics.classification_report(y_test, y_pred_class_log))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.32      0.45       130\n",
            "           1       0.88      0.98      0.93       668\n",
            "\n",
            "    accuracy                           0.87       798\n",
            "   macro avg       0.83      0.65      0.69       798\n",
            "weighted avg       0.86      0.87      0.85       798\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8iiiF1x1q9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}