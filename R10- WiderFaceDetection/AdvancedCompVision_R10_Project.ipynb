{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Face_detection_Questions_Project_CV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VvWl3ebqzCc1"
      },
      "source": [
        "# Instructions\n",
        "- Some parts of the code are already done for you\n",
        "- You need to execute all the cells\n",
        "- You need to add the code where ever you see `\"#### Add your code here ####\"`\n",
        "- Marks are mentioned along with the cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NgR0j5310qqC"
      },
      "source": [
        "# Face detection\n",
        "Task is to predict the boundaries(mask) around the face in a given image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Aa0jyJzw091I"
      },
      "source": [
        "## Dataset\n",
        "Faces in images marked with bounding boxes. Have around 500 images with around 1100 faces manually tagged via bounding box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CjRTlPkp1LC2"
      },
      "source": [
        "### Mount Google drive if you are using google colab\n",
        "- We recommend using Google Colab as you can face memory issues and longer runtimes while running on local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sBWMoTJ9cf3Z",
        "outputId": "12afd36e-766b-4ca3-b82d-49852c18d380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sO9mgMmp13sI"
      },
      "source": [
        "### Change current working directory to project folder (1 mark)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TddMnf4D1-59",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/ACV_FaceDetection/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3srplE-FEpKa"
      },
      "source": [
        "### Load the \"images.npy\" file (2 marks)\n",
        "- This file contains images with details of bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MqFE_tZDf0sM",
        "outputId": "87ebf661-eef7-417a-e1ca-ad29af924bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "data = np.load('images.npy',allow_pickle=True)\n",
        "data.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_SMP8zliFT7R"
      },
      "source": [
        "### Check one sample from the loaded \"images.npy\" file  (2 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NoqNvPK-iXqG",
        "outputId": "6818e25f-17d4-4fee-bd61-da9915ca9004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "source": [
        "print(data[0])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[[42, 37, 34],\n",
            "        [56, 51, 48],\n",
            "        [71, 66, 63],\n",
            "        ...,\n",
            "        [23, 33, 34],\n",
            "        [26, 36, 37],\n",
            "        [28, 38, 39]],\n",
            "\n",
            "       [[40, 35, 32],\n",
            "        [51, 46, 43],\n",
            "        [64, 59, 56],\n",
            "        ...,\n",
            "        [27, 36, 35],\n",
            "        [24, 33, 32],\n",
            "        [26, 35, 34]],\n",
            "\n",
            "       [[43, 38, 35],\n",
            "        [51, 46, 43],\n",
            "        [61, 56, 53],\n",
            "        ...,\n",
            "        [28, 30, 27],\n",
            "        [33, 35, 32],\n",
            "        [35, 37, 34]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[56, 47, 40],\n",
            "        [57, 48, 41],\n",
            "        [61, 52, 45],\n",
            "        ...,\n",
            "        [67, 48, 42],\n",
            "        [55, 35, 28],\n",
            "        [60, 40, 33]],\n",
            "\n",
            "       [[53, 44, 37],\n",
            "        [54, 45, 38],\n",
            "        [57, 48, 41],\n",
            "        ...,\n",
            "        [59, 40, 34],\n",
            "        [60, 40, 33],\n",
            "        [54, 34, 27]],\n",
            "\n",
            "       [[53, 44, 37],\n",
            "        [54, 45, 38],\n",
            "        [57, 48, 41],\n",
            "        ...,\n",
            "        [59, 40, 34],\n",
            "        [70, 50, 43],\n",
            "        [64, 44, 37]]], dtype=uint8)\n",
            " list([{'label': ['Face'], 'notes': '', 'points': [{'x': 0.08615384615384615, 'y': 0.3063063063063063}, {'x': 0.1723076923076923, 'y': 0.45345345345345345}], 'imageWidth': 650, 'imageHeight': 333}, {'label': ['Face'], 'notes': '', 'points': [{'x': 0.583076923076923, 'y': 0.2912912912912913}, {'x': 0.6584615384615384, 'y': 0.46846846846846846}], 'imageWidth': 650, 'imageHeight': 333}])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m94G4p3CE5Cj"
      },
      "source": [
        "### Set image dimensions   (1 mark)\n",
        "- Initialize image height, image width with value: 224 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kuZmtOASevDo",
        "colab": {}
      },
      "source": [
        "IMAGE_WIDTH = 224\n",
        "IMAGE_HEIGHT = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wY6FEsCjG47s"
      },
      "source": [
        "### Create features and labels\n",
        "- Here feature is the image\n",
        "- The label is the mask\n",
        "- Images will be stored in \"X_train\" array\n",
        "- Masks will be stored in \"masks\" array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XjCT9EVTgAvr",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "masks = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "X_train = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "for index in range(data.shape[0]):\n",
        "    img = data[index][0]\n",
        "    img = cv2.resize(img, dsize=(IMAGE_HEIGHT, IMAGE_WIDTH), interpolation=cv2.INTER_CUBIC)\n",
        "    try:\n",
        "      img = img[:, :, :3]\n",
        "    except:\n",
        "      continue\n",
        "    X_train[index] = preprocess_input(np.array(img, dtype=np.float32))\n",
        "    for i in data[index][1]:\n",
        "        x1 = int(i[\"points\"][0]['x'] * IMAGE_WIDTH)\n",
        "        x2 = int(i[\"points\"][1]['x'] * IMAGE_WIDTH)\n",
        "        y1 = int(i[\"points\"][0]['y'] * IMAGE_HEIGHT)\n",
        "        y2 = int(i[\"points\"][1]['y'] * IMAGE_HEIGHT)\n",
        "        masks[index][y1:y2, x1:x2] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N3AYbP79bFtJ"
      },
      "source": [
        "### Print the shape of X_train and mask array  (1 mark)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3PIRaEdWIjDa",
        "outputId": "ac7177d6-a6b9-4d96-dcd5-0e4a813102b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gw6uH5DxgI_r",
        "outputId": "4098e6db-5f03-46db-db83-9be48720c27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "masks.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409, 224, 224)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R4wgkWq1bk5F"
      },
      "source": [
        "### Print a sample image and image array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qfRZjQufj0N9",
        "outputId": "005838f4-5a0b-4000-892c-49ce50fff77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "n = 10\n",
        "print(X_train[n])\n",
        "pyplot.imshow(X_train[n])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[[-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  ...\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]]\n",
            "\n",
            " [[-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  ...\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]]\n",
            "\n",
            " [[-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  ...\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  ...\n",
            "  [-0.96862745 -0.96862745 -0.96862745]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]]\n",
            "\n",
            " [[-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  ...\n",
            "  [-0.96862745 -0.96862745 -0.96862745]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]\n",
            "  [-0.95294118 -0.95294118 -0.95294118]]\n",
            "\n",
            " [[-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  ...\n",
            "  [-0.97647059 -0.97647059 -0.97647059]\n",
            "  [-0.96862745 -0.96862745 -0.96862745]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f776c6d1748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOy9d5Rc13ng+bvvvXqVq3NCA41EBAIgCZEURZEUg6hAirIombKSx5ZGtiiuRzsez5y1PfLsjme83qP12taM18f2SpacrWDLsmSbypZIUSIpZgIECCKHzrnyi3f/+KqJJtAgQHQE+v7OqdNdr1+9d6u67ne/+0WltcZgMKxerOUegMFgWF6MEDAYVjlGCBgMqxwjBAyGVY4RAgbDKscIAYNhlbNoQkApdZdS6oBS6pBS6tcX6z4Gg2F+qMWIE1BK2cBLwFuBU8ATwAe11vsW/GYGg2FeLJYmcANwSGt9RGvtA18E7l2kexkMhnngLNJ1e4GTs56fAt5wrpOVUiZs0WBYfMa01h1nHlwsIXBelFL3A/cv1/0NhlXI8bkOLpYQ6AfWzXq+tnHsZbTWnwE+A0YTMBiWk8WyCTwBbFFKbVRKucAHgK8v0r0MBsM8WBRNQGsdKqU+AXwLsIHPa61fWIx7GQyG+bEoLsLXPAizHTAYloKntNbXn3nQRAwaDKscIwQMhlWOEQIGwyrHCAGDYZVjhIDBsMoxQsBgWOUYIWAwrHKMEDAYVjlGCBgMqxwjBAyGVY4RAgbDKscIAYNhlWOEgMGwylm2ykIGw6uxJgFBCBUNNcCkmS4eRhMwrAhSyIqUbfzc3gpv7IGNjjzvwXxZF4uL/lyVUuuUUt9XSu1TSr2glPrlxvHfVEr1K6WebTzesXDDNVyu9GShKSkVaBRQKsObdq9nXS6JjQgC1Tg3t2yjvDyZz3YgBP6T1vpppVQeeEop9Z3G3z6ttf7d+Q/PsFrwfOi0oKpgax4GqjA2PUU1ComBYSBqnNuj4JA2W4SF4qKFgNZ6EBhs/F5SSu1HSo0bDK+ZMIC737KVqDZOVpXY/1LIPz0/TVCBJFCede6QEQALyoJss5RSG4DXAY83Dn1CKfW8UurzSqmWhbiH4fImkwBHl8lZHs8dDelKxkx4YMWics6e9KUzXtuNbCMMF8e8hYBSKgd8BfgPWusi8MfAZmA3oin83jled79S6kml1JPzHYPh0mckhP0vDTN0rMILozGVMqhYPAOv9iW1gS4gXpphXpbMq9CoUioB/DPwLa3178/x9w3AP2utd53nOka7M7Dehpub4Udl2BTAoRhaEU2g3Pg5wNlbgW5gaInHeokyZ6HRi7YJKKUU8Dlg/2wBoJTqadgLAN4D7L3YexhWF0MRWBb0WDAci4FpLdAOZDugZ7tNMYzY8zz8awWmG6/rA+pAEaMRXAzz8Q7cDPwcsEcp9Wzj2CeBDyqldiMC+xjw8XmN0LBqaAL0NGwKZR/ZAWzJQ+8aaNsIXTv7SGWTXLXpFNc8W+ZPXhANYB2y0hgBcHHMxzvwCKddt7N58OKHY1jNJIHIhw0WrFFgO7CpD3o3Q9vmNeQ3rCVXgFw6pCc9gi4W+fRJ2IdsCY4s8/gvVUzYsGHZ6AW2K5gCDmhZUdozcFUvFFqhHsLGjdC9uZvmrZtwe9dh22XyKqAdG+f2kNZnq/zqHgiW+b1cyhghYFgyLMSan0X61N+zETbsgJN1GA8hSEJ330Zat24jn3KpV2uonjVUe3qxOnopdPUw4k1Qaz2G07UP7U7whu4q/9sY/NEgTCDhxeOAv4zv81LDCAHDkpFAVv9twE1rYO1mcPI2u69ZR8eGXUSZDjItXTS3t5NKuURhgJMvYOdbUNkWSKbIF0FXx4gcl2yumThb4d3vq5H6pub3DzSi1wyvCSMEDEtGCrHkb2uCdZsh1+fgdvaQ79uO27GJbPtm0u09pHJZrFyahK3AdsFNoVUKP9Cksx5+upmyTqJSGQLbJpHPc/MtRb5xAH7UuJeDuBQN58cIAcOSkAS2Arc0wTXXQu9VCQobNtG84fU0rd1Jun0LVvMmSOYBiBMay7GJsEFDiENoga3rWFaaehjj42A3teLGinWpkPuuqzLyFBy3FV/7+E7e9Sd7ubMXvnlyWd/6iscIAcOikwKuAu7KwQ1XQlsfkE0QN+dJrV1Hum87VnYD2F1oK0MQBmjAJkGoNZZKEGOBo7H8aZxEnlpo4fkB5dIEW3rWk3Lq3P0OGO6v8t0hzX/7o72gIB3BLe3wyNiyfgQrGpOibVhUXGA7cDvQl4BkCiIbAiuipiyCVJbYzUKyiWqcZipIEqZawWklIo+j8tg6QyJK4YYpIhwcJ4VlJfDjmGq9TtEvEuOS72jl5jdJvMFjgNZQn1L0deWX8yNY8RhNwLCoZIAdQG8SOnqg0CKW+wBI2BApiN0EOCl0nEZFCcDCQaMAC4WOIQ4jnDAG28InxrLAsmLiOKBanWKKHAXHpakAnbPuX6lqvvPCmSlHhtkYTcCwaNiIy+56C9Y0Q1cfZFsgVkAMVqSJgjpx5BHHHg4ax1ZYsSYOQuLAJ/J8lPZxYh+Fj4VPHIdYVkTGdXAs8MtFin4VXJfOvmY686INhMDDGAPh+TBCwLAo2MAG4E4FG1JQaId0K0QO+DHoSKN8D788hV8eI6hPYeOTUjEJ5eFYHrYVYjkBWD7araOdGjERvl9FxT7plCLjgBVCNSpSpUhze4brr4XrkS+3Yu6wVsNpzHbAsOBYSPbfVcBmC3IFSDWLAKh6coKDBj/AKxWZmhgkrzrJ5rtIJF2UisDSoERl0LGPVj4BHn5Qw6+WiX0fFfmoECIPak5MLSzTmc3RsxauSoNbg1NIYtHxZfw8VjpGEzAsKAlgPRIQtBFIK7DSkGiBUgxVX9yF2Tgi7RfRpX68yRP45X6ieAKogwrRaGIdExMT4hHrCmEwgfaGCeujKMtDeyWCOjgRZDxQXg3bUTR3i/2hCbFJGA/hq2M0AcOCYQO7kHiAVmAN4DpAHuoJqMbgaEhpSPkxrjeNP32Ksp0ktHIk8t246RxKZ4jjBLEFFj62ivArE9THTlGvHKM8fgKXKnUV4rpgB5J9OF2NqKTL5FottuzQ7Dmp2RNBLgFeAJ5JM5wTIwQMC4aLRARuAlqQzL4mGwpZKPugFSgL4rrk//upGn5igkqYxPKz2Nn1hORIWHlwUsQoXBeStk9pcoix0ZP4UyfwSqPY/gRhuUgqAXEN/BpUpmCspcSa7lZuuNEnqpRp3wNX3ZDiK0/U+fbocn46KxcjBAwLgoWo/x1IcFAWKQbiKlAa7AgSIRBBJQSSYLkR2p2m6tvEUYbs8BGiOEnCzmOnm4gti4QL6UTI9NgAtckBlDdGUB2lOnGSeLpKOoTQh6gGxDA8AOnUFPl0ikwzPDMGjz1Yx9SwOzdGCBgWBIVsAZqAQuORb4T+E0AaiD3wKjJpVW5mHx/gOlWisIQKJ3HiKZSOiKp1Ytsm9hSh7ePXxlH+NKo6BuVRdG2alAY3hiiUgqQqgIkhyCZi0msjlAtZG/bF0JWE8bpxF87FvIWAUuoYUgA2AkKt9fVKqVbgS4iX6BjwPq315HzvZVjZzDQJySOaQEbJlyIog52C2IegAtqCTBZyDlgJTSoFOgtNiTo5p4alHHwiImUTo9B+HTuqkoym8cqDWPUJ8o0MIVuDDuW+VghhFbwa1EOP9m64fQNsGoXOdfBHL4CJHj6bhfIO3KG13j2riOGvA9/TWm8Bvtd4briM0chKUELKfLlAFEO9BPVRqA9BPA5WGTIxNLmQd6HgQEsCmpwIx58iKg8RVkaxwiJOXCNpx9jUcFWNRFRBV8ZJ6jp5V6E8cGIpV15IigGwOQ1JG1KuIt+uuOnNFtfuhNK0FC8xnM1ibQfuRcLFAf4C+AHwa4t0L8MKoYz45H3AQ8qFBwHoItgKkq54CzJJaTmWQsqKW0oTK5/AmyasjKFUiB2H2FYBhSaOAyxCEvj4uk4YVLBVTMqCuKHfpy1QCbmeA2hboZIWazc6tOR8pqoxbaekk5HhlSyEJqCBbyulnlJK3d841jWr4vAQUhr+FZi+A5cXMVLRZxyoIALAQ74cTgROFZI+ZJVMfjuCqAr+NESlOlG1RFidIihN4FcmCWpFVORhRREJpUjZmpQdk3ZjXKWxYo3T+PYqBUTg2pB2JCdBo3EyWaoxWGmHK9bBdRnRUEyjkleyEJrALVrrfqVUJ/AdpdSLs/+otdZz9RXQWn8G+AyYvgOXC1NAP1Ldx0WMgTmg2QLXakxWgEBcelERIg0JOyBW09QChyBtgfJptpOkW1qJoxClNZEfYEcxFhG+HxMjRUktxO1ox40VLYYogihSJLM5Ij9JcXyEzha4e5fNvp9EDHK6r6FhAYSA1rq/8XNEKfVV4AZgeKb/gFKqBxiZ730MK58YCdM9ingLskh0oAMktFjw4xCCGkRliC1QNpABq+qTdKs4qkSMTdqvkPTLxEqhI5+oMoWuTGN5PsoXYyCeTP44giCUrUbggV2H2I8JSmWa8m3E+SmCWsCWjTZtP4k4tlwf0AplXtsBpVS20ZEYpVQWeBtSAv7rwIcbp30Y+Np87mO4NNCITeAEsgec6RpUjaBYg6AKugJWFewyZOqQD6BZQYcN6xzYaAX0UaYtmCRTHiZXGyZTHyJZHcUpjhJN+uhpsCqQCcGuQSqESiy5CbEPcRkSPviTJRJhQFtTjlhpJkv+KwqQNuVybOjpWYZPamUxX02gC/iqNCPCAf5Wa/1NpdQTwJeVUr+A5G68b573MVwiRIg20IG449qQPbjSUK7LhHUiyTGIHUhmZNKGCdBWDSuliOIaXiKB5SjiWpG6V4fSKE5tGiqaYBpiDZU62BZkXUg5sj2wOR03EAYx5alp0paFApIJcV92Ji2uurKXvg07eeyZ/cv1Ua0Y5iUEtNZHgGvmOD4O3DmfaxsuTTQwiWgDzUjw0MxxDWRDcMuQqEPOh1wINQ+sSXCafJxsQIhCTdaoToxRw6ZWC8hRJedVSdUhH0OtApPDEopMKySz4hlIJ0RAODHYPpQmitSwsW3Ip2CdC22dTfzSz7+NsbCDP/vHby7PB7WCMBGDhgUnQgyEOaSXYAuyLZhGNIMUYIcQTYKORCCojEQROjlNrDQqXUalytQVhJFUIApCCQ+OIpnorRmYmoLiBGR9KDSs/34IUUW0De1ApRyRTYHnia0imUpS8wO++OD3lucDWmEYIWBYcDRiDziF+OU3IUbDEqKOZxBjlBU3jHiT4JfBnwQrJau7kwadANJiPPRpGAGrMslVAvJtkGqB0SJUxqRpqUI0gsqkvD7RJF/yiTGYLMKID9VqhUcff4IHHzZbATBCwLBIaMRleASpMdiMeAtA9u0JRDDUGpZ+X0Fgy+RXlkz2RBYylmgWXh1UhBQR0WC5MtE71oCbgPKUFBdRjtgJ/DJoVwRGNg/7jsOBAakt4NTrjA71n9XifLVihIBh0fCQxJGTyDagB5n4NjKxi0AcQ3saOpshSsqqX69LH8K0Da1ZMQCOTEO1JpGHWJDOy7m1MjS3SCKRH0FsNwRB4x7VooQRX7ERnj4pmklfHBF43nJ8JCsSIwQMi8ZMPsFJpNBIntNCoN742Z6GzlYgDdO+TPQwhCCGaBrcJFhJaC7AdAjlsoQixxY4DkyMgmNLjEAhC54S4ZPOQD2QnIIjB6FzA7ztFgu3O+bQyZjHDpkWpjOY8mKGRSVAYgZGEIEAYrwrIJ4DJ4JKFYqNyR3GYNvSlrzuwcQUeD60dkFnL9hJcS1OVmBgFEol8D3wfREKOI2flhgdVSw/H3oIhk5pOmMIy3CsaMoMzWA0AcOiEgCjiOofIat/EvEYBEAlgEoJtAexK/UHbFv2/soSj8B0UVKP3Qx0r5WmIqMjMDUN0yVwXWhpATctXoZ0WmwNli1bgW1b4cXj8Ow+zeNl2F83YcOzMULAsKjEQJXT0YMzW4EK8uWrayQMOJCEItuCqoJJDYEj1n6nEQyUS0sGoo6gLQH5JpgcgYkBiRuIXMglAauh4nowOiXC4roNUD8Be0ZkLGfSt66TpJvg4OH+pfhYVhRGCBgWnQhZ9WcChjxEM7CQbUIZ8DSUG/kFecR7ANDVCp2bYPMmCQCaGpSIwIILiWbo7IDJUajFMtk9B9oTUtYs8mF0APYfg5YmKWZSYG4hsGFDH02FnBECBsNioBEh0Mj4pc7pMl8DSGCRQjwI3UBPEyRawc7B2h3Qts4i32QR10N8XyoHJZR8eaNGqTIiKAVAEsolqE1D0gNdFtfh3lFJMb4nBWMO7C3DwVljDL0Av7Y6PQZGCBgWHQ9Z8UPkC6cax+qN3zcB64CuFHT0Qn4N2F3gtEFzXzN23sUPa2jKZNs0biBbgnQCitOQycl10yGEFoyNwsiQhCgHk3KfI1q8C3YIU0q2KLMZGx2lXHKX7DNZSRghYFh0PMQ/X0UmfRrxECQbzxONhxWCXxVvgAugISTEDzXpTIZqvcLwtCaOJb4gDqVakZOSbYR2xaWYrUMuB860bB2aEdvEMLL6a81ZgUKHjg+iXi54sLowQsCwJPhIYlEZcQ1ayER0kS9hiAQINTfKhEVAUx6SuRRjdY9Dh0bpPxozPSnGwziWaEAnAb1roS0NmSaJM4jSkMlDbQzylmwzZuwM56o2HMczFovVhxEChkUnRlTyGVtAvXFMIV/AGClHlkaKk6YS0rn4+AkIxsaYCEU7iGMotEF7B6Rycm6xJvEF1QyQgEQCMi54g7I1ULFoHGlMUMy5MELAsOg4SNLQjKuwA4kTKLgS/DNVh2IgAmJqGqYOwMlnQefg5ntTXNHXROw6WFHEVODR1N5GU3MTJDOUq1WK5TqTtRpWWCfyp/BUFZ2GZO50hGK6MYa5SDbOOdNOsFq4aCGglNqG9BaYYRPwfyBbsI8hMSIAn9RaP3jRIzRcssx0J94CXNH4PUASidakIdMMdQXTEYSBaAgtFuSycPNuyHRDU1uOshfjKod0Okm6ewNWNodOZbBcl3Qa0h0WHSmXcnGS6tgx4vHj2D1lpiahclAmeDPnLjDqn+P4auGihYDW+gCwG0ApZSOenq8C/xb4tNb6dxdkhIZLlhk1P4Ws/DNegqNApQaFQFT/ki8CIAN0t0DvZgjz4AdQnihBSwvpfBY3maFmpwAX7YMXxfhYZJuacQoZMqkMmYxNnIDy+AskxsUOAdIjsWWOMdqIsLrSlUrIj65CL+FCbQfuBA5rrY+vVgurYW4iRBCAFBnpbjxyQMKChAMtIaQiyCchGYM/JqnD9TQkHAvlWIxVy1h6klQhS6G7Dc9OcGJynGJQZ8vWK8k4V+CQAreTemqayE2R7qgTJiDwRQs5q+49IgASwPZNfbRnkjz69ME5zrq8WSgh8AHgC7Oef0Ip9fPAk8B/Mi3IDFngamTP2JOCbC9k1kPSgvIwDPRD/xRU+iExBFEreDmYOlCjqGvUGtWCQqBz3SGy3eAloViH6VODdG+YoH3NGnKFJE7Npat9LZPDh5j0RMvoA3bOMa6g8Tj84gkipInqamtVprSen1tEKeUigV87tdbDSqku5HPUwG8BPVrrj87xuvuBmWYl181rEIYVhULCcxOIir8B2TdeiajkeSBnQXcrdLZAWIOBcXi8JhMyRDIOTwA/QoxLMyt2BKxBJnVnBqaqsqdvSsAV26C3D665sp3NBY01Oc6X/oeEKG9TMJiCX6hxTtY0xn4ZBw4/NatV4MsshCZwN/C01noYYOYngFLqs8A/z/Ui03zk8sdB7AFjyITuRlblMUTtnxyD4pjECpQQW8E4UpFoFFEjS3Ncd6Dxt0JVBIoCxgLo3gt9e+Gup8a4aSvcuBWaczBZlhqFSVuE0LnU0qEFe+eXFgshBD7IrK3ATNORxtP3IH0IDKsMC9ECNLJ6TyCTLMXpIKFa428zBrsx4HlEYIxw/nTfYuMxw7HGozoMU6PQ6kFXOxxrZAy5yGp/LiGwWisMzEsINBqOvBX4+KzDv6OU2o38r4+d8TfDKmCm7PjsyTaM2AV6kViBOlJx6BSwuXH8OPAE85+MTwLPxZB4Cj6yG1LHoKYlb+Bq4IV5Xv9yY759BypIVObsYz83rxEZLkumgG9xWhOYiRDciqiLm5EkohyvXN0vlhD4R+ADNfEKKC3diToQYVRpnJdpjGliAe55qWIiKQ1LxkyBkRnbXA3Yj9gCpoGNnLGizAMNHI3gkX2yrUhbUG40LZ0dNLQeuBERDKkFuvelhhEChmXFR/b/w4htIHeR15krOiUEHkOClJR9up5BbdZr8ojwua7xczVihIBh2TmMWPx3pKHPOXd476sx0wZ9NhFwAClTnk1BZ1ayCmdcUTlEE9gB3ANsu7jhX/IYIWBYdkaRPXlbL9xagM6LuEYCaYqZmHUsRmwRWNDcCjt3QXvhtBCY0QwSyDZktca6GiFgWHZmAoMOKlhnQ8tFzMZpJLCoddYxG4lQrAF+Euw8ZJOSTETj+DiSRVhpjGE1YoSAYdnZAKxLQjpnsaFb0Zq6+FV5JlJNIRrFLgXdWRiaBC8Ay2pULUKiE4tIDkNgr95gISMEDMvOdQo+tB5evyvH9mtcrilcvIFwhibgbcANBdi8CyZrECrwa6L6z9gdQkCloZqHwXNe7fLGCAHD8mNLbYHC2gKp5iRvSkLHRaoCa5G4gGuA63Kw5kpoXgttXdLRKK6LF2AnoilEQJgEnTERgwbDslEJYWAaNsYWOoDNOcgneM3VPnqB+9e69E/6rEnA67fB2qst0m7M9qth5IgUM+0Fbk4qDqRtHp4KmXTAX52FhgEjBAwrgBiILNCuQ9WzSDuwy4ZDnI7suxB+aWuOn7utk73PHaGQh83bbex2B9sLSWcjrFjamtnApuYkfZsKPPXoCBMaKqs4hc1sBwwrAjsBKulQD2ziOry/AG9wxHJ/PlqAm4AP39pKU7vL2iugeytYbYrIBW3b+HUI6qddgqDZmo34+fVw9TobO71618PV+84NKwYLqTAUhiFRFJGw4MoW+JmqdBB+XEvU32zuAXIJyBSkrsDuLATxNINDI7itCcJURMm2ybsOuhbilSCsiNfABiZKHn0DHu/e5pDrSfOTPT7nLkh+eWOEgGHZsQDXBq01YQhZF6jC7gxYDjANj8WS7LMZKfpxL7C1BdxWSK+BMA1eOE3oQmtHC7UEkE5iWwFQw6+Arp5OTx6qw6lBSDWDHYTUg2A53vqKwAgBw8ogAtdxiZVNEJwuOrpmDfRMwl/uhf5Asg7vtaA1hnpNgn961yeZ8DywQDvgFlJY6SyRUuj6FDoCrwrTFbE1OkB/DMNFOH4gZM10SOm1GB8uM4wQMKwIoilQviZ2NLUQ8i5YGch3wW0bFRk0P9wDAyEc13AL0q7c0nDwWISnoHs9qLSFZ0e4DthBgOX5eCUfqlAOZCsQI7UM9kewfRzei4OTVkj40OrjggyDSqnPK6VGlFJ7Zx1rVUp9Ryl1sPGzpXFcKaX+QCl1SCn1vFLq2sUavOHywAbCIsTVgIQVk7BAKWlLNl0F7Wpe/8Ym3ndTiuscGNLS8KK9BYYGYLg/RAfQ1ZmluTmDFUM4XSSeKuJNVvAmQorjksacQewCFSS60G1LctW6DIG/WqMELtw78OfAXWcc+3Xge1rrLcD3Gs9Bag5uaTzuB/54/sM0XM7YQFCBsBSQURFJi5fjhqNA+gtmC7D1Kpfrr1D8bBf8BHhuGBwbtq6HTeugOevSls1SIEE8UUSPVQgmQ6hCaUKMiwnE46CReIHraiEnBmoMT56vmNnlywUJAa31w5xdfOVe4C8av/8F8O5Zx/9SC48BzUqpnoUYrOHyRIG48KZrOEGICmXyJxqb1TiAICxjNwVsf3sr1+5UfKQD/rUC2TwkNXS1Wai6T1LZWKNF1LBHNOATDEBlEIqRbAOSSPGQDBI+PFGN+L9HA/aszp0AMD+bQNesgqJDnO7t0ItsuWY41Ti2WkOzDbMoIBNwdrKOAmINQc3DdiKiAOoakgWI6tKuPIoj/KiOTkX0Xm1xlxvBQzAyBK+7HoJSTNKqEVQDJvpD6pOaYErKig0ckXqHOSTLsIgIg/1IXcOxVRwoBAsULKSlecFr+iiVUvcrpZ5USj25EGMwrHxagOuRFWE2MeKhj2MIQw0uWEnRBFQArgbHgrqvGZr0qVkRfddYXLsT0gV4+keQ8CGcjrHHfbz+mPJL4J8AbxgGpsQekEeEgIMIghJiF4g4f2Xjy5n5aALDM+XFG+r+SON4P1Izcoa1zNHPwfQdWH2kkYl4ZoefOrIaqTBGZ8Xnb4WyqqRcaS8eVqTVeKkIvgfptTH5LohKUDoFA0ehpQmmB6EyKt6G2IMoAUUtdn8NpGzwotOVkE2h0flpAl8HPtz4/cPA12Yd//mGl+BGYHrWtsGwSmlGynhFzF33PwEkkimaerK4nTZOk2wR+o/C1ABQgZSGnAOeB2EMG6+A1i5wM3D8Bdj7Y/jhPvjaEOyvwUQElboYHvuAvA1uVr70SeDmxpiml+YjWLFcqIvwC8CjwDal1Cml1C8AnwLeqpQ6CLyl8RzgQeAIkv/xWeCXFnzUhhWPhZT33oqk7t6IpO/WOLukeAqxC6hsjqYNG0n1ZLEzECsYHYYHn4MnfgyOTtDRBLkU1KuQa3VpaoF8DlQIU0VpcR7GUNaiftaAdgU7CtDTBjohGsk6pN5AwOreCsAFbge01h88x5/unONcDfy7+QzKcOmTAq5F9uAbkIKew0jEXv2Mc5M03ISAbm4hbkoSjUgwUEcOnhiFPzsCW0cDuvtAK6jFUK/7ZJvFQ5CpQpMNdkmailYQi3QG6LChrUOqB02OQcaCXCxNUEwjEpNFaFgkYmSytyIqdy8y0edK208hBT5ytTKWM0XkBNg22Eno2AA3FeA5DQceh7iSpJB2cBPga0jlwXYh0QyFTrnWjPHPQzQBSyGNBWzpYuwlxX31HVZrytArMWHDhkWhjrQDSyLbgDQiGBSvdCNlEHtBCrAnp4hHB7BrHjkg6UCuFdpugNc/DJ8+Bdv6PQoR1JTUIOhKQ7JRi8zxoasA9aJcN0SJbLwAACAASURBVAvkFeRaYKoMYxPwQg08RzSA1daC/FwYTcCwaFSAp4F9iFBIIV+42XE57uzjEzHTh4aIRmu4MaQanYR1FR5oEqHy44fBqVnYdUgqMRKmchBo0BbkC9CaE8HShhgDCx0wXpbuxDUNYXQ6h8BghIBhkfEQA90Apzv+zG4uYiOagQISJYiPgz0IwZj0DlSBhAz35uE2BV8qQmUipiUBtUmo16U+YT2GagiRA4ns6fBg24Jkk2gNjitGQm2fXZ9gNWOEgGFRiREX3CDii0/xympBMw1AABI1cMfAnoT6JFQnwJuGYBJqJfgZLWr8Q98A10th1SGhQbuQzooQKPtQjcQA6SrItoHTCAawHTEeptKrt9HIXBibgGFR8YCXGj/XcrYKHiCRezWgNg0kJcinGMJEBcI6lIuQsGFXMzAFn9Ww+2Cdja9zKcU+1apsCQZPgRVAkwXKhVwkxkLtIoZGG3p6YMwHZyFaH18mGCFgWFRiZJKPI0Jg9soPoiV8H7Ho31GDNZNizf9RWfL9n0HiCm6N4P1J+CTwMeDFF6FznU+iScKNnQI4OXBi2SKotEQQtnRB3BAKlgt+KPkIF9Pv8HLFCAHDojKzHXA4veKfGSewH/h94HHg6qJEFP4T0qNwhlPAL26Hq4fAPgWfKcKuEejJSmhxDORbZe/vTUtBkpZucFIw6UsAUSYpN6+W53ZVrlaMEDAsCXXEOHimAJihCjyPTPzjnB1anAPaNnajsyXeMVDhhxGMDUF3N2TyEKXATkPOgqESYMvq73lQLEGl0kgjToCKjCYwG2MYNCwJHrKaj77KOcPAs8ydW/Au2yLV3EzH9j4+0WtTBF44CAcPigvRjyWHABfsFORykokYBFCchqEhKJelYlHCNqHCszFCwLAkhMi24GLqeSaAn7nnaiwdQybDm+7dynuSilPAkZcgDKHuQz4rk765BXIFCLVoALU6eKEUGw2r4FrGOzAbIwQMS0bAubcD5yID/JwCf+hZqtFL6PRxSuEh/vc7NP+goKrgxDHoaAVPwVgGJlugnoPyBAQ1SFalmEmoGlpG8rWP43LG2AQMKxYLeAdwcxM8+iSkMtDU4hDXFb1rUziqzkRFVv9SGVwXEg11P6FFKAS+tCNPqkbIsgdBtFrrCs+N0QQMr4qFRPktB92IJrClD55x4IdPwaG9I6QSeTLZFu524QTgpKXMWDoLLS0NYeCAmxQDYMKS0uRWDLWaJBEZIXAaIwQMr0oL8H6WXmVUSGxBP1CswBENXyjBZ74V88zz41QnYu671sIDqj6MDEu8QHOzrPyxgmRSJn7KlujBOIJyLNc1X/zTmO2A4VVRwF4avQGW8L4pTkcb/v1hqVIzUyPg8GPwkWPDvO3WFFcl64xOSpOSyWmJDbBtiDwZe60q2YgZB4qBGCcnmGlKaoALEIjnaDzy/yilXmw0F/mqUqq5cXyDUqqmlHq28fiTxRy8YfGpI249fwnvaSHBPxqJLXgEKQBSR6oUfw/4+hCcOFln/WYoeVJmbHxcXIBuRuID7MZMj3yZ9HbjGj5GE5jNhXwWf87ZjUe+A+zSWl+NCOv/POtvh7XWuxuPBxZmmIblogwc4zWWkp4HeaQS0RuR7jVtSJThjFCg8fwfgC89DoU8bLpCtgA6lpVfA04CHEciBesepJJyjRoiBNqX6P1cCpx3O6C1flgpteGMY9+e9fQx4L0LOyzDSmIpA2vu7m7mjbrGljhmyAs5WNbUFBxRipFQcwQpBlIGPhvD7gG4+e1QKoEdwuQkNDVBsgX0uNgGPE9KioWcDl3utmCvKSgALIxN4KNIa7gZNiqlZvI+/ovW+odzvUgpdT/SpsxgeJn7bt/OrfFJwv4iHUNVErWItTa02YpyAv6ypvkyMIVsDYolWe2bmqASQc2D7rTUJxwbkVyCegi1UOwBw8CQgk5TVeRl5iUElFK/gQjYv2kcGgT6tNbjSqnrgH9USu3UWp+VuGn6DhjORAEDJ0cZSXg88kKFJ6ZiDgFrAthEzLZmxZ11iLRkHqaAni6pSHzFFdKgxHJAa0gkRAOoeVKLcCKUVWkEOKUhYXyEL3PRQkAp9RHgncCdjQrDaK09GkVbtNZPKaUOI1WnTZchw3nRwN8+epgnbXguhMOI6g6N3gFTmrcCdyAxBO3A1l4YGoXUNgkQSuYhimT1L5UlWCiORAuYajwiRCMwCBclBJRSdwG/Ctymta7OOt4BTGitI6XUJsS2c2RBRmpYFTwRy+NMIuAoojq+hPQycIDBfvEGhDVJFVYKXBtG+6FSbFQdbgiBg8gWYnM2Q7azgxNHjy/V21rRXIiLcK7GI3+IGHK/c4Yr8FbgeaXUs8DfAw9orVdzhyfDIvAD4K+APwM+cwBqRZieglRKKhERwdigtDJzfUBLbEA/Yhh8XXcX99x1VsuMVcuFeAfmajzyuXOc+xXgK/MdlOHy4swy46+VNLL/dxrXSiOJQCeAfwZe1w9Ng3DFjgSlUkDRB1WHtANeIFuJIrJPtYGOljxrt2+dz1u6rDARg4ZF52IEQBLYDNy6o531rVnyjsKJfKIgJqsUdQUvHhnkB0Pw/To0vwBXbFHUp2BiWHoOOJbYA4qIW3EUcFyH5rUdtKxbQ2tLgYlJU2zQCAHDimIdsMuCN2wtcFVHjmt3dtDakcayA1QcYNUsypMTJMM6ldYEOx4P+NwoPDQKtx4JiKowfAy6m6TYSBiLEfAkkjOwpamJbW+8me6NG3nTrTfzta99Y1nf70rACAHDiiANXA+8d0OBN65JsakvRa4jj9PqoDI+2grRUZ2oXOfIiyPkEj59XYq7t8PXR8VoOHJUoywpT16OIKie9gRMISHDTj7PhmuuJd/VxdadO8AIASMEDMuPg/iRb7fg9uYkG9os7KCON+HjeQnqlkel6lEeC3jpQMDIcMCVPdJirL1JXIZfB54eELdhNYLpChCLa+o4pzMH87kca3fsYiQCLzBFxsAIgVVNWxp0ANPh8tbcixAj33diiA5P0X4KkkqjFSRsRUxMJYjw6tBfhj4g6UNtXMqJ39wBPxqFR+vSCbkJKMUSY/AjpA2aB7Tl8rzr1ttJNTczuO9FnnzchK+AEQKrlgfecwvve++dpBJJvvSZz/NXPzzExDL15tKItf8p4HApwCnJqq1mPVqRvgXbgC6gJSH9A8YGwStK0tEAYvybqWd4DHgYqWQM0N7Rzvs+8EFqvs/kRJFnnnx6yd7jSsYIgVXIOmBr4hTrCvvp3LSZB37lHdTDf+ALP+6n6C9fBHfAuasRDyKr+R3AJiBbgiApE7zfk5LkLjL560jdgRcbz2dIJFN0bdpKXYXEXpFatYrBpFWvStqB0ksn+fFX/4XHvvN3FHJ1/st/+V/4tftupC27MttyBEgKcIZGjsEYHB+EE4Ni+JtA1P9JRJCMIEJghkImy3tuvo1Aa6IgoF67mLrHlydGE1hlNCOVd2tHI4ZLFUonjzJ97O+59s538fFPvJOfev9dfOSB/8mzQxMrLsluHFHx04COYLLRePQ44gIcQDSGGqI1zBRCUUBvSwu/+NFfIFKKkdFRHvnhnMmtqxLVyP1Z3kGYLMIlw0b21NcpeIMFbR1Q64HUjgw/9ZH30r7hWsYrGT7/Z//Cp/6/b1CtL2VNoVdHAVcirkSFBAA5yKSvIkLgKGcHJ3W1tvDg//s/uebt7yRKKB557DHe9dP3Uamsuu3AU1rr6888aLYDq4wZv/lRDQMRRMOQHwT/cJXjT/2AyZNP0Lkm5GMfeweZTPJ8l1tSNHAA6Vn4JNKm/BRiCIyQGoRzrSZuOs1Vd76JWlxDJ2wixWoUAOfECIFVSISsmj8BXtBQG4bkIdjz5ZPs/f43mTz8MIXEKP/jV+4gk1pZO8aIRgViJIMt0/ipeKURcAbXgrd2JHDsCDeXYGh4gG99wwQIzWZl/YcNi4YCbujJUNDw+FCVCWRCBUBVw/ox6KhrXlTj5FofpnvrJJs6Lf7N9Sk+/+My4RIaCLJILEAHcA1i+T+J1Bc4ikz8NNCJ5BjEiA3gzK5CCtiYyfBzH/+3YCsiNAePHOQP/vCPl+aNXCIYIbBK+Pcfu49PffJjKE/zlT/8HL/1F1/jxVLA0cbfJ4GrytB6CPwjA8QdBXrym/jVT3yQv37izwi9pSk4flPjsQYRUHdshTWdDqMjIQcOw6lIhFcdsQmMNx5Tc1wrmbD58D3XsmXHFmq6yvD4NJVqjSAwZYVmY7YDq4Bda2xuXDeNpfohWeGWe+5k++uuAUStHkfy7PuRDr7pMiRqNRKWx+FD+4j10qgBVyJVhrchRUPSQGUSyhMhqQR052B7AXbn4C05uA2JDnQQF+FsFFLRpqZi0s1NpNIZMqksx48eW5L3cilxsX0HflMp1T+rv8A7Zv3tPyulDimlDiil3r5YAzdcGLub4L6uiFxtgPrYcyhrlJ6dPeQ7ml4+5xRiI/CQ1bc4DOXpGqOjQ3z/+49xU3e86KuFg3guQFyY63Ow04ZwCg4ehkNHQLtSO3CwAvU6rLFlSxBzdjtzC9jYbrNz51XkmgpM1yY5cvQAf/flLy7yO7n0uJDtwJ8jlYT+8ozjn9Za/+7sA0qpHcAHgJ2IRvddpdRWrbXJ1FgGuoGmafjxfqhY+xgNxrjxbe9h3aYcv3X/+xjvn+DBx54BJNGmHdlvDw1BcrzElAW33nEd2fUxD//FU8TR4nlyNRIDsL8x7mxZbAEDkQT+tCH1A21HJv3J8HR78blKV6UVNDXZbNm2FaejBWoek5PTPPKICRU+k4vqO/Aq3At8sVFw9KhS6hBwA1KezLCEdABXIStkUx02HoemZ0YoZv4J36nTu/PtPPCxt3BsdJB9h4cIkGSbVkDthb5rXdbftJXee36FrUd9/s+//nnCaPH20grRAIaQtmcuYvTby2ktYXJEPAA1JI+g3Pj743NcL2NZ7Nx1Pb1X30JUy1Ib9fnnv/vWoo3/UmY+Wt4nGm3IPq+Uamkc60UMuTOcahw7C6XU/UqpJ5VSJpVrERhT8F2kuOYo8FIRJgdh+MQoY8MnCUvD3PPen2LLzu2veN0wcNKHwFbY+Sa0nSC/fj3KWtwNwUxjkH4kFqAfsVWACIEBJNNwFBECU4j2cq4qtllLsWlzL9m0i+dVGStO88d/+teL+RYuWS72P/vHSPWn3Uik5u+91gtorT+jtb5+rggmw8WTVvCuHT18/Tfv4EM3KMqWxNCf8iGYgqAUcPLQXqb790DxCL/2/hvZvWXNy6//CZLNV657VItlAuXgtLTwy7/xPixLneu2C0IJEUJPNB7TyBbFRYTZIWTSDyHuwmeBZ+a4jgIKtkVrbyfZbJ56zed3PvU7izr2S5mLchFqrV8u266U+ixS7xFEgK+bderaxjHDEtCchvvf2sOv/4cPUGhP8IY713LvV37Ad/++n6ODmgeHNNe+CJvTI7j2D3DSzVx107X8wluv4FPDo/QXRd1/GvjxIzV2d5+kZ3iM1KaN/K+/9AC/99/+ljhefPNOhDQXKSL2gQARTtOI7WAmOOhc1QFtC+58cztXXbWTwdEJSp7H33z1m4s+7kuVi+070KO1Hmw8fQ+yNQMp8PK3SqnfRwyDW5D/n2EJyFjQWRrkob/+NIlmyPZ08vZ3Xsd7fur1nHjxON/+2gFe2l/hxB5NVDpCc8+z9HT18bP/8aM8++QQX3ziJSpaVtt/OAxbD44w/cRTNNNNW0sBW6klbU/+1DmOl87zumZlsXXnDnLd3Uy5ad75lnec5xWrm4vtO/A7Sqk9SqnnkRTvXwHQWr8AfBkp5vJN4N8Zz8DSkABaalDZC/UXIDoMU8+NMPjk86ASrLvzVt7xa3fRuauToZMwehJOHTiCiiZwmkI+8N7NdHWkX77ei8D4/jK1J/ag9hyElybY3byycgnORZcL7d296ESKkycHONQ/ttxDWtEsaN+Bxvm/Dfz2fAZleG3YiGV9IIaBcegKIB6BugN7j/YzNvEIPfe9leZd29l6wwDHHh9nZCxkun+E6UPP07bL4fZ3v4Xev9nLsZGTxMge7rP74cH9/0r3Z/+VzKZdPDG68nPwFdDUnGTdpp28dGKMG9/8s8s9pBWPCRu+TBhHXGpPxFCbgg1TDav6UThRHODKvj3s7lrDPe+7He+Ex7/8wzPsfbRK15pnKHQUoHsHv3xLB4ePDDJQEqX/ezMX94D9e19xvxRnx+qvBByluPddb8BNNvPO+4wAuBBM2PBlwMx+y0OMel8B/gVJt90fwpGjmrEfjaFPTeFkurj+3a8ns3MNx47BkR8e5+TjjzG650luu/M6ejrynM8HkAV+OpNatPczH9YnFDfccBP/1+//Cf1nhhE2sG2HbDa3tANbwRghcBlSQSy1zyFReLUKOMdKBC8cY+T4CJn127jpjdvJNbkcOwjHnznMqSP7ODm4j7s2RxTOs/W/Dfj3V19B7wrSI2eGsq0nwUtHhvm7787lPBR6e9dy77veuzQDuwQwQuAyxUPKbj2L1AwYGpiksu8QE4MnqDoJ7vjQ3Wx4804Olh38oxGJoy+hxvdwx40Fsplzz+4UonmMPrmX39ucWJo3cwGsTVnYQFxo5eO/fU6TFbZt09e3ltff8LqlG9wKxwiBy5wqohF8d1Cz77kxgokJhk8MECdbeO8Dd3Dt7g7sE5A6FZIuF+kuKBz73BuCdciXptmCW3a2LdG7eHXaCnl6OpKkgG/sGXzVczs62nnLW+5gePjVz1tNGCGwCqgBj3rwxecnGD/qkRmp4IyWuGLNFdy4tYWwCCcOw8BJeGHPSTzv3DkCZSR4RwcQja0Mb8G733wLe07WON9oXNflhhtez913381PfmLCV2YwQmCVMAE8Mg7P750gcWyE6KWTjD6xj9p0iUodpsfhxEEYHnAouHCuCGEfyeKraTj14vnCdpaGN912G+ULOK+rq5Nf/MWPMjg4yHPPPbfo47pUWEGmHcNCo3hl4c0h4O+f2E84NombyzHtT/PoC8PsKsE1aShOwK7bt/EzbYo/+PqLlGtnxwfaiBAYAqKRJXkb5yW6wHC0RCJBT88ahoaGGB8fP/8LVglGCFyiKCTH/tVi4ebK/v/xWI0jY0fRiGpfR/L2d0TQ2WGz+5a30td6BX/76H+lfOLsiTKjIBxDtAILlrU/wTU7dvCXX/67Czp3eHiEP/3Tz/Ge97x7kUd1aWG2A5coFufI0b4AhpBsvQpi6d8DlDX09jSTbOph4/ZdvOOeO0kmz+5GFDUeQ4gQWe5+Re96+9t56CfnyjJ4JZVKhUce+REnT548/8mrCCMELlFiJMd+ITgBHKtCPt+OEyh0GPFv3v8zZNJnBwR5yOQvcloTWE4ee/q1VQoaHBzii1/80iKN5tJkuf+HhovAQgo5bILzRvddCDXg+3WY9CLq48PUxwdY35XFts/+etSQEOUxxNi43F+g7zz00Gs6f2Jigu997/uLNJpLE2MTuASxkNJhNyKFNn+CqPfzYS/w0JNDNG3eQ2tzhuSabTBHi7qQ0yW+NeYLdDlg/oeXIBoJAvKAXYiRbr5CIAC+eaRM5h+fYuNImaB7P743d4pQDcnpb0bKgs9V899w6WCEwCVIDDyPhAXPlOSaDwlkhd8LTOwfpzD8NEFqL9Xa3M1IY8QmECKZi4ZLm/MKAaXU54F3AiNa612NY19CekSALAhTWuvdjarE+5FakQCPaa0fWOhBr3Y0vNw56LXU/00gGYB1XpkGHCFlvCpILT89ceYZZzPaeI1ZRS59LqrvgNb6/TO/K6V+j1f2gjystd69UAM0nM1a4L2If38QSR8+d86c4CKVYTuRiT7I6TiCGNlefKhg8ZVKzOgFBN94iHFwcUuPGpaCefUdUEop4H3Amxd2WIZXQwPX23DrbigWkjw05vPJPXrOrrwzpJCeAm3IBK7wSsldBF7X2cTBk0V+GEXMvRF4JYMsf5yAYf7M18PzJmBYa31w1rGNSqlnlFIPKaXeNM/rG+ZgDHgogsPHoaM14PXrNTee5zV1xHbQDtwNrD/j7xo42l/ivt2baEpf2NSeiRkwXNrMVwh8EPjCrOeDQJ/W+nXAf0QqDxfmeqFpPnLxhMie/NgUDA/EJH3xEvS9ymt8RHh098B9Nynu6JZmnrP5p1pI17p2kgl7jivMzeI1JjMsFRctBJRSDvDTwMvhV1prT2s93vj9KaRHxNa5Xm+aj1w8KaT2fj2GiWHAg20tUt/91SgCNRfaOh3W52zOLLB1APjct5/lA9dvIJ9aOQVDDIvLfIy7bwFe1FqfmjmglOoAJrTWkVJqE/K9PFenKMNFkkb29w4Q+BBXYW0zdJ6jpt4MMVCLILIslD13INCTxRofv3INf/XkMUp18T3sQFw+l+Kqr5Sie00TV+64kuZsE5s2bWRoYIi//uJXl3toK4YLcRF+AbgdaFdKnQL+q9b6c0j34S+ccfqtwH9XSgXId+4BrfVcTWMN8yBDo9qvhtgDvwx552z1fi6qPnjYMIcQADEYlo7vY13oM4a4D9sRd+ClUIunpz3HTXfcyptuu43d111Ld1c76YSL1pqU45JMunz3W/9qhMAsLrbvAFrrj8xx7CtIsVvDImI1HnUNeOAoyGSgNwHNwatH8JVq4Flpel2PAv5ZPeLywKPfHuJXPrSJT37pGCdqETZSR2Cl8dEP3UU+n+bFffv41g8P8OlP/Qb3vOudtHZ3kk5niK2YlJPC8+pEYYj1/7d37jF2nNUB/51vZu7M3Me+3494ba/jxEkgCTRNCwSphUKihtBWQvzTAkKKWkAFqVSkRa2Q+g+tBCqVEFUQSAGFoKLSQtWHgJQWIYVQEkIcEvIkDzuOH7G9u97HvXtnTv84M76bjddex7u+9+L5SddzPfexZ+7Md+Z85/WJI603eeHAc+0WvaMocj26DMGWHfcx87yZQtOHsAYzVdh74sxLdec8twCHkpixcag9eYr1PbkWAGkq79jr8ahvbcv3YWvKfY32Tgl6Mvn2DMG7br2Wr91zLy+nkCQJ77i6yof+5A/wxUMWD7Mwv8jKcp1Fp5SCEkHikTqP/Y8/xr//211tPIrOo1ACXUiCZQoGwOoyrJyCag0qMfSfsLv2Rvk+zwIvSci+2iphyKuUQBkopaD1Raqq3Ax8EfhrbFWi/9mOA9okUQgLdZierHDn3Q+z0EhRbLrymb//G1aOPM/BFw+z2mjwyBOPcvToMVR9akGF3t4eBofGeeSZJ3nyicISWEuhBLqQJhajF+BUAu4o9PVBHMAoMA4c2OCzR4Dnjp7guskG5fiVr9WwO37Vh5WFeaqx8tZpuOtxeCSFd2N+h29t03GdiyN12/73w4unCxyvGYJ7vvpJDh9+nvvv/yFHjr/Mfff/iO/c12AV+41CgYlYmJ2t0j+yg+cPd6OLc/solEAXskwrSacOLK1AfQnKJUspPpsSALjvvuO85S0erw+FH6OcwjIJ92I9CvZeBuKlvPNW+Ku74c9T+ACWizC+fYe1aXIFcOt1cNutb+Ufv/B5nn1pjocfhhfqCvrKaUsTeHIBDuyf47Keh9shckdTKIEuQ7FmHicwBdALJCk0FkEDM+cr5/iOB5pwxAu4ym/ST5MAmMESOgaBid1QnqgyNNnL3nsOsYByJVaj8DFMGTyy4bdfPA4+B3ff/b88+DRnTZnOaTThxSJW9Sra3Rim4DWwgBX8rGCKQBUadeu6G2NlnWdL/H0ROLCwQrzSZABzuNWA/uwRj0Aj9pHegCtmhcMCf4opl6PA7PYd2nnx/HH4/iYVANjFXiuu+FdR/CRdSBObDuTdglOF5jKkqQ3ocSyufzZeeAb0uEUahjFfwCQwNgmViRipVVkNHNfeAH0e3Pw2+LLAd2nVibebs3VaPhOeB9VzmUmXIIUS6EIUc/AdxZRAQ2F1FZyDWqWV3HO2k/vkUXjxlN35p7G6gyv3wtU3wdDuCQjLLC6uMD2mOIGvfQ+u2wcf4rV3OW4nATATOXbMFKsRr6fwCXQhit0FX6bVZsz3ISpBrQTDizaoD7BxR+KTmIMxwLoDlYG+CRieAj8MaCYRQcMnTmDagx4HX/m5fWZpuw9wiwkcvH7U47rXDZJ6A7D/F+0WqaMolECXMp89FoGmQFgCvwTlCPodDKRm5s/xqlQAyPbn0wkfyzuQEFwIjZU6zjVZObHE0hGY6oFAYO6wtSfvhq79ebMTJzAc+Vz3azu45oodHDi2mU4JlxaFEuhSfCwpaAUr0hAFp+BVodyA8ZfNgbeIlXKuj4zPYYN5CXMmJoB4kOCIm4t4y3VOHDqBHFMIYP9B60p0P52hBDwxZ2YD85GUsd8kFfs9ygKVqqPcF7B37w5uevvvMjk+wvIDjwI/bKPknUehBLqUBmaanyBbKbhpjkEiiHpg1wL42U2viRX/5CsLZiUHHMIGfxVTBCSwPJ+yuHyEpA5H9oO8CIdfhHsxH8QTF+0Iz4zD7vI3jnnEoeKpDfySAE5oeuD5jrBWY2hskp1XXsmV+67hN37zJspxlSNHVomx367AKJRAl5Jg3YZ9YFhhcQXCBmgJ4hpMjkB0BFYaZg0MY1ZDnnLs0VpBKC8QSpZh6RDMN2B1AU6+AM0DcEhtbYMX2Hw4bjsoAaOe+TFuvHEWUPxA8T3FSRPnIprOIywPUh0cZWJqhpk9+7hs5yzDY9M0VuuEUUzVs5LqAqNQAl2KYusB1sjm/SnIKQh88MsQ91tF4dhRmE7tfWn2uSY2Dahk/w/IqhJPAgK6AqvzUD8GS01zQj5N++6eDqh6MBHCxLggzmf37F7K5QpLK6dQreN8IXUerhTTPzTJwOgkk5ftZnxqD+VqDfwIaYIf+8RVgbmtTR3OIzHCxnUbnUqhBLqYPEpwEphLgHmo1EwRBDH0pbAzgfpxOL5m6WDBlIBg04K84OjYS1CeceSiWQAAEElJREFUh0YDTs3ByVMWinwme9/FxMMGVimAfh9mpwImJwK8oEJf3yA3vPktNFNheWmJJG2Q+ornl6jUBhmemKZ/ZIyo0ktUHgA8EvXATwjLFcrVMsydyV16/kgmZ3/2vIop526abmymqcg01m58FLvu7lTVz4nIANZabAYrTnuPqp7IOhB/DrgFu9ber6rnt2pkwaYRbMAolj7s+xBWIIqgVIYwMvO/7ziQZg5AWpGFheyzy8CLh1vWwTFsunGQi9tVyGEFP8MlqEYwOeUzMhqwZ88sg2OTnJpb5djxeXbuvZrVVSERAZqop5TCkFrPEH65igtrNJMmCWWcOFSbpOpTrvTSN9gPBy9cCQg2RenD0rf7sdqL57AS7G6JQ2zGEmgCf6aqD4pIDXhARL4LvB+4V1U/LSJ3AHcAn8Ca2e7JHr8OfCHbFmwTQmbWO6hUoNoLYQDBKkQBTNYhasDiMsyvZpV1tFYREkwJNLALYh7T6o9gIcHnuThKwAP6BIbKsGvGY3DEZ3JqgsHRCfZcfhXVvgEaDeEb3/hXUr/E8PAEqymoS0lo4kcxpVJESkCaejgvQsUnQUhUUSeU45j+/n7OXmK1OWJsKhVhNRcV4E1Y1uZxbArVxBRbTOd2Zt5MZ6FDZJ2lVHVBRB7DksZuw9qOAdyFlZp/Itv/FVVV4Eci0ici49n3FGwh+ZqEy7QWB/XU/pNkW0eWPxBDM7PpE8w/kIfXgjXPl7AkpGexi3jtIiXbSa4AxmswNuKzY2aYkbFBJnbsYmh0grGZPVR7BomCkJnZRymV+5CoSiABqQOfJi7wQUqoWu8lEZ809RAnOKeI84ijEkMD/Vsicx6WDLKHjymDHqwH5EksolLBBsxzdGai1Xn5BLJFSK7DwsWjawb2S9h0Aex414aSD2T7CiWwDTSwMOEK4CvoKqxkdQSyCv4q+M6SiFZc1myUrASZloNQsMHfwC7WJ7GTup0KIJ/KlICaByNVmJ0pc9llI1w2u4vRiSkmZ3bTOzzG0NgUQaWXSqDc+q7fp9o3gLoIcSHiCUITnIeqQ8RBpghQhwgIgiLEYYnhwYEtkT93tDpsIOUFXbmSbWbPG9l2D1Z3cfYF3i4+m1YCIlLF+gd+TFXnbepvqKqKyHldLyJyO3D7+Xym4NWk2N1mEasmTJuwWs8sgTqUViFOzFnoqV2Mc9iFuICZ/qvY9OAkNvCfw7R4eoa/dyHkTrTcaomA2IO+EIZ6YWqqzFVX7mVmZjdTOy9nZGqKoclp4t5Bwp4h0iAgaM5xxTXXIF5AgodIgIiP0CBJwBOHqkOdj+BwDkTV/qYn1CoxAwObacm6ueNJMSsgjwrkSjZ/QKsJzCTmN+i0u+GmlICIBJgCuFtVv5ntPpyb+SIyjjmSwXxJ02s+PpXtewWqeidwZ/b9RauX14hiA3oZWFboXQZZMtM/bUBzFZI6JAvm9a9j89Xc7D+BXQQxdsd6ATPdtiMaEDqoOGgmUBUoe1Arw8iAMDIWsWPXDLN79zE9s4uR6VkGRyaoDQ/jxz0QlEnFA22ifpOEEoqPOI8URRRSFQSHYhmUiuIQs2ZSSNIUPCEMt2YtZY+Wc1Cx30+ybT49AFMOS5hPoJ15FhuxmeiAAF8CHlPVz6556dvA+4BPZ9tvrdn/ERH5OuYQnCv8AduHh1UNOqCegC6A80F8W5OgmUBjGU6dtMVKTmLa+gRmQWRBA3zMmjjJ9s1bo5JjrOxoLDWJPIhjGOwXxkaqjI6PMLVjDxO7LmdgegfR4AR+3wgS9SBhFVUfRSDoY35+jsEoAi21PP8CzvdOT18UQBVJBJXMSgISF+DH5S05ntwKKNPysYDd+fuxqMEcrQzNp+hen8CbgD8E9ovIQ9m+v8QG/z+JyAcxC/I92Wv/gYUH82P+wJZKXHAawS608ex5PYUTixAlVgfQaNodsd6AA6t2QT6JhfzyAqIlWsktdbbXB1CpxOye6WNl4QQlv0mt5jM0VGV0dIyJqRl27X0dO/dcQe/AGKXaIEGlhueFZvIjNFNYTeo063VUUyQrExK3vrWqrPm3hRNHGET09GzddCDPZ0gzCY5jv2OTV/6WS2z99Gqr2Ex04IdsvAL1b5/h/Qp8+ALlKtgEEa3kjXnMvF+sQ1BvrRMQYneopzFN/SzwS1rRgItJT62Xq668kvryAQJvibgc0Nc/zPjkLsandjO96yqGx3cSlvuQsIKEZVABAjtITRFxpJoizuEkD45Ca+BLphwsh0+F0/ud8/CCgFpta5RA/lcF86usYqXbK7QyMXMu9m99PhQZg11KbgXE2F39GK2BX6JVZdiDXZAHgJ+yveb+uQijmLGxaepLEJQWCWOfnoExJnfvZXRyF30jU5Qqw7igAl4WfBMBddZcVD0855Gq4sThOYeqIiietAZ+fsdSMiWg2VZ8PK/EwGA/w4MxR1++sLy+/C/6tPIBTvHKqEE3UCiBLibPFFRsfr+EndAKNk91mIkaZ6+9RHtN0jiuMLljFyuLAeLmiashA6PTjO2YZWB4mqgyhPplmkQ48bNQH6CCqiCqOOfhMitAVch9yhuZqiK5NZC93w8Ymxzj6qt28/0fXHi71AA7D2H2fImWVbB6wd9+cSiUQJeitDLQcodUPkeNsNr/flq9A1PaPyet1nrYfcVVLJ3qwckSPf099I1MUukfJa4O4PxelNi6m3gWTDw9xFUQTRARPC+3eRQQZAMNINKaLDgcqOA8n4HBIa553TUXrATmsMGfJ2t5ZKFaTAEHmLV2tmXhOoFCCXQxC9hFt/6O44DDmDLYiVkDnXAhxpUK07tnaaz04GhQ7ukhrPYjYRk/KIPEaHZPFdHMlFfEZVtMLYg4VCws2EqazlDNFibIVJ5zliiURQdEPEpBxNTkhXdKrGMWWAmztnL/S+bFIKSVOdjJFEqgi0k4c9lqiimHxTX/P3yxhDoLfhjSOzKONmOQBC+IUS8El0fVHc7ZTDoBlBRE8RDEpQipRQXkHLPtbI6kWOJgXj5NCr5YdL8Unq0p++ZZwaZZeev2lFbeQJ5S3OkUSuBXnNwR2BHeaefhlSJSibNOJhVUPZvfZyY/qoikJCRImiIikPkGRFJSTXEO0jTFyca+gDPhez4u9SiVQqJoaxKGwH7fvCfDEpa3kScMdYNfoFACv+IkdEZtu+d5hGGIOoeUyhbqkxBSl6X3rXmI+QJS1iyJLunpzD/IiiDyXmObQARUU1QVP4iIoq1bgCAP0XpYnkCZVgSm0+oEzkShBH6FiLHmoiF2NwJ4AJu3tps4jhkdHUUJSNUj8Hwcko1yM/tVldzLFyAgXmuMi0eaKCJ+NmXwTk8d7EvW2Douj97ncXxFNCXVBuqU1Avwwr4tPb4Us7ryJKEImxZsTeuS7aVQAr9C5Dnq+bJieW57JxBFEQMDg9YMFWdZ/SKn787rcxUdZ7L1LcyXJAlpmsUNZJ1j8HSoQNZ93GyLVBXnecTx1i9FlDV34jBmDVQx522nUyiBLkOw1YOf5dWmZl4GfDR73kkrBZVKJWq1GkmS4HkeaZried4ZFcDZOd/35wiCl0UXPAJ/ey79vCuTjynjTqwVWE+3JDVdcnz09j9GNgiAR1hbp48DbwPegOUFQCtisIKZp51ygn3fJ4oiksRi/fmxbRTj3whTHsGaXIHN4nDic3qCoK9FkWyOvJjoZS5eW7YLobAEOpRDBzde4uMU1gL87VilVoLVav8Cq1W/DMsabGDFRSdpv4PKOUcQBPi+v2Yun5vzWWLQJgZmmqb4vofnnY96s8xCVcERoC49b+VzLm555xv4r+88eHqaAt2hAKBzbhQF6/jpj+/bcFBUMDPzp8CDWDdgsDnoKaxY6AnMLHWY5dBuSqUSfX19lEqlV1gCYNbA+n0tWk4+5ywq4Jy8YrCdFyJ4EhJFAeEW/jDPHH6OKy7fusKki0lhCXQoTx09vuFrg8A+zAF1gFZDi1VaCiFvdhHRGfPS3CeQpikuL/yRfICbaX/uu7PL8gDXv3GzCsFHSEGaRGFAf38/Lx06sfmDOAuP/+xYxzhhz5fCEuhQznZZN4EdwLti+C0sP93RKmHNY+x59tokLZ9Bu4iiiMHBQZJkfY6jnMdjowt2M8NvbTs8iMoRk1NT53UMZ0PTbBm4LqSwBDqUayeHeejgmSP8Taw5SHkFZivQu2jz/gNYssqLWK7AKBYq7ITMtTAM6e1tmcsbOT23H8tODAKfgf6eNsnQWRSWQIdy+Z7ZM97ferABnQAvK7y0aCb/pMDlHlyNJQqFWKLKSvb+i72C0Ho8zyOO4yw3QLdACbzWS9eajoRhQFzemjZj3U5hCXQoPT21PNf1FfsjzBLwaDULBQgVJLEOrwOYj+AoVu7aCWvj+b5/WglcCClNgsAHGtn6AoLIRnZ4PjFaN7mSJkVv2xaynfHSTQshknfNPtZuWS6AIbpbfuj+Y+h2+WF7j2GHqg6v39kRSgBARH6iqm9stxyvlW6XH7r/GLpdfmjPMRQ+gYKCS5xCCRQUXOJ0khK4s90CXCDdLj90/zF0u/zQhmPoGJ9AQUFBe+gkS6CgoKANtF0JiMg7ReRxEXlKRO5otzybRUSeFZH9IvKQiPwk2zcgIt8VkSezbX+75VyLiHxZRI6IyCNr9p1RZjH+ITsvD4vI9e2T/LSsZ5L/UyJyMDsPD4nILWte+4tM/sdF5B3tkbqFiEyLyPdF5FER+bmIfDTb395zoKpte2A5L08Du7A0958B+9op03nI/iwwtG7f3wF3ZM/vAP623XKuk+8m4HrgkXPJjFUp/yeWdH8jcH+Hyv8p4ONneO++7HoKsc7rTwNem+UfB67PntewYs997T4H7bYEbgCeUtVnVLUBfB24rc0yXQi3AXdlz+8C3t1GWV6Fqv4AKy9Yy0Yy3wZ8RY0fAX3ZEvRtYwP5N+I24OuqWlfVX2IL5N6wbcJtAlU9pKoPZs8XsLVhJ2nzOWi3EpgE1nbPOEBndcU6Gwp8R0QeEJHbs32j2lqG/SWshqfT2Ujmbjo3H8nM5S+vmYJ1tPwiMgNcB9xPm89Bu5VAN/NmVb0euBn4sIjctPZFNXuuq0Iv3Sgz8AVgN3At1ljpM+0V59yISBX4Z+Bjqjq/9rV2nIN2K4GDWM1LzlS2r+NR1YPZ9gjwL5ipeTg317LtkfZJuGk2krkrzo2qHlbVRFVT4Iu0TP6OlF9EAkwB3K2q38x2t/UctFsJ/B+wR0R2ikgJeC/w7TbLdE5EpCIitfw58DvAI5js78ve9j7gW+2R8LzYSOZvA3+UeahvBObWmKwdw7o58u9h5wFM/veKSCgiO4E9WGvGtiFWQvkl4DFV/eyal9p7DtrpLV3jAX0C895+st3ybFLmXZjn+WfAz3O5sc5f92I9P74HDLRb1nVy34OZzKvY/PKDG8mMeaQ/n52X/cAbO1T+r2byPZwNmvE17/9kJv/jwM0dIP+bMVP/YeCh7HFLu89BkTFYUHCJ0+7pQEFBQZsplEBBwSVOoQQKCi5xCiVQUHCJUyiBgoJLnEIJFBRc4hRKoKDgEqdQAgUFlzj/D2KdrBfc3ygdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "983gGKcwlSe8",
        "outputId": "0b266f4b-5ad4-4c50-e442-66e97e846338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "pyplot.imshow(masks[n])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f77e132d278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0Qa1UOue9TE"
      },
      "source": [
        "## Create the model (10 marks)\n",
        "- Add MobileNet as model with below parameter values\n",
        "  - input_shape: IMAGE_HEIGHT, IMAGE_WIDTH, 3\n",
        "  - include_top: False\n",
        "  - alpha: 1.0\n",
        "  - weights: \"imagenet\"\n",
        "- Add UNET architecture layers\n",
        "  - This is the trickiest part of the project, you need to research and implement it correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DukHZ3tqPofT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SETTINGS\n",
        "\n",
        "ALPHA = 1.0 # Width hyper parameter for MobileNet (0.25, 0.5, 0.75, 1.0). Higher width means more accurate but slower\n",
        "\n",
        "EPOCHS = 130 # Number of epochs. I got decent performance with just 5.\n",
        "BATCH_SIZE = 32 # Depends on your GPU or CPU RAM.\n",
        "HEIGHT_CELLS = 28\n",
        "WIDTH_CELLS = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PsU5TBjQjLbI",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.layers import Concatenate, UpSampling2D, Conv2D, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def create_model(trainable=True):\n",
        "  \n",
        "    model = MobileNet(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), include_top=False, alpha=ALPHA, weights=\"imagenet\")\n",
        "\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    block1 = model.get_layer(\"conv_pw_5_relu\").output\n",
        "    block2 = model.get_layer(\"conv_pw_11_relu\").output\n",
        "    block3 = model.get_layer(\"conv_pw_13_relu\").output\n",
        "    block4 = model.get_layer(\"conv_pw_3_relu\").output\n",
        "    block5 = model.get_layer(\"conv_pw_1_relu\").output\n",
        "\n",
        "    x = Concatenate()([UpSampling2D()(block3), block2])\n",
        "    x = Concatenate()([UpSampling2D()(x), block1])\n",
        "    x = Concatenate()([UpSampling2D()(x), block4])\n",
        "    x = Concatenate()([UpSampling2D()(x), block5])\n",
        "\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(1, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = Conv2D(1, kernel_size=1, activation=\"sigmoid\")(x)\n",
        "    x = Reshape((IMAGE_HEIGHT, IMAGE_WIDTH))(x)\n",
        "\n",
        "    return Model(inputs=model.input, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_snZ9o0ZBAiv"
      },
      "source": [
        "### Call the create_model function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqdeCC6UaSqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Give trainable=False as argument, if you want to freeze lower layers for fast training (but low accuracy)\n",
        "model = create_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9TfSSP51uPoO",
        "outputId": "cb6e176f-5737-464b-c019-20ec79ca902b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Print summary\n",
        "model.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 32) 864         conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 32) 128         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (ReLU)               (None, 112, 112, 32) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)     (None, 112, 112, 32) 288         conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormalizatio (None, 112, 112, 32) 128         conv_dw_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)           (None, 112, 112, 32) 0           conv_dw_1_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_1 (Conv2D)              (None, 112, 112, 64) 2048        conv_dw_1_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormalizatio (None, 112, 112, 64) 256         conv_pw_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)           (None, 112, 112, 64) 0           conv_pw_1_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)      (None, 113, 113, 64) 0           conv_pw_1_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)     (None, 56, 56, 64)   576         conv_pad_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormalizatio (None, 56, 56, 64)   256         conv_dw_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)           (None, 56, 56, 64)   0           conv_dw_2_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_2 (Conv2D)              (None, 56, 56, 128)  8192        conv_dw_2_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormalizatio (None, 56, 56, 128)  512         conv_pw_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)           (None, 56, 56, 128)  0           conv_pw_2_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)     (None, 56, 56, 128)  1152        conv_pw_2_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormalizatio (None, 56, 56, 128)  512         conv_dw_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)           (None, 56, 56, 128)  0           conv_dw_3_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_3 (Conv2D)              (None, 56, 56, 128)  16384       conv_dw_3_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormalizatio (None, 56, 56, 128)  512         conv_pw_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)           (None, 56, 56, 128)  0           conv_pw_3_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)      (None, 57, 57, 128)  0           conv_pw_3_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)     (None, 28, 28, 128)  1152        conv_pad_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormalizatio (None, 28, 28, 128)  512         conv_dw_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)           (None, 28, 28, 128)  0           conv_dw_4_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_4 (Conv2D)              (None, 28, 28, 256)  32768       conv_dw_4_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormalizatio (None, 28, 28, 256)  1024        conv_pw_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)           (None, 28, 28, 256)  0           conv_pw_4_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)     (None, 28, 28, 256)  2304        conv_pw_4_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormalizatio (None, 28, 28, 256)  1024        conv_dw_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)           (None, 28, 28, 256)  0           conv_dw_5_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_5 (Conv2D)              (None, 28, 28, 256)  65536       conv_dw_5_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormalizatio (None, 28, 28, 256)  1024        conv_pw_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)           (None, 28, 28, 256)  0           conv_pw_5_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)      (None, 29, 29, 256)  0           conv_pw_5_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)     (None, 14, 14, 256)  2304        conv_pad_6[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv_dw_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)           (None, 14, 14, 256)  0           conv_dw_6_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_6 (Conv2D)              (None, 14, 14, 512)  131072      conv_dw_6_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_pw_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)           (None, 14, 14, 512)  0           conv_pw_6_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)     (None, 14, 14, 512)  4608        conv_pw_6_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_dw_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)           (None, 14, 14, 512)  0           conv_dw_7_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_7 (Conv2D)              (None, 14, 14, 512)  262144      conv_dw_7_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_pw_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)           (None, 14, 14, 512)  0           conv_pw_7_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)     (None, 14, 14, 512)  4608        conv_pw_7_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_dw_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)           (None, 14, 14, 512)  0           conv_dw_8_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_8 (Conv2D)              (None, 14, 14, 512)  262144      conv_dw_8_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_pw_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)           (None, 14, 14, 512)  0           conv_pw_8_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)     (None, 14, 14, 512)  4608        conv_pw_8_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_dw_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)           (None, 14, 14, 512)  0           conv_dw_9_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_9 (Conv2D)              (None, 14, 14, 512)  262144      conv_dw_9_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_pw_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)           (None, 14, 14, 512)  0           conv_pw_9_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        conv_pw_9_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormalizati (None, 14, 14, 512)  2048        conv_dw_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)          (None, 14, 14, 512)  0           conv_dw_10_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_10 (Conv2D)             (None, 14, 14, 512)  262144      conv_dw_10_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormalizati (None, 14, 14, 512)  2048        conv_pw_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)          (None, 14, 14, 512)  0           conv_pw_10_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        conv_pw_10_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormalizati (None, 14, 14, 512)  2048        conv_dw_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)          (None, 14, 14, 512)  0           conv_dw_11_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_11 (Conv2D)             (None, 14, 14, 512)  262144      conv_dw_11_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormalizati (None, 14, 14, 512)  2048        conv_pw_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)          (None, 14, 14, 512)  0           conv_pw_11_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)     (None, 15, 15, 512)  0           conv_pw_11_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D)    (None, 7, 7, 512)    4608        conv_pad_12[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormalizati (None, 7, 7, 512)    2048        conv_dw_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)          (None, 7, 7, 512)    0           conv_dw_12_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_12 (Conv2D)             (None, 7, 7, 1024)   524288      conv_dw_12_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormalizati (None, 7, 7, 1024)   4096        conv_pw_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)          (None, 7, 7, 1024)   0           conv_pw_12_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D)    (None, 7, 7, 1024)   9216        conv_pw_12_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormalizati (None, 7, 7, 1024)   4096        conv_dw_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)          (None, 7, 7, 1024)   0           conv_dw_13_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_13 (Conv2D)             (None, 7, 7, 1024)   1048576     conv_dw_13_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormalizati (None, 7, 7, 1024)   4096        conv_pw_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)          (None, 7, 7, 1024)   0           conv_pw_13_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 14, 14, 1024) 0           conv_pw_13_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 14, 14, 1536) 0           up_sampling2d_5[0][0]            \n",
            "                                                                 conv_pw_11_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 28, 28, 1536) 0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 28, 28, 1792) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv_pw_5_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 56, 56, 1792) 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 56, 56, 1920) 0           up_sampling2d_7[0][0]            \n",
            "                                                                 conv_pw_3_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2D)  (None, 112, 112, 192 0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 112, 112, 198 0           up_sampling2d_8[0][0]            \n",
            "                                                                 conv_pw_1_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2D)  (None, 224, 224, 198 0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 224, 224, 1)  1985        up_sampling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 224, 224, 1)  2           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 224, 224)     0           conv2d_3[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 3,230,851\n",
            "Trainable params: 3,208,963\n",
            "Non-trainable params: 21,888\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2spcE4TvfEZw"
      },
      "source": [
        "### Define dice coefficient function (5 marks)\n",
        "- Create a function to calculate dice coefficient\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8H8aViXZuWz1",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "\n",
        "    return numerator / (denominator + tf.keras.backend.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nkp5SDM1fIu2"
      },
      "source": [
        "### Define loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FEOVfs19KVLv",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.backend import log, epsilon\n",
        "def loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - log(dice_coefficient(y_true, y_pred) + epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Thltv_akfOMS"
      },
      "source": [
        "### Compile the model (2 marks)\n",
        "- Complie the model using below parameters\n",
        "  - loss: use the loss function defined above\n",
        "  - optimizers: use Adam optimizer\n",
        "  - metrics: use dice_coefficient function defined above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "atPb8xm2qkK5",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=[dice_coefficient])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VTumZyg0fuVy"
      },
      "source": [
        "### Define checkpoint and earlystopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QNlQHt8DMy7h",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, save_best_only=True,\n",
        "                             save_weights_only=True, mode=\"min\", save_freq=1)\n",
        "stop = EarlyStopping(monitor=\"loss\", patience=5, mode=\"min\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode=\"min\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LxxbwvXEf07e"
      },
      "source": [
        "### Fit the model (2 marks)\n",
        "- Fit the model using below parameters\n",
        "  - epochs: you can decide\n",
        "  - batch_size: 1\n",
        "  - callbacks: checkpoint, reduce_lr, stop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "guFfKsEmq58j",
        "outputId": "83cb04bf-8fbe-4b59-ec9c-32657d9e3a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x=X_train,epochs=EPOCHS,\n",
        "          y=masks,\n",
        "          batch_size = 1,\n",
        "          callbacks=[checkpoint, reduce_lr, stop],\n",
        "          workers=1,\n",
        "          use_multiprocessing=False,\n",
        "                    shuffle=True,\n",
        "          verbose=1\n",
        "                    )"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "371/409 [==========================>...] - ETA: 1s - loss: 0.3005 - dice_coefficient: 0.8292\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "373/409 [==========================>...] - ETA: 1s - loss: 0.2997 - dice_coefficient: 0.8297\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "375/409 [==========================>...] - ETA: 1s - loss: 0.2993 - dice_coefficient: 0.8297\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "377/409 [==========================>...] - ETA: 1s - loss: 0.2988 - dice_coefficient: 0.8300\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "379/409 [==========================>...] - ETA: 1s - loss: 0.2999 - dice_coefficient: 0.8291\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "381/409 [==========================>...] - ETA: 0s - loss: 0.2998 - dice_coefficient: 0.8290\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "383/409 [===========================>..] - ETA: 0s - loss: 0.3000 - dice_coefficient: 0.8285\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "385/409 [===========================>..] - ETA: 0s - loss: 0.3001 - dice_coefficient: 0.8281\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "387/409 [===========================>..] - ETA: 0s - loss: 0.3003 - dice_coefficient: 0.8277\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "389/409 [===========================>..] - ETA: 0s - loss: 0.2996 - dice_coefficient: 0.8280\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "391/409 [===========================>..] - ETA: 0s - loss: 0.2993 - dice_coefficient: 0.8280\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "393/409 [===========================>..] - ETA: 0s - loss: 0.2989 - dice_coefficient: 0.8283\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "395/409 [===========================>..] - ETA: 0s - loss: 0.2978 - dice_coefficient: 0.8290\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "397/409 [============================>.] - ETA: 0s - loss: 0.2975 - dice_coefficient: 0.8290\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "399/409 [============================>.] - ETA: 0s - loss: 0.2973 - dice_coefficient: 0.8289\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "401/409 [============================>.] - ETA: 0s - loss: 0.2973 - dice_coefficient: 0.8288\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "403/409 [============================>.] - ETA: 0s - loss: 0.2976 - dice_coefficient: 0.8284\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "405/409 [============================>.] - ETA: 0s - loss: 0.2977 - dice_coefficient: 0.8281\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "407/409 [============================>.] - ETA: 0s - loss: 0.2977 - dice_coefficient: 0.8279\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.16045\n",
            "409/409 [==============================] - 14s 35ms/step - loss: 0.2979 - dice_coefficient: 0.8283 - lr: 1.0000e-04\n",
            "Epoch 125/130\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "  1/409 [..............................] - ETA: 0s - loss: 0.1695 - dice_coefficient: 0.9384\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "  3/409 [..............................] - ETA: 9s - loss: 0.1820 - dice_coefficient: 0.8984\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "  5/409 [..............................] - ETA: 11s - loss: 0.2928 - dice_coefficient: 0.8107\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "  7/409 [..............................] - ETA: 12s - loss: 0.3201 - dice_coefficient: 0.7835\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "  9/409 [..............................] - ETA: 12s - loss: 0.2963 - dice_coefficient: 0.8019\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 11/409 [..............................] - ETA: 12s - loss: 0.2896 - dice_coefficient: 0.8053\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 13/409 [..............................] - ETA: 12s - loss: 0.2789 - dice_coefficient: 0.8104\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 15/409 [>.............................] - ETA: 12s - loss: 0.2810 - dice_coefficient: 0.8064\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 17/409 [>.............................] - ETA: 12s - loss: 0.2693 - dice_coefficient: 0.8156\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 19/409 [>.............................] - ETA: 12s - loss: 0.2738 - dice_coefficient: 0.8120\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 21/409 [>.............................] - ETA: 12s - loss: 0.2643 - dice_coefficient: 0.8228\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 23/409 [>.............................] - ETA: 12s - loss: 0.2559 - dice_coefficient: 0.8299\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 25/409 [>.............................] - ETA: 12s - loss: 0.2700 - dice_coefficient: 0.8194\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 27/409 [>.............................] - ETA: 12s - loss: 0.2674 - dice_coefficient: 0.8205\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 29/409 [=>............................] - ETA: 12s - loss: 0.2658 - dice_coefficient: 0.8212\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 31/409 [=>............................] - ETA: 12s - loss: 0.2740 - dice_coefficient: 0.8152\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 33/409 [=>............................] - ETA: 12s - loss: 0.2715 - dice_coefficient: 0.8176\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 35/409 [=>............................] - ETA: 12s - loss: 0.2689 - dice_coefficient: 0.8212\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 37/409 [=>............................] - ETA: 12s - loss: 0.2682 - dice_coefficient: 0.8208\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 39/409 [=>............................] - ETA: 12s - loss: 0.2654 - dice_coefficient: 0.8221\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 41/409 [==>...........................] - ETA: 12s - loss: 0.2630 - dice_coefficient: 0.8249\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 43/409 [==>...........................] - ETA: 12s - loss: 0.2624 - dice_coefficient: 0.8240\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 45/409 [==>...........................] - ETA: 12s - loss: 0.2614 - dice_coefficient: 0.8234\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 47/409 [==>...........................] - ETA: 12s - loss: 0.2575 - dice_coefficient: 0.8256\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 49/409 [==>...........................] - ETA: 12s - loss: 0.2631 - dice_coefficient: 0.8271\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 51/409 [==>...........................] - ETA: 12s - loss: 0.2610 - dice_coefficient: 0.8290\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 53/409 [==>...........................] - ETA: 12s - loss: 0.2623 - dice_coefficient: 0.8273\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 55/409 [===>..........................] - ETA: 12s - loss: 0.2648 - dice_coefficient: 0.8248\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 57/409 [===>..........................] - ETA: 12s - loss: 0.2635 - dice_coefficient: 0.8267\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 59/409 [===>..........................] - ETA: 12s - loss: 0.2641 - dice_coefficient: 0.8254\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 61/409 [===>..........................] - ETA: 11s - loss: 0.2605 - dice_coefficient: 0.8279\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 63/409 [===>..........................] - ETA: 11s - loss: 0.2604 - dice_coefficient: 0.8277\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 65/409 [===>..........................] - ETA: 11s - loss: 0.2586 - dice_coefficient: 0.8289\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 67/409 [===>..........................] - ETA: 11s - loss: 0.2578 - dice_coefficient: 0.8295\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 69/409 [====>.........................] - ETA: 11s - loss: 0.2617 - dice_coefficient: 0.8269\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 71/409 [====>.........................] - ETA: 11s - loss: 0.2613 - dice_coefficient: 0.8270\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 73/409 [====>.........................] - ETA: 11s - loss: 0.2706 - dice_coefficient: 0.8202\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 75/409 [====>.........................] - ETA: 11s - loss: 0.2690 - dice_coefficient: 0.8220\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 77/409 [====>.........................] - ETA: 11s - loss: 0.2672 - dice_coefficient: 0.8228\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 79/409 [====>.........................] - ETA: 11s - loss: 0.2673 - dice_coefficient: 0.8227\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 81/409 [====>.........................] - ETA: 11s - loss: 0.2662 - dice_coefficient: 0.8238\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 83/409 [=====>........................] - ETA: 11s - loss: 0.2639 - dice_coefficient: 0.8252\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 85/409 [=====>........................] - ETA: 11s - loss: 0.2626 - dice_coefficient: 0.8267\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 87/409 [=====>........................] - ETA: 11s - loss: 0.2621 - dice_coefficient: 0.8285\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 89/409 [=====>........................] - ETA: 11s - loss: 0.2601 - dice_coefficient: 0.8301\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 91/409 [=====>........................] - ETA: 11s - loss: 0.2608 - dice_coefficient: 0.8295\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 93/409 [=====>........................] - ETA: 10s - loss: 0.2584 - dice_coefficient: 0.8313\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 95/409 [=====>........................] - ETA: 10s - loss: 0.2614 - dice_coefficient: 0.8295\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 97/409 [======>.......................] - ETA: 10s - loss: 0.2642 - dice_coefficient: 0.8267\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            " 99/409 [======>.......................] - ETA: 10s - loss: 0.2649 - dice_coefficient: 0.8257\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "101/409 [======>.......................] - ETA: 10s - loss: 0.2640 - dice_coefficient: 0.8269\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "103/409 [======>.......................] - ETA: 10s - loss: 0.2618 - dice_coefficient: 0.8288\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "105/409 [======>.......................] - ETA: 10s - loss: 0.2598 - dice_coefficient: 0.8300\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "107/409 [======>.......................] - ETA: 10s - loss: 0.2577 - dice_coefficient: 0.8314\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "109/409 [======>.......................] - ETA: 10s - loss: 0.2559 - dice_coefficient: 0.8324\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "111/409 [=======>......................] - ETA: 10s - loss: 0.2546 - dice_coefficient: 0.8332\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "113/409 [=======>......................] - ETA: 10s - loss: 0.2547 - dice_coefficient: 0.8325\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "115/409 [=======>......................] - ETA: 10s - loss: 0.2558 - dice_coefficient: 0.8320\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "117/409 [=======>......................] - ETA: 10s - loss: 0.2563 - dice_coefficient: 0.8321\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "119/409 [=======>......................] - ETA: 10s - loss: 0.2551 - dice_coefficient: 0.8330\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "121/409 [=======>......................] - ETA: 10s - loss: 0.2542 - dice_coefficient: 0.8333\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "123/409 [========>.....................] - ETA: 9s - loss: 0.2521 - dice_coefficient: 0.8351 \n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "125/409 [========>.....................] - ETA: 9s - loss: 0.2520 - dice_coefficient: 0.8349\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "127/409 [========>.....................] - ETA: 9s - loss: 0.2504 - dice_coefficient: 0.8357\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "129/409 [========>.....................] - ETA: 9s - loss: 0.2508 - dice_coefficient: 0.8351\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "131/409 [========>.....................] - ETA: 9s - loss: 0.2494 - dice_coefficient: 0.8361\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "133/409 [========>.....................] - ETA: 9s - loss: 0.2479 - dice_coefficient: 0.8375\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "135/409 [========>.....................] - ETA: 9s - loss: 0.2471 - dice_coefficient: 0.8384\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "137/409 [=========>....................] - ETA: 9s - loss: 0.2481 - dice_coefficient: 0.8381\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "139/409 [=========>....................] - ETA: 9s - loss: 0.2481 - dice_coefficient: 0.8377\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "141/409 [=========>....................] - ETA: 9s - loss: 0.2472 - dice_coefficient: 0.8380\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "143/409 [=========>....................] - ETA: 9s - loss: 0.2466 - dice_coefficient: 0.8387\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "145/409 [=========>....................] - ETA: 9s - loss: 0.2488 - dice_coefficient: 0.8367\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "147/409 [=========>....................] - ETA: 9s - loss: 0.2480 - dice_coefficient: 0.8373\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "149/409 [=========>....................] - ETA: 9s - loss: 0.2485 - dice_coefficient: 0.8365\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "151/409 [==========>...................] - ETA: 8s - loss: 0.2501 - dice_coefficient: 0.8350\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "153/409 [==========>...................] - ETA: 8s - loss: 0.2487 - dice_coefficient: 0.8362\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "155/409 [==========>...................] - ETA: 8s - loss: 0.2470 - dice_coefficient: 0.8374\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "157/409 [==========>...................] - ETA: 8s - loss: 0.2485 - dice_coefficient: 0.8368\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "159/409 [==========>...................] - ETA: 8s - loss: 0.2476 - dice_coefficient: 0.8377\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "161/409 [==========>...................] - ETA: 8s - loss: 0.2473 - dice_coefficient: 0.8377\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "163/409 [==========>...................] - ETA: 8s - loss: 0.2471 - dice_coefficient: 0.8379\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "165/409 [===========>..................] - ETA: 8s - loss: 0.2497 - dice_coefficient: 0.8361\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "167/409 [===========>..................] - ETA: 8s - loss: 0.2510 - dice_coefficient: 0.8349\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "169/409 [===========>..................] - ETA: 8s - loss: 0.2511 - dice_coefficient: 0.8346\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "171/409 [===========>..................] - ETA: 8s - loss: 0.2507 - dice_coefficient: 0.8348\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "173/409 [===========>..................] - ETA: 8s - loss: 0.2507 - dice_coefficient: 0.8347\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "175/409 [===========>..................] - ETA: 8s - loss: 0.2515 - dice_coefficient: 0.8338\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "177/409 [===========>..................] - ETA: 8s - loss: 0.2512 - dice_coefficient: 0.8337\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "179/409 [============>.................] - ETA: 8s - loss: 0.2526 - dice_coefficient: 0.8341\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "181/409 [============>.................] - ETA: 7s - loss: 0.2516 - dice_coefficient: 0.8351\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "183/409 [============>.................] - ETA: 7s - loss: 0.2556 - dice_coefficient: 0.8320\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "185/409 [============>.................] - ETA: 7s - loss: 0.3407 - dice_coefficient: 0.8280\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "187/409 [============>.................] - ETA: 7s - loss: 0.3402 - dice_coefficient: 0.8278\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "189/409 [============>.................] - ETA: 7s - loss: 0.3391 - dice_coefficient: 0.8283\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "191/409 [=============>................] - ETA: 7s - loss: 0.3371 - dice_coefficient: 0.8294\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "193/409 [=============>................] - ETA: 7s - loss: 0.3358 - dice_coefficient: 0.8298\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "195/409 [=============>................] - ETA: 7s - loss: 0.3339 - dice_coefficient: 0.8308\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "197/409 [=============>................] - ETA: 7s - loss: 0.3330 - dice_coefficient: 0.8306\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "199/409 [=============>................] - ETA: 7s - loss: 0.3315 - dice_coefficient: 0.8311\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "201/409 [=============>................] - ETA: 7s - loss: 0.3319 - dice_coefficient: 0.8303\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "203/409 [=============>................] - ETA: 7s - loss: 0.3324 - dice_coefficient: 0.8290\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "205/409 [==============>...............] - ETA: 7s - loss: 0.3326 - dice_coefficient: 0.8293\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "207/409 [==============>...............] - ETA: 7s - loss: 0.3328 - dice_coefficient: 0.8284\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "209/409 [==============>...............] - ETA: 6s - loss: 0.3310 - dice_coefficient: 0.8292\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "211/409 [==============>...............] - ETA: 6s - loss: 0.3295 - dice_coefficient: 0.8300\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "213/409 [==============>...............] - ETA: 6s - loss: 0.3279 - dice_coefficient: 0.8306\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "215/409 [==============>...............] - ETA: 6s - loss: 0.3275 - dice_coefficient: 0.8303\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "217/409 [==============>...............] - ETA: 6s - loss: 0.3261 - dice_coefficient: 0.8311\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "219/409 [===============>..............] - ETA: 6s - loss: 0.3260 - dice_coefficient: 0.8305\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "221/409 [===============>..............] - ETA: 6s - loss: 0.3247 - dice_coefficient: 0.8311\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "223/409 [===============>..............] - ETA: 6s - loss: 0.3234 - dice_coefficient: 0.8314\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "225/409 [===============>..............] - ETA: 6s - loss: 0.3230 - dice_coefficient: 0.8311\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "227/409 [===============>..............] - ETA: 6s - loss: 0.3225 - dice_coefficient: 0.8311\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "229/409 [===============>..............] - ETA: 6s - loss: 0.3218 - dice_coefficient: 0.8311\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "231/409 [===============>..............] - ETA: 6s - loss: 0.3205 - dice_coefficient: 0.8318\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "233/409 [================>.............] - ETA: 6s - loss: 0.3192 - dice_coefficient: 0.8323\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "235/409 [================>.............] - ETA: 6s - loss: 0.3190 - dice_coefficient: 0.8321\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "237/409 [================>.............] - ETA: 6s - loss: 0.3180 - dice_coefficient: 0.8325\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "239/409 [================>.............] - ETA: 5s - loss: 0.3185 - dice_coefficient: 0.8317\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "241/409 [================>.............] - ETA: 5s - loss: 0.3196 - dice_coefficient: 0.8306\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "243/409 [================>.............] - ETA: 5s - loss: 0.3202 - dice_coefficient: 0.8297\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "245/409 [================>.............] - ETA: 5s - loss: 0.3191 - dice_coefficient: 0.8303\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "247/409 [=================>............] - ETA: 5s - loss: 0.3179 - dice_coefficient: 0.8310\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "249/409 [=================>............] - ETA: 5s - loss: 0.3174 - dice_coefficient: 0.8310\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "251/409 [=================>............] - ETA: 5s - loss: 0.3162 - dice_coefficient: 0.8315\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "253/409 [=================>............] - ETA: 5s - loss: 0.3161 - dice_coefficient: 0.8312\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "255/409 [=================>............] - ETA: 5s - loss: 0.3159 - dice_coefficient: 0.8308\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "257/409 [=================>............] - ETA: 5s - loss: 0.3150 - dice_coefficient: 0.8312\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "259/409 [=================>............] - ETA: 5s - loss: 0.3180 - dice_coefficient: 0.8288\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "261/409 [==================>...........] - ETA: 5s - loss: 0.3169 - dice_coefficient: 0.8292\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "263/409 [==================>...........] - ETA: 5s - loss: 0.3162 - dice_coefficient: 0.8296\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "265/409 [==================>...........] - ETA: 5s - loss: 0.3167 - dice_coefficient: 0.8295\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "267/409 [==================>...........] - ETA: 4s - loss: 0.3165 - dice_coefficient: 0.8293\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "269/409 [==================>...........] - ETA: 4s - loss: 0.3165 - dice_coefficient: 0.8288\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "271/409 [==================>...........] - ETA: 4s - loss: 0.3156 - dice_coefficient: 0.8290\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "273/409 [===================>..........] - ETA: 4s - loss: 0.3161 - dice_coefficient: 0.8281\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "275/409 [===================>..........] - ETA: 4s - loss: 0.3157 - dice_coefficient: 0.8279\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "277/409 [===================>..........] - ETA: 4s - loss: 0.3144 - dice_coefficient: 0.8287\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "279/409 [===================>..........] - ETA: 4s - loss: 0.3143 - dice_coefficient: 0.8283\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "281/409 [===================>..........] - ETA: 4s - loss: 0.3134 - dice_coefficient: 0.8288\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "283/409 [===================>..........] - ETA: 4s - loss: 0.3131 - dice_coefficient: 0.8288\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "285/409 [===================>..........] - ETA: 4s - loss: 0.3124 - dice_coefficient: 0.8293\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "287/409 [====================>.........] - ETA: 4s - loss: 0.3117 - dice_coefficient: 0.8294\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "289/409 [====================>.........] - ETA: 4s - loss: 0.3111 - dice_coefficient: 0.8297\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "291/409 [====================>.........] - ETA: 4s - loss: 0.3111 - dice_coefficient: 0.8300\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "293/409 [====================>.........] - ETA: 4s - loss: 0.3104 - dice_coefficient: 0.8303\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "295/409 [====================>.........] - ETA: 3s - loss: 0.3094 - dice_coefficient: 0.8308\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "297/409 [====================>.........] - ETA: 3s - loss: 0.3085 - dice_coefficient: 0.8313\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "299/409 [====================>.........] - ETA: 3s - loss: 0.3113 - dice_coefficient: 0.8293\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "301/409 [=====================>........] - ETA: 3s - loss: 0.3105 - dice_coefficient: 0.8296\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "303/409 [=====================>........] - ETA: 3s - loss: 0.3098 - dice_coefficient: 0.8298\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "305/409 [=====================>........] - ETA: 3s - loss: 0.3091 - dice_coefficient: 0.8303\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "307/409 [=====================>........] - ETA: 3s - loss: 0.3081 - dice_coefficient: 0.8310\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "309/409 [=====================>........] - ETA: 3s - loss: 0.3082 - dice_coefficient: 0.8306\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "311/409 [=====================>........] - ETA: 3s - loss: 0.3072 - dice_coefficient: 0.8312\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "313/409 [=====================>........] - ETA: 3s - loss: 0.3070 - dice_coefficient: 0.8310\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "315/409 [======================>.......] - ETA: 3s - loss: 0.3065 - dice_coefficient: 0.8311\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "317/409 [======================>.......] - ETA: 3s - loss: 0.3062 - dice_coefficient: 0.8312\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "319/409 [======================>.......] - ETA: 3s - loss: 0.3060 - dice_coefficient: 0.8309\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "321/409 [======================>.......] - ETA: 3s - loss: 0.3053 - dice_coefficient: 0.8313\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "323/409 [======================>.......] - ETA: 3s - loss: 0.3055 - dice_coefficient: 0.8307\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "325/409 [======================>.......] - ETA: 2s - loss: 0.3049 - dice_coefficient: 0.8309\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "327/409 [======================>.......] - ETA: 2s - loss: 0.3040 - dice_coefficient: 0.8315\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "329/409 [=======================>......] - ETA: 2s - loss: 0.3038 - dice_coefficient: 0.8317\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "331/409 [=======================>......] - ETA: 2s - loss: 0.3037 - dice_coefficient: 0.8316\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "333/409 [=======================>......] - ETA: 2s - loss: 0.3036 - dice_coefficient: 0.8317\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "335/409 [=======================>......] - ETA: 2s - loss: 0.3033 - dice_coefficient: 0.8316\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "337/409 [=======================>......] - ETA: 2s - loss: 0.3031 - dice_coefficient: 0.8315\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "339/409 [=======================>......] - ETA: 2s - loss: 0.3034 - dice_coefficient: 0.8309\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "341/409 [========================>.....] - ETA: 2s - loss: 0.3036 - dice_coefficient: 0.8303\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "343/409 [========================>.....] - ETA: 2s - loss: 0.3029 - dice_coefficient: 0.8306\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "345/409 [========================>.....] - ETA: 2s - loss: 0.3023 - dice_coefficient: 0.8308\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "347/409 [========================>.....] - ETA: 2s - loss: 0.3019 - dice_coefficient: 0.8309\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "349/409 [========================>.....] - ETA: 2s - loss: 0.3015 - dice_coefficient: 0.8312\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "351/409 [========================>.....] - ETA: 2s - loss: 0.3011 - dice_coefficient: 0.8313\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "353/409 [========================>.....] - ETA: 1s - loss: 0.3009 - dice_coefficient: 0.8314\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "355/409 [=========================>....] - ETA: 1s - loss: 0.3014 - dice_coefficient: 0.8307\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "357/409 [=========================>....] - ETA: 1s - loss: 0.3011 - dice_coefficient: 0.8307\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "359/409 [=========================>....] - ETA: 1s - loss: 0.3011 - dice_coefficient: 0.8305\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "361/409 [=========================>....] - ETA: 1s - loss: 0.3024 - dice_coefficient: 0.8293\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "363/409 [=========================>....] - ETA: 1s - loss: 0.3026 - dice_coefficient: 0.8289\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "365/409 [=========================>....] - ETA: 1s - loss: 0.3020 - dice_coefficient: 0.8290\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "367/409 [=========================>....] - ETA: 1s - loss: 0.3015 - dice_coefficient: 0.8292\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "369/409 [==========================>...] - ETA: 1s - loss: 0.3025 - dice_coefficient: 0.8282\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "371/409 [==========================>...] - ETA: 1s - loss: 0.3019 - dice_coefficient: 0.8286\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "373/409 [==========================>...] - ETA: 1s - loss: 0.3035 - dice_coefficient: 0.8272\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "375/409 [==========================>...] - ETA: 1s - loss: 0.3034 - dice_coefficient: 0.8270\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "377/409 [==========================>...] - ETA: 1s - loss: 0.3041 - dice_coefficient: 0.8266\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "379/409 [==========================>...] - ETA: 1s - loss: 0.3039 - dice_coefficient: 0.8267\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "381/409 [==========================>...] - ETA: 0s - loss: 0.3034 - dice_coefficient: 0.8270\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "383/409 [===========================>..] - ETA: 0s - loss: 0.3038 - dice_coefficient: 0.8263\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "385/409 [===========================>..] - ETA: 0s - loss: 0.3035 - dice_coefficient: 0.8269\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "387/409 [===========================>..] - ETA: 0s - loss: 0.3030 - dice_coefficient: 0.8270\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "389/409 [===========================>..] - ETA: 0s - loss: 0.3030 - dice_coefficient: 0.8274\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "391/409 [===========================>..] - ETA: 0s - loss: 0.3027 - dice_coefficient: 0.8274\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "393/409 [===========================>..] - ETA: 0s - loss: 0.3020 - dice_coefficient: 0.8278\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "395/409 [===========================>..] - ETA: 0s - loss: 0.3017 - dice_coefficient: 0.8277\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "397/409 [============================>.] - ETA: 0s - loss: 0.3017 - dice_coefficient: 0.8277\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "399/409 [============================>.] - ETA: 0s - loss: 0.3013 - dice_coefficient: 0.8277\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "401/409 [============================>.] - ETA: 0s - loss: 0.3009 - dice_coefficient: 0.8278\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "403/409 [============================>.] - ETA: 0s - loss: 0.3003 - dice_coefficient: 0.8280\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "405/409 [============================>.] - ETA: 0s - loss: 0.2995 - dice_coefficient: 0.8285\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "407/409 [============================>.] - ETA: 0s - loss: 0.2998 - dice_coefficient: 0.8280\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.16045\n",
            "409/409 [==============================] - 14s 35ms/step - loss: 0.2997 - dice_coefficient: 0.8279 - lr: 1.0000e-04\n",
            "Epoch 126/130\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "  1/409 [..............................] - ETA: 0s - loss: 0.1759 - dice_coefficient: 0.8747\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "  3/409 [..............................] - ETA: 9s - loss: 0.3041 - dice_coefficient: 0.7853\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "  5/409 [..............................] - ETA: 11s - loss: 0.2546 - dice_coefficient: 0.8192\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "  7/409 [..............................] - ETA: 12s - loss: 0.3211 - dice_coefficient: 0.7777\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "  9/409 [..............................] - ETA: 12s - loss: 0.3098 - dice_coefficient: 0.7799\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 11/409 [..............................] - ETA: 12s - loss: 0.2979 - dice_coefficient: 0.7926\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 13/409 [..............................] - ETA: 12s - loss: 0.3094 - dice_coefficient: 0.7820\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 15/409 [>.............................] - ETA: 12s - loss: 0.3056 - dice_coefficient: 0.7861\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 17/409 [>.............................] - ETA: 12s - loss: 0.2893 - dice_coefficient: 0.7972\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 19/409 [>.............................] - ETA: 12s - loss: 0.2810 - dice_coefficient: 0.8045\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 21/409 [>.............................] - ETA: 12s - loss: 0.2786 - dice_coefficient: 0.8131\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 23/409 [>.............................] - ETA: 12s - loss: 0.2703 - dice_coefficient: 0.8188\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 25/409 [>.............................] - ETA: 12s - loss: 0.2643 - dice_coefficient: 0.8245\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 27/409 [>.............................] - ETA: 12s - loss: 0.2582 - dice_coefficient: 0.8293\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 29/409 [=>............................] - ETA: 12s - loss: 0.2550 - dice_coefficient: 0.8349\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 31/409 [=>............................] - ETA: 12s - loss: 0.2523 - dice_coefficient: 0.8377\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 33/409 [=>............................] - ETA: 12s - loss: 0.2492 - dice_coefficient: 0.8387\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 35/409 [=>............................] - ETA: 12s - loss: 0.2446 - dice_coefficient: 0.8428\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 37/409 [=>............................] - ETA: 12s - loss: 0.2475 - dice_coefficient: 0.8390\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 39/409 [=>............................] - ETA: 12s - loss: 0.2509 - dice_coefficient: 0.8397\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 41/409 [==>...........................] - ETA: 12s - loss: 0.2543 - dice_coefficient: 0.8363\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 43/409 [==>...........................] - ETA: 12s - loss: 0.2540 - dice_coefficient: 0.8365\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 45/409 [==>...........................] - ETA: 12s - loss: 0.2579 - dice_coefficient: 0.8320\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 47/409 [==>...........................] - ETA: 12s - loss: 0.2555 - dice_coefficient: 0.8361\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 49/409 [==>...........................] - ETA: 12s - loss: 0.2659 - dice_coefficient: 0.8279\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 51/409 [==>...........................] - ETA: 12s - loss: 0.2631 - dice_coefficient: 0.8310\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 53/409 [==>...........................] - ETA: 12s - loss: 0.2618 - dice_coefficient: 0.8327\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 55/409 [===>..........................] - ETA: 12s - loss: 0.2594 - dice_coefficient: 0.8340\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 57/409 [===>..........................] - ETA: 12s - loss: 0.2642 - dice_coefficient: 0.8356\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 59/409 [===>..........................] - ETA: 12s - loss: 0.2667 - dice_coefficient: 0.8332\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 61/409 [===>..........................] - ETA: 12s - loss: 0.2650 - dice_coefficient: 0.8339\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 63/409 [===>..........................] - ETA: 11s - loss: 0.2672 - dice_coefficient: 0.8307\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 65/409 [===>..........................] - ETA: 11s - loss: 0.2655 - dice_coefficient: 0.8317\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 67/409 [===>..........................] - ETA: 11s - loss: 0.2657 - dice_coefficient: 0.8304\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 69/409 [====>.........................] - ETA: 11s - loss: 0.2640 - dice_coefficient: 0.8311\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 71/409 [====>.........................] - ETA: 11s - loss: 0.2626 - dice_coefficient: 0.8316\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 73/409 [====>.........................] - ETA: 11s - loss: 0.2632 - dice_coefficient: 0.8320\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 75/409 [====>.........................] - ETA: 11s - loss: 0.2713 - dice_coefficient: 0.8264\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 77/409 [====>.........................] - ETA: 11s - loss: 0.2772 - dice_coefficient: 0.8220\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 79/409 [====>.........................] - ETA: 11s - loss: 0.2780 - dice_coefficient: 0.8218\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 81/409 [====>.........................] - ETA: 11s - loss: 0.2763 - dice_coefficient: 0.8230\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 83/409 [=====>........................] - ETA: 11s - loss: 0.2750 - dice_coefficient: 0.8235\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 85/409 [=====>........................] - ETA: 11s - loss: 0.2742 - dice_coefficient: 0.8235\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 87/409 [=====>........................] - ETA: 11s - loss: 0.2714 - dice_coefficient: 0.8255\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 89/409 [=====>........................] - ETA: 11s - loss: 0.2690 - dice_coefficient: 0.8272\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 91/409 [=====>........................] - ETA: 11s - loss: 0.2652 - dice_coefficient: 0.8298\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 93/409 [=====>........................] - ETA: 10s - loss: 0.2623 - dice_coefficient: 0.8320\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 95/409 [=====>........................] - ETA: 10s - loss: 0.2635 - dice_coefficient: 0.8304\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 97/409 [======>.......................] - ETA: 10s - loss: 0.2623 - dice_coefficient: 0.8310\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            " 99/409 [======>.......................] - ETA: 10s - loss: 0.2621 - dice_coefficient: 0.8306\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "101/409 [======>.......................] - ETA: 10s - loss: 0.2598 - dice_coefficient: 0.8327\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "103/409 [======>.......................] - ETA: 10s - loss: 0.2588 - dice_coefficient: 0.8338\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "105/409 [======>.......................] - ETA: 10s - loss: 0.2578 - dice_coefficient: 0.8345\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "107/409 [======>.......................] - ETA: 10s - loss: 0.2575 - dice_coefficient: 0.8346\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "109/409 [======>.......................] - ETA: 10s - loss: 0.2571 - dice_coefficient: 0.8348\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "111/409 [=======>......................] - ETA: 10s - loss: 0.2552 - dice_coefficient: 0.8360\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "113/409 [=======>......................] - ETA: 10s - loss: 0.2537 - dice_coefficient: 0.8372\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "115/409 [=======>......................] - ETA: 10s - loss: 0.2522 - dice_coefficient: 0.8380\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "117/409 [=======>......................] - ETA: 10s - loss: 0.2552 - dice_coefficient: 0.8358\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "119/409 [=======>......................] - ETA: 10s - loss: 0.2543 - dice_coefficient: 0.8364\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "121/409 [=======>......................] - ETA: 10s - loss: 0.2541 - dice_coefficient: 0.8362\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "123/409 [========>.....................] - ETA: 9s - loss: 0.2521 - dice_coefficient: 0.8377 \n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "125/409 [========>.....................] - ETA: 9s - loss: 0.2514 - dice_coefficient: 0.8380\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "127/409 [========>.....................] - ETA: 9s - loss: 0.2505 - dice_coefficient: 0.8389\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "129/409 [========>.....................] - ETA: 9s - loss: 0.2507 - dice_coefficient: 0.8388\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "131/409 [========>.....................] - ETA: 9s - loss: 0.2502 - dice_coefficient: 0.8391\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "133/409 [========>.....................] - ETA: 9s - loss: 0.2500 - dice_coefficient: 0.8393\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "135/409 [========>.....................] - ETA: 9s - loss: 0.2494 - dice_coefficient: 0.8393\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "137/409 [=========>....................] - ETA: 9s - loss: 0.2486 - dice_coefficient: 0.8399\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "139/409 [=========>....................] - ETA: 9s - loss: 0.2484 - dice_coefficient: 0.8396\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "141/409 [=========>....................] - ETA: 9s - loss: 0.2476 - dice_coefficient: 0.8403\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "143/409 [=========>....................] - ETA: 9s - loss: 0.2469 - dice_coefficient: 0.8407\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "145/409 [=========>....................] - ETA: 9s - loss: 0.2480 - dice_coefficient: 0.8397\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "147/409 [=========>....................] - ETA: 9s - loss: 0.2486 - dice_coefficient: 0.8390\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "149/409 [=========>....................] - ETA: 9s - loss: 0.2483 - dice_coefficient: 0.8389\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "151/409 [==========>...................] - ETA: 8s - loss: 0.2483 - dice_coefficient: 0.8391\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "153/409 [==========>...................] - ETA: 8s - loss: 0.2470 - dice_coefficient: 0.8401\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "155/409 [==========>...................] - ETA: 8s - loss: 0.2497 - dice_coefficient: 0.8381\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "157/409 [==========>...................] - ETA: 8s - loss: 0.2484 - dice_coefficient: 0.8388\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "159/409 [==========>...................] - ETA: 8s - loss: 0.2478 - dice_coefficient: 0.8391\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "161/409 [==========>...................] - ETA: 8s - loss: 0.2492 - dice_coefficient: 0.8377\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "163/409 [==========>...................] - ETA: 8s - loss: 0.2490 - dice_coefficient: 0.8378\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "165/409 [===========>..................] - ETA: 8s - loss: 0.2484 - dice_coefficient: 0.8383\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "167/409 [===========>..................] - ETA: 8s - loss: 0.2482 - dice_coefficient: 0.8386\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "169/409 [===========>..................] - ETA: 8s - loss: 0.2483 - dice_coefficient: 0.8387\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "171/409 [===========>..................] - ETA: 8s - loss: 0.2490 - dice_coefficient: 0.8382\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "173/409 [===========>..................] - ETA: 8s - loss: 0.2481 - dice_coefficient: 0.8394\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "175/409 [===========>..................] - ETA: 8s - loss: 0.2484 - dice_coefficient: 0.8389\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "177/409 [===========>..................] - ETA: 8s - loss: 0.2487 - dice_coefficient: 0.8386\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "179/409 [============>.................] - ETA: 8s - loss: 0.2504 - dice_coefficient: 0.8371\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "181/409 [============>.................] - ETA: 7s - loss: 0.2497 - dice_coefficient: 0.8378\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "183/409 [============>.................] - ETA: 7s - loss: 0.2509 - dice_coefficient: 0.8379\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "185/409 [============>.................] - ETA: 7s - loss: 0.2506 - dice_coefficient: 0.8386\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "187/409 [============>.................] - ETA: 7s - loss: 0.2505 - dice_coefficient: 0.8386\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "189/409 [============>.................] - ETA: 7s - loss: 0.2498 - dice_coefficient: 0.8393\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "191/409 [=============>................] - ETA: 7s - loss: 0.2495 - dice_coefficient: 0.8396\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "193/409 [=============>................] - ETA: 7s - loss: 0.2486 - dice_coefficient: 0.8403\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "195/409 [=============>................] - ETA: 7s - loss: 0.2480 - dice_coefficient: 0.8406\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "197/409 [=============>................] - ETA: 7s - loss: 0.2480 - dice_coefficient: 0.8404\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "199/409 [=============>................] - ETA: 7s - loss: 0.2496 - dice_coefficient: 0.8392\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "201/409 [=============>................] - ETA: 7s - loss: 0.2501 - dice_coefficient: 0.8395\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "203/409 [=============>................] - ETA: 7s - loss: 0.2510 - dice_coefficient: 0.8387\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "205/409 [==============>...............] - ETA: 7s - loss: 0.2514 - dice_coefficient: 0.8380\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "207/409 [==============>...............] - ETA: 7s - loss: 0.2508 - dice_coefficient: 0.8385\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "209/409 [==============>...............] - ETA: 6s - loss: 0.2506 - dice_coefficient: 0.8390\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "211/409 [==============>...............] - ETA: 6s - loss: 0.2504 - dice_coefficient: 0.8390\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "213/409 [==============>...............] - ETA: 6s - loss: 0.2500 - dice_coefficient: 0.8393\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "215/409 [==============>...............] - ETA: 6s - loss: 0.2508 - dice_coefficient: 0.8383\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "217/409 [==============>...............] - ETA: 6s - loss: 0.2514 - dice_coefficient: 0.8376\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "219/409 [===============>..............] - ETA: 6s - loss: 0.2513 - dice_coefficient: 0.8377\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "221/409 [===============>..............] - ETA: 6s - loss: 0.2512 - dice_coefficient: 0.8377\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "223/409 [===============>..............] - ETA: 6s - loss: 0.2502 - dice_coefficient: 0.8385\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "225/409 [===============>..............] - ETA: 6s - loss: 0.2510 - dice_coefficient: 0.8379\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "227/409 [===============>..............] - ETA: 6s - loss: 0.2515 - dice_coefficient: 0.8373\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "229/409 [===============>..............] - ETA: 6s - loss: 0.2515 - dice_coefficient: 0.8373\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "231/409 [===============>..............] - ETA: 6s - loss: 0.2516 - dice_coefficient: 0.8372\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "233/409 [================>.............] - ETA: 6s - loss: 0.2516 - dice_coefficient: 0.8371\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "235/409 [================>.............] - ETA: 6s - loss: 0.2506 - dice_coefficient: 0.8380\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "237/409 [================>.............] - ETA: 6s - loss: 0.2496 - dice_coefficient: 0.8387\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "239/409 [================>.............] - ETA: 5s - loss: 0.2494 - dice_coefficient: 0.8389\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "241/409 [================>.............] - ETA: 5s - loss: 0.2491 - dice_coefficient: 0.8391\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "243/409 [================>.............] - ETA: 5s - loss: 0.2489 - dice_coefficient: 0.8390\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "245/409 [================>.............] - ETA: 5s - loss: 0.2493 - dice_coefficient: 0.8390\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "247/409 [=================>............] - ETA: 5s - loss: 0.2489 - dice_coefficient: 0.8393\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "249/409 [=================>............] - ETA: 5s - loss: 0.2495 - dice_coefficient: 0.8387\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "251/409 [=================>............] - ETA: 5s - loss: 0.2485 - dice_coefficient: 0.8394\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "253/409 [=================>............] - ETA: 5s - loss: 0.2483 - dice_coefficient: 0.8397\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "255/409 [=================>............] - ETA: 5s - loss: 0.2499 - dice_coefficient: 0.8382\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "257/409 [=================>............] - ETA: 5s - loss: 0.2496 - dice_coefficient: 0.8384\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "259/409 [=================>............] - ETA: 5s - loss: 0.2499 - dice_coefficient: 0.8380\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "261/409 [==================>...........] - ETA: 5s - loss: 0.2496 - dice_coefficient: 0.8385\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "263/409 [==================>...........] - ETA: 5s - loss: 0.2497 - dice_coefficient: 0.8383\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "265/409 [==================>...........] - ETA: 5s - loss: 0.2503 - dice_coefficient: 0.8378\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "267/409 [==================>...........] - ETA: 4s - loss: 0.2495 - dice_coefficient: 0.8383\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "269/409 [==================>...........] - ETA: 4s - loss: 0.2510 - dice_coefficient: 0.8373\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "271/409 [==================>...........] - ETA: 4s - loss: 0.2520 - dice_coefficient: 0.8364\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "273/409 [===================>..........] - ETA: 4s - loss: 0.2521 - dice_coefficient: 0.8362\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "275/409 [===================>..........] - ETA: 4s - loss: 0.2525 - dice_coefficient: 0.8359\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "277/409 [===================>..........] - ETA: 4s - loss: 0.2535 - dice_coefficient: 0.8360\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "279/409 [===================>..........] - ETA: 4s - loss: 0.2534 - dice_coefficient: 0.8361\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "281/409 [===================>..........] - ETA: 4s - loss: 0.2530 - dice_coefficient: 0.8365\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "283/409 [===================>..........] - ETA: 4s - loss: 0.2530 - dice_coefficient: 0.8369\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "285/409 [===================>..........] - ETA: 4s - loss: 0.2540 - dice_coefficient: 0.8359\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "287/409 [====================>.........] - ETA: 4s - loss: 0.2555 - dice_coefficient: 0.8346\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "289/409 [====================>.........] - ETA: 4s - loss: 0.2572 - dice_coefficient: 0.8333\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "291/409 [====================>.........] - ETA: 4s - loss: 0.2572 - dice_coefficient: 0.8332\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "293/409 [====================>.........] - ETA: 4s - loss: 0.2567 - dice_coefficient: 0.8337\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "295/409 [====================>.........] - ETA: 3s - loss: 0.2568 - dice_coefficient: 0.8335\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "297/409 [====================>.........] - ETA: 3s - loss: 0.2569 - dice_coefficient: 0.8334\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "299/409 [====================>.........] - ETA: 3s - loss: 0.2561 - dice_coefficient: 0.8341\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "301/409 [=====================>........] - ETA: 3s - loss: 0.2563 - dice_coefficient: 0.8343\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "303/409 [=====================>........] - ETA: 3s - loss: 0.2561 - dice_coefficient: 0.8344\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "305/409 [=====================>........] - ETA: 3s - loss: 0.2561 - dice_coefficient: 0.8341\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "307/409 [=====================>........] - ETA: 3s - loss: 0.2561 - dice_coefficient: 0.8343\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "309/409 [=====================>........] - ETA: 3s - loss: 0.2565 - dice_coefficient: 0.8338\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "311/409 [=====================>........] - ETA: 3s - loss: 0.2565 - dice_coefficient: 0.8337\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "313/409 [=====================>........] - ETA: 3s - loss: 0.2564 - dice_coefficient: 0.8340\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "315/409 [======================>.......] - ETA: 3s - loss: 0.2562 - dice_coefficient: 0.8342\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "317/409 [======================>.......] - ETA: 3s - loss: 0.2572 - dice_coefficient: 0.8334\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "319/409 [======================>.......] - ETA: 3s - loss: 0.2569 - dice_coefficient: 0.8336\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "321/409 [======================>.......] - ETA: 3s - loss: 0.2573 - dice_coefficient: 0.8332\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "322/409 [======================>.......] - ETA: 3s - loss: 0.2569 - dice_coefficient: 0.8334\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "323/409 [======================>.......] - ETA: 3s - loss: 0.2567 - dice_coefficient: 0.8335\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "324/409 [======================>.......] - ETA: 3s - loss: 0.2570 - dice_coefficient: 0.8332\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "325/409 [======================>.......] - ETA: 2s - loss: 0.2578 - dice_coefficient: 0.8334\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "327/409 [======================>.......] - ETA: 2s - loss: 0.2575 - dice_coefficient: 0.8337\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "329/409 [=======================>......] - ETA: 2s - loss: 0.2577 - dice_coefficient: 0.8333\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "330/409 [=======================>......] - ETA: 2s - loss: 0.2577 - dice_coefficient: 0.8335\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "331/409 [=======================>......] - ETA: 2s - loss: 0.2574 - dice_coefficient: 0.8338\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "333/409 [=======================>......] - ETA: 2s - loss: 0.2567 - dice_coefficient: 0.8343\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "335/409 [=======================>......] - ETA: 2s - loss: 0.2565 - dice_coefficient: 0.8345\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "336/409 [=======================>......] - ETA: 2s - loss: 0.2576 - dice_coefficient: 0.8336\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "338/409 [=======================>......] - ETA: 2s - loss: 0.2573 - dice_coefficient: 0.8338\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "340/409 [=======================>......] - ETA: 2s - loss: 0.2566 - dice_coefficient: 0.8345\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "342/409 [========================>.....] - ETA: 2s - loss: 0.2563 - dice_coefficient: 0.8347\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "344/409 [========================>.....] - ETA: 2s - loss: 0.2572 - dice_coefficient: 0.8341\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "346/409 [========================>.....] - ETA: 2s - loss: 0.2568 - dice_coefficient: 0.8344\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "348/409 [========================>.....] - ETA: 2s - loss: 0.2567 - dice_coefficient: 0.8344\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "350/409 [========================>.....] - ETA: 2s - loss: 0.2567 - dice_coefficient: 0.8344\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "352/409 [========================>.....] - ETA: 2s - loss: 0.2581 - dice_coefficient: 0.8332\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "354/409 [========================>.....] - ETA: 1s - loss: 0.2582 - dice_coefficient: 0.8332\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "355/409 [=========================>....] - ETA: 1s - loss: 0.2579 - dice_coefficient: 0.8333\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "356/409 [=========================>....] - ETA: 1s - loss: 0.2575 - dice_coefficient: 0.8336\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "357/409 [=========================>....] - ETA: 1s - loss: 0.2574 - dice_coefficient: 0.8336\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "359/409 [=========================>....] - ETA: 1s - loss: 0.2575 - dice_coefficient: 0.8334\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "361/409 [=========================>....] - ETA: 1s - loss: 0.2574 - dice_coefficient: 0.8334\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "362/409 [=========================>....] - ETA: 1s - loss: 0.2573 - dice_coefficient: 0.8334\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "363/409 [=========================>....] - ETA: 1s - loss: 0.2576 - dice_coefficient: 0.8331\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "365/409 [=========================>....] - ETA: 1s - loss: 0.3013 - dice_coefficient: 0.8310\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "366/409 [=========================>....] - ETA: 1s - loss: 0.3012 - dice_coefficient: 0.8309\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "367/409 [=========================>....] - ETA: 1s - loss: 0.3010 - dice_coefficient: 0.8310\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "368/409 [=========================>....] - ETA: 1s - loss: 0.3012 - dice_coefficient: 0.8306\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "369/409 [==========================>...] - ETA: 1s - loss: 0.3009 - dice_coefficient: 0.8307\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "371/409 [==========================>...] - ETA: 1s - loss: 0.3002 - dice_coefficient: 0.8311\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "373/409 [==========================>...] - ETA: 1s - loss: 0.2996 - dice_coefficient: 0.8312\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "375/409 [==========================>...] - ETA: 1s - loss: 0.2990 - dice_coefficient: 0.8316\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "376/409 [==========================>...] - ETA: 1s - loss: 0.2986 - dice_coefficient: 0.8319\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "378/409 [==========================>...] - ETA: 1s - loss: 0.2979 - dice_coefficient: 0.8322\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "380/409 [==========================>...] - ETA: 1s - loss: 0.2980 - dice_coefficient: 0.8319\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "382/409 [===========================>..] - ETA: 0s - loss: 0.2977 - dice_coefficient: 0.8319\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "384/409 [===========================>..] - ETA: 0s - loss: 0.2974 - dice_coefficient: 0.8321\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "386/409 [===========================>..] - ETA: 0s - loss: 0.2973 - dice_coefficient: 0.8319\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "388/409 [===========================>..] - ETA: 0s - loss: 0.2977 - dice_coefficient: 0.8313\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "390/409 [===========================>..] - ETA: 0s - loss: 0.2978 - dice_coefficient: 0.8313\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "392/409 [===========================>..] - ETA: 0s - loss: 0.2977 - dice_coefficient: 0.8310\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "393/409 [===========================>..] - ETA: 0s - loss: 0.2984 - dice_coefficient: 0.8304\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "395/409 [===========================>..] - ETA: 0s - loss: 0.2977 - dice_coefficient: 0.8307\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "396/409 [============================>.] - ETA: 0s - loss: 0.2976 - dice_coefficient: 0.8307\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "397/409 [============================>.] - ETA: 0s - loss: 0.2975 - dice_coefficient: 0.8306\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "399/409 [============================>.] - ETA: 0s - loss: 0.2973 - dice_coefficient: 0.8306\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "401/409 [============================>.] - ETA: 0s - loss: 0.2972 - dice_coefficient: 0.8305\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "403/409 [============================>.] - ETA: 0s - loss: 0.2969 - dice_coefficient: 0.8306\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "405/409 [============================>.] - ETA: 0s - loss: 0.2969 - dice_coefficient: 0.8304\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "406/409 [============================>.] - ETA: 0s - loss: 0.2970 - dice_coefficient: 0.8301\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "407/409 [============================>.] - ETA: 0s - loss: 0.2968 - dice_coefficient: 0.8301\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.16045\n",
            "409/409 [==============================] - 15s 38ms/step - loss: 0.2978 - dice_coefficient: 0.8293 - lr: 1.0000e-04\n",
            "Epoch 127/130\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.16045\n",
            "  1/409 [..............................] - ETA: 0s - loss: 0.2275 - dice_coefficient: 0.8557\n",
            "Epoch 00127: loss did not improve from 0.16045\n",
            "\n",
            "Epoch 00127: loss improved from 0.16045 to 0.15336, saving model to model-0.15.h5\n",
            "  3/409 [..............................] - ETA: 55s - loss: 0.1534 - dice_coefficient: 0.9135\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "  5/409 [..............................] - ETA: 40s - loss: 0.1831 - dice_coefficient: 0.8943\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "  7/409 [..............................] - ETA: 33s - loss: 0.1901 - dice_coefficient: 0.8881\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "  8/409 [..............................] - ETA: 31s - loss: 0.2023 - dice_coefficient: 0.8740\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 10/409 [..............................] - ETA: 28s - loss: 0.2157 - dice_coefficient: 0.8634\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 12/409 [..............................] - ETA: 25s - loss: 0.2052 - dice_coefficient: 0.8685\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 14/409 [>.............................] - ETA: 24s - loss: 0.2071 - dice_coefficient: 0.8666\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 16/409 [>.............................] - ETA: 23s - loss: 0.2096 - dice_coefficient: 0.8636\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 18/409 [>.............................] - ETA: 22s - loss: 0.2064 - dice_coefficient: 0.8663\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 19/409 [>.............................] - ETA: 22s - loss: 0.2072 - dice_coefficient: 0.8662\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 20/409 [>.............................] - ETA: 22s - loss: 0.2044 - dice_coefficient: 0.8683\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 22/409 [>.............................] - ETA: 22s - loss: 0.2180 - dice_coefficient: 0.8675\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 24/409 [>.............................] - ETA: 21s - loss: 0.2260 - dice_coefficient: 0.8634\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 26/409 [>.............................] - ETA: 20s - loss: 0.8345 - dice_coefficient: 0.8334\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 28/409 [=>............................] - ETA: 20s - loss: 0.7900 - dice_coefficient: 0.8348\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 30/409 [=>............................] - ETA: 20s - loss: 0.7660 - dice_coefficient: 0.8270\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 31/409 [=>............................] - ETA: 20s - loss: 0.7450 - dice_coefficient: 0.8303\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 33/409 [=>............................] - ETA: 19s - loss: 0.7154 - dice_coefficient: 0.8325\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 35/409 [=>............................] - ETA: 19s - loss: 0.6856 - dice_coefficient: 0.8344\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 37/409 [=>............................] - ETA: 19s - loss: 0.6674 - dice_coefficient: 0.8376\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 39/409 [=>............................] - ETA: 18s - loss: 0.6429 - dice_coefficient: 0.8412\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 41/409 [==>...........................] - ETA: 18s - loss: 0.6201 - dice_coefficient: 0.8436\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 43/409 [==>...........................] - ETA: 18s - loss: 0.5992 - dice_coefficient: 0.8460\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 45/409 [==>...........................] - ETA: 18s - loss: 0.5826 - dice_coefficient: 0.8457\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 47/409 [==>...........................] - ETA: 17s - loss: 0.5742 - dice_coefficient: 0.8409\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 48/409 [==>...........................] - ETA: 17s - loss: 0.5670 - dice_coefficient: 0.8416\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 50/409 [==>...........................] - ETA: 17s - loss: 0.5568 - dice_coefficient: 0.8392\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 52/409 [==>...........................] - ETA: 17s - loss: 0.5444 - dice_coefficient: 0.8396\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 53/409 [==>...........................] - ETA: 17s - loss: 0.5376 - dice_coefficient: 0.8407\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 54/409 [==>...........................] - ETA: 17s - loss: 0.5320 - dice_coefficient: 0.8405\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 56/409 [===>..........................] - ETA: 17s - loss: 0.5189 - dice_coefficient: 0.8421\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 58/409 [===>..........................] - ETA: 17s - loss: 0.5145 - dice_coefficient: 0.8386\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 60/409 [===>..........................] - ETA: 16s - loss: 0.5066 - dice_coefficient: 0.8366\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 62/409 [===>..........................] - ETA: 16s - loss: 0.4984 - dice_coefficient: 0.8358\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 64/409 [===>..........................] - ETA: 16s - loss: 0.4896 - dice_coefficient: 0.8368\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 66/409 [===>..........................] - ETA: 16s - loss: 0.4781 - dice_coefficient: 0.8401\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 68/409 [===>..........................] - ETA: 16s - loss: 0.4695 - dice_coefficient: 0.8406\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 70/409 [====>.........................] - ETA: 16s - loss: 0.4623 - dice_coefficient: 0.8408\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 72/409 [====>.........................] - ETA: 15s - loss: 0.4549 - dice_coefficient: 0.8421\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 74/409 [====>.........................] - ETA: 15s - loss: 0.4495 - dice_coefficient: 0.8425\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 76/409 [====>.........................] - ETA: 15s - loss: 0.4410 - dice_coefficient: 0.8447\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 78/409 [====>.........................] - ETA: 15s - loss: 0.4368 - dice_coefficient: 0.8431\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 80/409 [====>.........................] - ETA: 15s - loss: 0.4296 - dice_coefficient: 0.8445\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 82/409 [=====>........................] - ETA: 14s - loss: 0.4247 - dice_coefficient: 0.8438\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 84/409 [=====>........................] - ETA: 14s - loss: 0.4213 - dice_coefficient: 0.8425\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 86/409 [=====>........................] - ETA: 14s - loss: 0.4177 - dice_coefficient: 0.8416\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 88/409 [=====>........................] - ETA: 14s - loss: 0.4141 - dice_coefficient: 0.8415\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 90/409 [=====>........................] - ETA: 14s - loss: 0.4118 - dice_coefficient: 0.8402\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 92/409 [=====>........................] - ETA: 14s - loss: 0.4127 - dice_coefficient: 0.8367\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 94/409 [=====>........................] - ETA: 14s - loss: 0.4097 - dice_coefficient: 0.8356\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 96/409 [======>.......................] - ETA: 13s - loss: 0.4048 - dice_coefficient: 0.8368\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            " 98/409 [======>.......................] - ETA: 13s - loss: 0.4012 - dice_coefficient: 0.8366\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "100/409 [======>.......................] - ETA: 13s - loss: 0.3995 - dice_coefficient: 0.8349\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "102/409 [======>.......................] - ETA: 13s - loss: 0.3974 - dice_coefficient: 0.8344\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "104/409 [======>.......................] - ETA: 13s - loss: 0.3969 - dice_coefficient: 0.8325\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "106/409 [======>.......................] - ETA: 13s - loss: 0.3951 - dice_coefficient: 0.8315\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "108/409 [======>.......................] - ETA: 13s - loss: 0.3911 - dice_coefficient: 0.8332\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "110/409 [=======>......................] - ETA: 13s - loss: 0.3866 - dice_coefficient: 0.8350\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "112/409 [=======>......................] - ETA: 12s - loss: 0.3854 - dice_coefficient: 0.8334\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "114/409 [=======>......................] - ETA: 12s - loss: 0.3824 - dice_coefficient: 0.8345\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "116/409 [=======>......................] - ETA: 12s - loss: 0.3802 - dice_coefficient: 0.8354\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "118/409 [=======>......................] - ETA: 12s - loss: 0.3772 - dice_coefficient: 0.8362\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "120/409 [=======>......................] - ETA: 12s - loss: 0.3780 - dice_coefficient: 0.8339\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "122/409 [=======>......................] - ETA: 12s - loss: 0.3777 - dice_coefficient: 0.8323\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "124/409 [========>.....................] - ETA: 12s - loss: 0.3755 - dice_coefficient: 0.8331\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "126/409 [========>.....................] - ETA: 12s - loss: 0.3733 - dice_coefficient: 0.8331\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "128/409 [========>.....................] - ETA: 11s - loss: 0.3727 - dice_coefficient: 0.8319\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "130/409 [========>.....................] - ETA: 11s - loss: 0.3720 - dice_coefficient: 0.8306\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "132/409 [========>.....................] - ETA: 11s - loss: 0.3705 - dice_coefficient: 0.8300\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "134/409 [========>.....................] - ETA: 11s - loss: 0.3683 - dice_coefficient: 0.8302\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "136/409 [========>.....................] - ETA: 11s - loss: 0.3662 - dice_coefficient: 0.8301\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "138/409 [=========>....................] - ETA: 11s - loss: 0.3641 - dice_coefficient: 0.8305\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "140/409 [=========>....................] - ETA: 11s - loss: 0.3621 - dice_coefficient: 0.8311\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "142/409 [=========>....................] - ETA: 11s - loss: 0.3600 - dice_coefficient: 0.8313\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "144/409 [=========>....................] - ETA: 11s - loss: 0.3572 - dice_coefficient: 0.8327\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "146/409 [=========>....................] - ETA: 10s - loss: 0.3543 - dice_coefficient: 0.8340\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "148/409 [=========>....................] - ETA: 10s - loss: 0.3552 - dice_coefficient: 0.8328\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "150/409 [==========>...................] - ETA: 10s - loss: 0.3557 - dice_coefficient: 0.8315\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "152/409 [==========>...................] - ETA: 10s - loss: 0.3529 - dice_coefficient: 0.8329\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "154/409 [==========>...................] - ETA: 10s - loss: 0.3502 - dice_coefficient: 0.8340\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "156/409 [==========>...................] - ETA: 10s - loss: 0.3498 - dice_coefficient: 0.8331\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "158/409 [==========>...................] - ETA: 10s - loss: 0.3478 - dice_coefficient: 0.8338\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "160/409 [==========>...................] - ETA: 10s - loss: 0.3461 - dice_coefficient: 0.8340\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "162/409 [==========>...................] - ETA: 10s - loss: 0.3445 - dice_coefficient: 0.8342\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "164/409 [===========>..................] - ETA: 10s - loss: 0.3419 - dice_coefficient: 0.8355\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "166/409 [===========>..................] - ETA: 9s - loss: 0.3404 - dice_coefficient: 0.8355 \n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "168/409 [===========>..................] - ETA: 9s - loss: 0.3387 - dice_coefficient: 0.8358\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "170/409 [===========>..................] - ETA: 9s - loss: 0.3370 - dice_coefficient: 0.8362\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "172/409 [===========>..................] - ETA: 9s - loss: 0.3362 - dice_coefficient: 0.8357\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "174/409 [===========>..................] - ETA: 9s - loss: 0.3354 - dice_coefficient: 0.8357\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "176/409 [===========>..................] - ETA: 9s - loss: 0.3362 - dice_coefficient: 0.8344\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "178/409 [============>.................] - ETA: 9s - loss: 0.3342 - dice_coefficient: 0.8352\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "180/409 [============>.................] - ETA: 9s - loss: 0.3349 - dice_coefficient: 0.8338\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "182/409 [============>.................] - ETA: 9s - loss: 0.3334 - dice_coefficient: 0.8341\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "184/409 [============>.................] - ETA: 9s - loss: 0.3329 - dice_coefficient: 0.8336\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "186/409 [============>.................] - ETA: 9s - loss: 0.3312 - dice_coefficient: 0.8342\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "188/409 [============>.................] - ETA: 8s - loss: 0.3291 - dice_coefficient: 0.8352\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "190/409 [============>.................] - ETA: 8s - loss: 0.3308 - dice_coefficient: 0.8334\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "192/409 [=============>................] - ETA: 8s - loss: 0.3299 - dice_coefficient: 0.8332\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "194/409 [=============>................] - ETA: 8s - loss: 0.3281 - dice_coefficient: 0.8340\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "196/409 [=============>................] - ETA: 8s - loss: 0.3272 - dice_coefficient: 0.8344\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "198/409 [=============>................] - ETA: 8s - loss: 0.3263 - dice_coefficient: 0.8346\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "200/409 [=============>................] - ETA: 8s - loss: 0.3251 - dice_coefficient: 0.8350\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "202/409 [=============>................] - ETA: 8s - loss: 0.3231 - dice_coefficient: 0.8359\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "204/409 [=============>................] - ETA: 8s - loss: 0.3236 - dice_coefficient: 0.8346\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "206/409 [==============>...............] - ETA: 8s - loss: 0.3226 - dice_coefficient: 0.8348\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "208/409 [==============>...............] - ETA: 8s - loss: 0.3213 - dice_coefficient: 0.8352\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "210/409 [==============>...............] - ETA: 7s - loss: 0.3206 - dice_coefficient: 0.8353\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "212/409 [==============>...............] - ETA: 7s - loss: 0.3202 - dice_coefficient: 0.8353\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "214/409 [==============>...............] - ETA: 7s - loss: 0.3189 - dice_coefficient: 0.8356\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "216/409 [==============>...............] - ETA: 7s - loss: 0.3187 - dice_coefficient: 0.8354\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "218/409 [==============>...............] - ETA: 7s - loss: 0.3177 - dice_coefficient: 0.8357\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "220/409 [===============>..............] - ETA: 7s - loss: 0.3169 - dice_coefficient: 0.8359\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "222/409 [===============>..............] - ETA: 7s - loss: 0.3156 - dice_coefficient: 0.8363\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "224/409 [===============>..............] - ETA: 7s - loss: 0.3146 - dice_coefficient: 0.8363\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "226/409 [===============>..............] - ETA: 7s - loss: 0.3138 - dice_coefficient: 0.8368\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "228/409 [===============>..............] - ETA: 7s - loss: 0.3125 - dice_coefficient: 0.8374\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "230/409 [===============>..............] - ETA: 7s - loss: 0.3122 - dice_coefficient: 0.8371\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "232/409 [================>.............] - ETA: 6s - loss: 0.3108 - dice_coefficient: 0.8377\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "234/409 [================>.............] - ETA: 6s - loss: 0.3099 - dice_coefficient: 0.8379\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "236/409 [================>.............] - ETA: 6s - loss: 0.3091 - dice_coefficient: 0.8382\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "238/409 [================>.............] - ETA: 6s - loss: 0.3079 - dice_coefficient: 0.8388\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "240/409 [================>.............] - ETA: 6s - loss: 0.3087 - dice_coefficient: 0.8382\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "242/409 [================>.............] - ETA: 6s - loss: 0.3084 - dice_coefficient: 0.8379\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "244/409 [================>.............] - ETA: 6s - loss: 0.3075 - dice_coefficient: 0.8382\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "246/409 [=================>............] - ETA: 6s - loss: 0.3069 - dice_coefficient: 0.8381\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "248/409 [=================>............] - ETA: 6s - loss: 0.3064 - dice_coefficient: 0.8380\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "250/409 [=================>............] - ETA: 6s - loss: 0.3058 - dice_coefficient: 0.8379\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "252/409 [=================>............] - ETA: 6s - loss: 0.3053 - dice_coefficient: 0.8377\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "254/409 [=================>............] - ETA: 6s - loss: 0.3041 - dice_coefficient: 0.8384\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "256/409 [=================>............] - ETA: 5s - loss: 0.3039 - dice_coefficient: 0.8381\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "258/409 [=================>............] - ETA: 5s - loss: 0.3032 - dice_coefficient: 0.8382\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "260/409 [==================>...........] - ETA: 5s - loss: 0.3029 - dice_coefficient: 0.8380\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "262/409 [==================>...........] - ETA: 5s - loss: 0.3022 - dice_coefficient: 0.8383\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "264/409 [==================>...........] - ETA: 5s - loss: 0.3020 - dice_coefficient: 0.8379\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "266/409 [==================>...........] - ETA: 5s - loss: 0.3015 - dice_coefficient: 0.8379\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "268/409 [==================>...........] - ETA: 5s - loss: 0.3017 - dice_coefficient: 0.8373\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "270/409 [==================>...........] - ETA: 5s - loss: 0.3010 - dice_coefficient: 0.8378\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "272/409 [==================>...........] - ETA: 5s - loss: 0.3010 - dice_coefficient: 0.8372\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "274/409 [===================>..........] - ETA: 5s - loss: 0.3006 - dice_coefficient: 0.8372\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "276/409 [===================>..........] - ETA: 5s - loss: 0.3000 - dice_coefficient: 0.8374\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "278/409 [===================>..........] - ETA: 5s - loss: 0.2998 - dice_coefficient: 0.8370\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "280/409 [===================>..........] - ETA: 5s - loss: 0.2989 - dice_coefficient: 0.8375\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "282/409 [===================>..........] - ETA: 4s - loss: 0.2982 - dice_coefficient: 0.8376\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "284/409 [===================>..........] - ETA: 4s - loss: 0.2998 - dice_coefficient: 0.8365\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "286/409 [===================>..........] - ETA: 4s - loss: 0.2991 - dice_coefficient: 0.8366\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "288/409 [====================>.........] - ETA: 4s - loss: 0.3005 - dice_coefficient: 0.8357\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "290/409 [====================>.........] - ETA: 4s - loss: 0.2999 - dice_coefficient: 0.8357\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "292/409 [====================>.........] - ETA: 4s - loss: 0.2989 - dice_coefficient: 0.8362\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "294/409 [====================>.........] - ETA: 4s - loss: 0.2985 - dice_coefficient: 0.8361\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "296/409 [====================>.........] - ETA: 4s - loss: 0.2976 - dice_coefficient: 0.8365\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "298/409 [====================>.........] - ETA: 4s - loss: 0.2983 - dice_coefficient: 0.8363\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "300/409 [=====================>........] - ETA: 4s - loss: 0.2986 - dice_coefficient: 0.8356\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "302/409 [=====================>........] - ETA: 4s - loss: 0.2981 - dice_coefficient: 0.8356\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "304/409 [=====================>........] - ETA: 4s - loss: 0.2975 - dice_coefficient: 0.8359\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "306/409 [=====================>........] - ETA: 3s - loss: 0.2970 - dice_coefficient: 0.8361\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "308/409 [=====================>........] - ETA: 3s - loss: 0.2958 - dice_coefficient: 0.8367\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "310/409 [=====================>........] - ETA: 3s - loss: 0.2953 - dice_coefficient: 0.8369\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "312/409 [=====================>........] - ETA: 3s - loss: 0.2946 - dice_coefficient: 0.8371\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "314/409 [======================>.......] - ETA: 3s - loss: 0.2960 - dice_coefficient: 0.8359\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "316/409 [======================>.......] - ETA: 3s - loss: 0.2954 - dice_coefficient: 0.8364\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "318/409 [======================>.......] - ETA: 3s - loss: 0.2947 - dice_coefficient: 0.8367\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "320/409 [======================>.......] - ETA: 3s - loss: 0.2947 - dice_coefficient: 0.8365\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "322/409 [======================>.......] - ETA: 3s - loss: 0.2950 - dice_coefficient: 0.8360\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "324/409 [======================>.......] - ETA: 3s - loss: 0.2945 - dice_coefficient: 0.8363\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "326/409 [======================>.......] - ETA: 3s - loss: 0.2949 - dice_coefficient: 0.8356\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "328/409 [=======================>......] - ETA: 3s - loss: 0.2948 - dice_coefficient: 0.8354\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "330/409 [=======================>......] - ETA: 3s - loss: 0.2943 - dice_coefficient: 0.8354\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "332/409 [=======================>......] - ETA: 2s - loss: 0.2940 - dice_coefficient: 0.8356\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "334/409 [=======================>......] - ETA: 2s - loss: 0.2939 - dice_coefficient: 0.8353\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "336/409 [=======================>......] - ETA: 2s - loss: 0.2934 - dice_coefficient: 0.8357\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "338/409 [=======================>......] - ETA: 2s - loss: 0.2929 - dice_coefficient: 0.8359\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "340/409 [=======================>......] - ETA: 2s - loss: 0.2921 - dice_coefficient: 0.8363\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "342/409 [========================>.....] - ETA: 2s - loss: 0.2934 - dice_coefficient: 0.8360\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "344/409 [========================>.....] - ETA: 2s - loss: 0.2941 - dice_coefficient: 0.8353\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "346/409 [========================>.....] - ETA: 2s - loss: 0.2936 - dice_coefficient: 0.8353\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "348/409 [========================>.....] - ETA: 2s - loss: 0.2930 - dice_coefficient: 0.8357\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "350/409 [========================>.....] - ETA: 2s - loss: 0.2927 - dice_coefficient: 0.8358\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "352/409 [========================>.....] - ETA: 2s - loss: 0.2934 - dice_coefficient: 0.8351\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "354/409 [========================>.....] - ETA: 2s - loss: 0.2929 - dice_coefficient: 0.8353\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "356/409 [=========================>....] - ETA: 2s - loss: 0.2925 - dice_coefficient: 0.8354\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "358/409 [=========================>....] - ETA: 1s - loss: 0.2925 - dice_coefficient: 0.8351\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "360/409 [=========================>....] - ETA: 1s - loss: 0.2922 - dice_coefficient: 0.8351\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "362/409 [=========================>....] - ETA: 1s - loss: 0.2919 - dice_coefficient: 0.8352\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "364/409 [=========================>....] - ETA: 1s - loss: 0.2917 - dice_coefficient: 0.8350\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "366/409 [=========================>....] - ETA: 1s - loss: 0.2912 - dice_coefficient: 0.8354\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "368/409 [=========================>....] - ETA: 1s - loss: 0.2910 - dice_coefficient: 0.8353\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "370/409 [==========================>...] - ETA: 1s - loss: 0.2904 - dice_coefficient: 0.8357\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "372/409 [==========================>...] - ETA: 1s - loss: 0.2898 - dice_coefficient: 0.8361\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "374/409 [==========================>...] - ETA: 1s - loss: 0.2893 - dice_coefficient: 0.8365\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "376/409 [==========================>...] - ETA: 1s - loss: 0.2893 - dice_coefficient: 0.8362\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "378/409 [==========================>...] - ETA: 1s - loss: 0.2897 - dice_coefficient: 0.8357\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "380/409 [==========================>...] - ETA: 1s - loss: 0.2893 - dice_coefficient: 0.8357\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "382/409 [===========================>..] - ETA: 1s - loss: 0.2886 - dice_coefficient: 0.8361\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "384/409 [===========================>..] - ETA: 0s - loss: 0.2883 - dice_coefficient: 0.8360\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "386/409 [===========================>..] - ETA: 0s - loss: 0.2878 - dice_coefficient: 0.8361\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "388/409 [===========================>..] - ETA: 0s - loss: 0.2874 - dice_coefficient: 0.8362\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "390/409 [===========================>..] - ETA: 0s - loss: 0.2883 - dice_coefficient: 0.8352\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "392/409 [===========================>..] - ETA: 0s - loss: 0.2888 - dice_coefficient: 0.8351\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "394/409 [===========================>..] - ETA: 0s - loss: 0.2883 - dice_coefficient: 0.8354\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "396/409 [============================>.] - ETA: 0s - loss: 0.2883 - dice_coefficient: 0.8351\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "398/409 [============================>.] - ETA: 0s - loss: 0.2880 - dice_coefficient: 0.8351\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "400/409 [============================>.] - ETA: 0s - loss: 0.2878 - dice_coefficient: 0.8352\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "402/409 [============================>.] - ETA: 0s - loss: 0.2885 - dice_coefficient: 0.8344\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "404/409 [============================>.] - ETA: 0s - loss: 0.2878 - dice_coefficient: 0.8349\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "406/409 [============================>.] - ETA: 0s - loss: 0.2879 - dice_coefficient: 0.8347\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "408/409 [============================>.] - ETA: 0s - loss: 0.2873 - dice_coefficient: 0.8351\n",
            "Epoch 00127: loss did not improve from 0.15336\n",
            "409/409 [==============================] - 15s 38ms/step - loss: 0.2875 - dice_coefficient: 0.8348 - lr: 1.0000e-04\n",
            "Epoch 128/130\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "  1/409 [..............................] - ETA: 0s - loss: 0.1555 - dice_coefficient: 0.9032\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "  3/409 [..............................] - ETA: 9s - loss: 0.1553 - dice_coefficient: 0.9090\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "  5/409 [..............................] - ETA: 11s - loss: 0.1735 - dice_coefficient: 0.9028\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "  7/409 [..............................] - ETA: 12s - loss: 0.1704 - dice_coefficient: 0.9025\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "  9/409 [..............................] - ETA: 12s - loss: 0.1931 - dice_coefficient: 0.8789\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 11/409 [..............................] - ETA: 12s - loss: 0.1980 - dice_coefficient: 0.8770\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 13/409 [..............................] - ETA: 13s - loss: 0.2004 - dice_coefficient: 0.8757\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 15/409 [>.............................] - ETA: 13s - loss: 0.1962 - dice_coefficient: 0.8807\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 17/409 [>.............................] - ETA: 13s - loss: 0.1953 - dice_coefficient: 0.8806\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 19/409 [>.............................] - ETA: 13s - loss: 0.2314 - dice_coefficient: 0.8533\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 21/409 [>.............................] - ETA: 13s - loss: 0.2337 - dice_coefficient: 0.8497\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 23/409 [>.............................] - ETA: 13s - loss: 0.2421 - dice_coefficient: 0.8453\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 25/409 [>.............................] - ETA: 13s - loss: 0.2470 - dice_coefficient: 0.8399\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 27/409 [>.............................] - ETA: 13s - loss: 0.2487 - dice_coefficient: 0.8437\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 29/409 [=>............................] - ETA: 13s - loss: 0.2441 - dice_coefficient: 0.8489\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 31/409 [=>............................] - ETA: 13s - loss: 0.2406 - dice_coefficient: 0.8500\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 33/409 [=>............................] - ETA: 13s - loss: 0.2400 - dice_coefficient: 0.8494\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 35/409 [=>............................] - ETA: 13s - loss: 0.2422 - dice_coefficient: 0.8476\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 37/409 [=>............................] - ETA: 12s - loss: 0.2466 - dice_coefficient: 0.8436\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 39/409 [=>............................] - ETA: 12s - loss: 0.2424 - dice_coefficient: 0.8461\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 41/409 [==>...........................] - ETA: 12s - loss: 0.2403 - dice_coefficient: 0.8475\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 43/409 [==>...........................] - ETA: 12s - loss: 0.2468 - dice_coefficient: 0.8415\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 45/409 [==>...........................] - ETA: 12s - loss: 0.2438 - dice_coefficient: 0.8433\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 47/409 [==>...........................] - ETA: 12s - loss: 0.2443 - dice_coefficient: 0.8413\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 49/409 [==>...........................] - ETA: 12s - loss: 0.2427 - dice_coefficient: 0.8429\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 51/409 [==>...........................] - ETA: 12s - loss: 0.2407 - dice_coefficient: 0.8438\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 53/409 [==>...........................] - ETA: 12s - loss: 0.2389 - dice_coefficient: 0.8453\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 55/409 [===>..........................] - ETA: 12s - loss: 0.2405 - dice_coefficient: 0.8432\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 57/409 [===>..........................] - ETA: 12s - loss: 0.2476 - dice_coefficient: 0.8377\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 59/409 [===>..........................] - ETA: 12s - loss: 0.2476 - dice_coefficient: 0.8372\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 61/409 [===>..........................] - ETA: 12s - loss: 0.2484 - dice_coefficient: 0.8369\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 63/409 [===>..........................] - ETA: 12s - loss: 0.2468 - dice_coefficient: 0.8384\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 65/409 [===>..........................] - ETA: 12s - loss: 0.2450 - dice_coefficient: 0.8396\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 67/409 [===>..........................] - ETA: 12s - loss: 0.2419 - dice_coefficient: 0.8423\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 69/409 [====>.........................] - ETA: 11s - loss: 0.2451 - dice_coefficient: 0.8395\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 71/409 [====>.........................] - ETA: 11s - loss: 0.2471 - dice_coefficient: 0.8377\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 73/409 [====>.........................] - ETA: 11s - loss: 0.2456 - dice_coefficient: 0.8383\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 75/409 [====>.........................] - ETA: 11s - loss: 0.2472 - dice_coefficient: 0.8371\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 77/409 [====>.........................] - ETA: 11s - loss: 0.2545 - dice_coefficient: 0.8319\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 79/409 [====>.........................] - ETA: 11s - loss: 0.2542 - dice_coefficient: 0.8333\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 81/409 [====>.........................] - ETA: 11s - loss: 0.2531 - dice_coefficient: 0.8342\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 83/409 [=====>........................] - ETA: 11s - loss: 0.2512 - dice_coefficient: 0.8350\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 85/409 [=====>........................] - ETA: 11s - loss: 0.2512 - dice_coefficient: 0.8368\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 87/409 [=====>........................] - ETA: 11s - loss: 0.4333 - dice_coefficient: 0.8275\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 89/409 [=====>........................] - ETA: 11s - loss: 0.4281 - dice_coefficient: 0.8293\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 91/409 [=====>........................] - ETA: 11s - loss: 0.4239 - dice_coefficient: 0.8302\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 93/409 [=====>........................] - ETA: 11s - loss: 0.4201 - dice_coefficient: 0.8302\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 95/409 [=====>........................] - ETA: 11s - loss: 0.4169 - dice_coefficient: 0.8298\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 97/409 [======>.......................] - ETA: 11s - loss: 0.4119 - dice_coefficient: 0.8309\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            " 99/409 [======>.......................] - ETA: 10s - loss: 0.4088 - dice_coefficient: 0.8303\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "101/409 [======>.......................] - ETA: 10s - loss: 0.4046 - dice_coefficient: 0.8310\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "103/409 [======>.......................] - ETA: 10s - loss: 0.4009 - dice_coefficient: 0.8317\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "105/409 [======>.......................] - ETA: 10s - loss: 0.3999 - dice_coefficient: 0.8304\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "107/409 [======>.......................] - ETA: 10s - loss: 0.3949 - dice_coefficient: 0.8322\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "109/409 [======>.......................] - ETA: 10s - loss: 0.3914 - dice_coefficient: 0.8326\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "111/409 [=======>......................] - ETA: 10s - loss: 0.3871 - dice_coefficient: 0.8342\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "113/409 [=======>......................] - ETA: 10s - loss: 0.3849 - dice_coefficient: 0.8340\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "115/409 [=======>......................] - ETA: 10s - loss: 0.3808 - dice_coefficient: 0.8352\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "117/409 [=======>......................] - ETA: 10s - loss: 0.3807 - dice_coefficient: 0.8336\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "119/409 [=======>......................] - ETA: 10s - loss: 0.3812 - dice_coefficient: 0.8319\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "121/409 [=======>......................] - ETA: 10s - loss: 0.3778 - dice_coefficient: 0.8332\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "123/409 [========>.....................] - ETA: 10s - loss: 0.3758 - dice_coefficient: 0.8329\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "125/409 [========>.....................] - ETA: 10s - loss: 0.3767 - dice_coefficient: 0.8310\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "127/409 [========>.....................] - ETA: 10s - loss: 0.3751 - dice_coefficient: 0.8304\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "129/409 [========>.....................] - ETA: 9s - loss: 0.3719 - dice_coefficient: 0.8315 \n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "131/409 [========>.....................] - ETA: 9s - loss: 0.3695 - dice_coefficient: 0.8321\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "133/409 [========>.....................] - ETA: 9s - loss: 0.3669 - dice_coefficient: 0.8331\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "135/409 [========>.....................] - ETA: 9s - loss: 0.3651 - dice_coefficient: 0.8330\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "137/409 [=========>....................] - ETA: 9s - loss: 0.3636 - dice_coefficient: 0.8331\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "139/409 [=========>....................] - ETA: 9s - loss: 0.3610 - dice_coefficient: 0.8337\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "141/409 [=========>....................] - ETA: 9s - loss: 0.3586 - dice_coefficient: 0.8340\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "143/409 [=========>....................] - ETA: 9s - loss: 0.3564 - dice_coefficient: 0.8342\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "145/409 [=========>....................] - ETA: 9s - loss: 0.3539 - dice_coefficient: 0.8351\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "147/409 [=========>....................] - ETA: 9s - loss: 0.3524 - dice_coefficient: 0.8350\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "149/409 [=========>....................] - ETA: 9s - loss: 0.3498 - dice_coefficient: 0.8363\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "151/409 [==========>...................] - ETA: 9s - loss: 0.3477 - dice_coefficient: 0.8367\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "153/409 [==========>...................] - ETA: 9s - loss: 0.3457 - dice_coefficient: 0.8378\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "155/409 [==========>...................] - ETA: 9s - loss: 0.3443 - dice_coefficient: 0.8374\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "157/409 [==========>...................] - ETA: 8s - loss: 0.3425 - dice_coefficient: 0.8377\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "159/409 [==========>...................] - ETA: 8s - loss: 0.3411 - dice_coefficient: 0.8377\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "161/409 [==========>...................] - ETA: 8s - loss: 0.3412 - dice_coefficient: 0.8366\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "163/409 [==========>...................] - ETA: 8s - loss: 0.3407 - dice_coefficient: 0.8358\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "165/409 [===========>..................] - ETA: 8s - loss: 0.3380 - dice_coefficient: 0.8372\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "167/409 [===========>..................] - ETA: 8s - loss: 0.3378 - dice_coefficient: 0.8363\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "169/409 [===========>..................] - ETA: 8s - loss: 0.3363 - dice_coefficient: 0.8367\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "171/409 [===========>..................] - ETA: 8s - loss: 0.3343 - dice_coefficient: 0.8374\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "173/409 [===========>..................] - ETA: 8s - loss: 0.3341 - dice_coefficient: 0.8378\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "175/409 [===========>..................] - ETA: 8s - loss: 0.3324 - dice_coefficient: 0.8385\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "177/409 [===========>..................] - ETA: 8s - loss: 0.3308 - dice_coefficient: 0.8389\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "179/409 [============>.................] - ETA: 8s - loss: 0.3305 - dice_coefficient: 0.8385\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "181/409 [============>.................] - ETA: 8s - loss: 0.3287 - dice_coefficient: 0.8391\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "183/409 [============>.................] - ETA: 8s - loss: 0.3266 - dice_coefficient: 0.8398\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "185/409 [============>.................] - ETA: 7s - loss: 0.3260 - dice_coefficient: 0.8397\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "187/409 [============>.................] - ETA: 7s - loss: 0.3249 - dice_coefficient: 0.8396\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "189/409 [============>.................] - ETA: 7s - loss: 0.3229 - dice_coefficient: 0.8404\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "191/409 [=============>................] - ETA: 7s - loss: 0.3215 - dice_coefficient: 0.8408\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "193/409 [=============>................] - ETA: 7s - loss: 0.3199 - dice_coefficient: 0.8414\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "195/409 [=============>................] - ETA: 7s - loss: 0.3182 - dice_coefficient: 0.8422\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "197/409 [=============>................] - ETA: 7s - loss: 0.3178 - dice_coefficient: 0.8417\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "199/409 [=============>................] - ETA: 7s - loss: 0.3163 - dice_coefficient: 0.8421\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "201/409 [=============>................] - ETA: 7s - loss: 0.3161 - dice_coefficient: 0.8414\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "203/409 [=============>................] - ETA: 7s - loss: 0.3146 - dice_coefficient: 0.8420\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "205/409 [==============>...............] - ETA: 7s - loss: 0.3146 - dice_coefficient: 0.8415\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "207/409 [==============>...............] - ETA: 7s - loss: 0.3145 - dice_coefficient: 0.8408\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "209/409 [==============>...............] - ETA: 7s - loss: 0.3142 - dice_coefficient: 0.8403\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "211/409 [==============>...............] - ETA: 7s - loss: 0.3130 - dice_coefficient: 0.8406\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "213/409 [==============>...............] - ETA: 6s - loss: 0.3113 - dice_coefficient: 0.8414\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "215/409 [==============>...............] - ETA: 6s - loss: 0.3100 - dice_coefficient: 0.8417\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "217/409 [==============>...............] - ETA: 6s - loss: 0.3120 - dice_coefficient: 0.8401\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "219/409 [===============>..............] - ETA: 6s - loss: 0.3117 - dice_coefficient: 0.8397\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "221/409 [===============>..............] - ETA: 6s - loss: 0.3103 - dice_coefficient: 0.8403\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "223/409 [===============>..............] - ETA: 6s - loss: 0.3098 - dice_coefficient: 0.8401\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "225/409 [===============>..............] - ETA: 6s - loss: 0.3089 - dice_coefficient: 0.8404\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "227/409 [===============>..............] - ETA: 6s - loss: 0.3087 - dice_coefficient: 0.8399\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "229/409 [===============>..............] - ETA: 6s - loss: 0.3083 - dice_coefficient: 0.8398\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "231/409 [===============>..............] - ETA: 6s - loss: 0.3075 - dice_coefficient: 0.8399\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "233/409 [================>.............] - ETA: 6s - loss: 0.3077 - dice_coefficient: 0.8390\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "235/409 [================>.............] - ETA: 6s - loss: 0.3067 - dice_coefficient: 0.8394\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "237/409 [================>.............] - ETA: 6s - loss: 0.3059 - dice_coefficient: 0.8394\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "239/409 [================>.............] - ETA: 6s - loss: 0.3061 - dice_coefficient: 0.8388\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "241/409 [================>.............] - ETA: 5s - loss: 0.3052 - dice_coefficient: 0.8392\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "243/409 [================>.............] - ETA: 5s - loss: 0.3048 - dice_coefficient: 0.8391\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "245/409 [================>.............] - ETA: 5s - loss: 0.3046 - dice_coefficient: 0.8386\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "247/409 [=================>............] - ETA: 5s - loss: 0.3058 - dice_coefficient: 0.8374\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "249/409 [=================>............] - ETA: 5s - loss: 0.3046 - dice_coefficient: 0.8378\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "251/409 [=================>............] - ETA: 5s - loss: 0.3039 - dice_coefficient: 0.8379\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "253/409 [=================>............] - ETA: 5s - loss: 0.3026 - dice_coefficient: 0.8383\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "255/409 [=================>............] - ETA: 5s - loss: 0.3017 - dice_coefficient: 0.8386\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "257/409 [=================>............] - ETA: 5s - loss: 0.3007 - dice_coefficient: 0.8394\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "259/409 [=================>............] - ETA: 5s - loss: 0.3006 - dice_coefficient: 0.8390\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "261/409 [==================>...........] - ETA: 5s - loss: 0.2996 - dice_coefficient: 0.8394\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "263/409 [==================>...........] - ETA: 5s - loss: 0.2988 - dice_coefficient: 0.8395\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "265/409 [==================>...........] - ETA: 5s - loss: 0.2975 - dice_coefficient: 0.8402\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "267/409 [==================>...........] - ETA: 5s - loss: 0.2966 - dice_coefficient: 0.8406\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "269/409 [==================>...........] - ETA: 4s - loss: 0.2963 - dice_coefficient: 0.8405\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "271/409 [==================>...........] - ETA: 4s - loss: 0.2959 - dice_coefficient: 0.8404\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "273/409 [===================>..........] - ETA: 4s - loss: 0.2962 - dice_coefficient: 0.8409\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "275/409 [===================>..........] - ETA: 4s - loss: 0.2960 - dice_coefficient: 0.8407\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "277/409 [===================>..........] - ETA: 4s - loss: 0.2961 - dice_coefficient: 0.8401\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "279/409 [===================>..........] - ETA: 4s - loss: 0.2964 - dice_coefficient: 0.8395\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "281/409 [===================>..........] - ETA: 4s - loss: 0.2955 - dice_coefficient: 0.8401\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "283/409 [===================>..........] - ETA: 4s - loss: 0.2952 - dice_coefficient: 0.8399\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "285/409 [===================>..........] - ETA: 4s - loss: 0.2946 - dice_coefficient: 0.8400\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "287/409 [====================>.........] - ETA: 4s - loss: 0.2960 - dice_coefficient: 0.8386\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "289/409 [====================>.........] - ETA: 4s - loss: 0.2968 - dice_coefficient: 0.8377\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "291/409 [====================>.........] - ETA: 4s - loss: 0.2965 - dice_coefficient: 0.8375\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "293/409 [====================>.........] - ETA: 4s - loss: 0.2960 - dice_coefficient: 0.8378\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "295/409 [====================>.........] - ETA: 4s - loss: 0.2963 - dice_coefficient: 0.8370\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "297/409 [====================>.........] - ETA: 3s - loss: 0.2959 - dice_coefficient: 0.8370\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "299/409 [====================>.........] - ETA: 3s - loss: 0.2964 - dice_coefficient: 0.8364\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "301/409 [=====================>........] - ETA: 3s - loss: 0.2960 - dice_coefficient: 0.8364\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "303/409 [=====================>........] - ETA: 3s - loss: 0.2953 - dice_coefficient: 0.8368\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "305/409 [=====================>........] - ETA: 3s - loss: 0.2945 - dice_coefficient: 0.8371\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "307/409 [=====================>........] - ETA: 3s - loss: 0.2938 - dice_coefficient: 0.8376\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "309/409 [=====================>........] - ETA: 3s - loss: 0.2933 - dice_coefficient: 0.8378\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "311/409 [=====================>........] - ETA: 3s - loss: 0.2926 - dice_coefficient: 0.8383\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "313/409 [=====================>........] - ETA: 3s - loss: 0.2923 - dice_coefficient: 0.8381\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "315/409 [======================>.......] - ETA: 3s - loss: 0.2918 - dice_coefficient: 0.8383\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "317/409 [======================>.......] - ETA: 3s - loss: 0.2914 - dice_coefficient: 0.8383\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "319/409 [======================>.......] - ETA: 3s - loss: 0.2910 - dice_coefficient: 0.8383\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "321/409 [======================>.......] - ETA: 3s - loss: 0.2904 - dice_coefficient: 0.8386\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "323/409 [======================>.......] - ETA: 3s - loss: 0.2897 - dice_coefficient: 0.8390\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "325/409 [======================>.......] - ETA: 2s - loss: 0.2901 - dice_coefficient: 0.8385\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "327/409 [======================>.......] - ETA: 2s - loss: 0.2894 - dice_coefficient: 0.8388\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "329/409 [=======================>......] - ETA: 2s - loss: 0.2906 - dice_coefficient: 0.8377\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "331/409 [=======================>......] - ETA: 2s - loss: 0.2903 - dice_coefficient: 0.8377\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "333/409 [=======================>......] - ETA: 2s - loss: 0.2894 - dice_coefficient: 0.8382\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "335/409 [=======================>......] - ETA: 2s - loss: 0.2895 - dice_coefficient: 0.8378\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "337/409 [=======================>......] - ETA: 2s - loss: 0.2896 - dice_coefficient: 0.8373\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "339/409 [=======================>......] - ETA: 2s - loss: 0.2893 - dice_coefficient: 0.8372\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "341/409 [========================>.....] - ETA: 2s - loss: 0.2892 - dice_coefficient: 0.8371\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "343/409 [========================>.....] - ETA: 2s - loss: 0.2888 - dice_coefficient: 0.8371\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "345/409 [========================>.....] - ETA: 2s - loss: 0.2882 - dice_coefficient: 0.8373\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "347/409 [========================>.....] - ETA: 2s - loss: 0.2875 - dice_coefficient: 0.8378\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "349/409 [========================>.....] - ETA: 2s - loss: 0.2868 - dice_coefficient: 0.8381\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "351/409 [========================>.....] - ETA: 2s - loss: 0.2864 - dice_coefficient: 0.8384\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "353/409 [========================>.....] - ETA: 1s - loss: 0.2858 - dice_coefficient: 0.8386\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "355/409 [=========================>....] - ETA: 1s - loss: 0.2853 - dice_coefficient: 0.8387\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "357/409 [=========================>....] - ETA: 1s - loss: 0.2847 - dice_coefficient: 0.8390\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "359/409 [=========================>....] - ETA: 1s - loss: 0.2841 - dice_coefficient: 0.8393\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "361/409 [=========================>....] - ETA: 1s - loss: 0.2848 - dice_coefficient: 0.8392\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "363/409 [=========================>....] - ETA: 1s - loss: 0.2841 - dice_coefficient: 0.8394\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "365/409 [=========================>....] - ETA: 1s - loss: 0.2836 - dice_coefficient: 0.8395\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "367/409 [=========================>....] - ETA: 1s - loss: 0.2841 - dice_coefficient: 0.8397\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "369/409 [==========================>...] - ETA: 1s - loss: 0.2854 - dice_coefficient: 0.8386\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "371/409 [==========================>...] - ETA: 1s - loss: 0.2856 - dice_coefficient: 0.8382\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "373/409 [==========================>...] - ETA: 1s - loss: 0.2849 - dice_coefficient: 0.8388\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "375/409 [==========================>...] - ETA: 1s - loss: 0.2853 - dice_coefficient: 0.8381\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "377/409 [==========================>...] - ETA: 1s - loss: 0.2847 - dice_coefficient: 0.8384\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "379/409 [==========================>...] - ETA: 1s - loss: 0.2842 - dice_coefficient: 0.8387\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "381/409 [==========================>...] - ETA: 0s - loss: 0.2836 - dice_coefficient: 0.8389\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "383/409 [===========================>..] - ETA: 0s - loss: 0.2831 - dice_coefficient: 0.8392\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "385/409 [===========================>..] - ETA: 0s - loss: 0.2835 - dice_coefficient: 0.8386\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "387/409 [===========================>..] - ETA: 0s - loss: 0.2837 - dice_coefficient: 0.8382\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "389/409 [===========================>..] - ETA: 0s - loss: 0.2848 - dice_coefficient: 0.8373\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "391/409 [===========================>..] - ETA: 0s - loss: 0.2841 - dice_coefficient: 0.8377\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "393/409 [===========================>..] - ETA: 0s - loss: 0.2849 - dice_coefficient: 0.8378\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "395/409 [===========================>..] - ETA: 0s - loss: 0.2848 - dice_coefficient: 0.8375\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "397/409 [============================>.] - ETA: 0s - loss: 0.2844 - dice_coefficient: 0.8376\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "399/409 [============================>.] - ETA: 0s - loss: 0.2839 - dice_coefficient: 0.8378\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "401/409 [============================>.] - ETA: 0s - loss: 0.2832 - dice_coefficient: 0.8382\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "403/409 [============================>.] - ETA: 0s - loss: 0.2825 - dice_coefficient: 0.8384\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "405/409 [============================>.] - ETA: 0s - loss: 0.2819 - dice_coefficient: 0.8387\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "407/409 [============================>.] - ETA: 0s - loss: 0.2823 - dice_coefficient: 0.8381\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.15336\n",
            "409/409 [==============================] - 15s 36ms/step - loss: 0.2820 - dice_coefficient: 0.8380 - lr: 1.0000e-04\n",
            "Epoch 129/130\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "  1/409 [..............................] - ETA: 0s - loss: 0.2210 - dice_coefficient: 0.8232\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "  3/409 [..............................] - ETA: 10s - loss: 0.1960 - dice_coefficient: 0.8596\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "  5/409 [..............................] - ETA: 11s - loss: 0.2288 - dice_coefficient: 0.8326\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "  7/409 [..............................] - ETA: 12s - loss: 0.2078 - dice_coefficient: 0.8568\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "  9/409 [..............................] - ETA: 12s - loss: 0.2078 - dice_coefficient: 0.8613\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 11/409 [..............................] - ETA: 12s - loss: 0.2017 - dice_coefficient: 0.8674\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 13/409 [..............................] - ETA: 13s - loss: 0.1991 - dice_coefficient: 0.8680\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 15/409 [>.............................] - ETA: 13s - loss: 0.1998 - dice_coefficient: 0.8659\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 17/409 [>.............................] - ETA: 13s - loss: 0.1977 - dice_coefficient: 0.8683\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 19/409 [>.............................] - ETA: 13s - loss: 0.1992 - dice_coefficient: 0.8682\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 21/409 [>.............................] - ETA: 13s - loss: 0.1985 - dice_coefficient: 0.8684\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 23/409 [>.............................] - ETA: 13s - loss: 0.2018 - dice_coefficient: 0.8648\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 25/409 [>.............................] - ETA: 13s - loss: 0.1997 - dice_coefficient: 0.8668\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 27/409 [>.............................] - ETA: 13s - loss: 0.2000 - dice_coefficient: 0.8669\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 29/409 [=>............................] - ETA: 13s - loss: 0.2059 - dice_coefficient: 0.8671\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 31/409 [=>............................] - ETA: 12s - loss: 0.2146 - dice_coefficient: 0.8582\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 33/409 [=>............................] - ETA: 12s - loss: 0.2175 - dice_coefficient: 0.8566\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 35/409 [=>............................] - ETA: 12s - loss: 0.2182 - dice_coefficient: 0.8551\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 37/409 [=>............................] - ETA: 12s - loss: 0.2158 - dice_coefficient: 0.8564\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 39/409 [=>............................] - ETA: 12s - loss: 0.2157 - dice_coefficient: 0.8580\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 41/409 [==>...........................] - ETA: 12s - loss: 0.2144 - dice_coefficient: 0.8577\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 43/409 [==>...........................] - ETA: 12s - loss: 0.2118 - dice_coefficient: 0.8595\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 45/409 [==>...........................] - ETA: 12s - loss: 0.2120 - dice_coefficient: 0.8599\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 47/409 [==>...........................] - ETA: 12s - loss: 0.2155 - dice_coefficient: 0.8610\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 49/409 [==>...........................] - ETA: 12s - loss: 0.2173 - dice_coefficient: 0.8596\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 51/409 [==>...........................] - ETA: 12s - loss: 0.2150 - dice_coefficient: 0.8623\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 53/409 [==>...........................] - ETA: 12s - loss: 0.2153 - dice_coefficient: 0.8634\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 55/409 [===>..........................] - ETA: 12s - loss: 0.2151 - dice_coefficient: 0.8632\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 57/409 [===>..........................] - ETA: 12s - loss: 0.2167 - dice_coefficient: 0.8609\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 59/409 [===>..........................] - ETA: 12s - loss: 0.2172 - dice_coefficient: 0.8613\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 61/409 [===>..........................] - ETA: 12s - loss: 0.2168 - dice_coefficient: 0.8622\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 63/409 [===>..........................] - ETA: 12s - loss: 0.2240 - dice_coefficient: 0.8559\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 65/409 [===>..........................] - ETA: 12s - loss: 0.2259 - dice_coefficient: 0.8535\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 67/409 [===>..........................] - ETA: 11s - loss: 0.2256 - dice_coefficient: 0.8535\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 69/409 [====>.........................] - ETA: 11s - loss: 0.2239 - dice_coefficient: 0.8552\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 71/409 [====>.........................] - ETA: 11s - loss: 0.2227 - dice_coefficient: 0.8569\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 73/409 [====>.........................] - ETA: 11s - loss: 0.2215 - dice_coefficient: 0.8581\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 75/409 [====>.........................] - ETA: 11s - loss: 0.2235 - dice_coefficient: 0.8576\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 77/409 [====>.........................] - ETA: 11s - loss: 0.2236 - dice_coefficient: 0.8570\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 79/409 [====>.........................] - ETA: 11s - loss: 0.2232 - dice_coefficient: 0.8576\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 81/409 [====>.........................] - ETA: 11s - loss: 0.2248 - dice_coefficient: 0.8562\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 83/409 [=====>........................] - ETA: 11s - loss: 0.2231 - dice_coefficient: 0.8578\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 85/409 [=====>........................] - ETA: 11s - loss: 0.2238 - dice_coefficient: 0.8570\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 87/409 [=====>........................] - ETA: 11s - loss: 0.2229 - dice_coefficient: 0.8577\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 89/409 [=====>........................] - ETA: 11s - loss: 0.2222 - dice_coefficient: 0.8587\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 91/409 [=====>........................] - ETA: 11s - loss: 0.2260 - dice_coefficient: 0.8557\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 93/409 [=====>........................] - ETA: 11s - loss: 0.2252 - dice_coefficient: 0.8561\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 95/409 [=====>........................] - ETA: 11s - loss: 0.2279 - dice_coefficient: 0.8533\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 97/409 [======>.......................] - ETA: 10s - loss: 0.2278 - dice_coefficient: 0.8529\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            " 99/409 [======>.......................] - ETA: 10s - loss: 0.2268 - dice_coefficient: 0.8534\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "101/409 [======>.......................] - ETA: 10s - loss: 0.2282 - dice_coefficient: 0.8517\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "103/409 [======>.......................] - ETA: 10s - loss: 0.2297 - dice_coefficient: 0.8524\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "105/409 [======>.......................] - ETA: 10s - loss: 0.2294 - dice_coefficient: 0.8526\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "107/409 [======>.......................] - ETA: 10s - loss: 0.2319 - dice_coefficient: 0.8505\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "109/409 [======>.......................] - ETA: 10s - loss: 0.2323 - dice_coefficient: 0.8497\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "111/409 [=======>......................] - ETA: 10s - loss: 0.2307 - dice_coefficient: 0.8509\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "113/409 [=======>......................] - ETA: 10s - loss: 0.2311 - dice_coefficient: 0.8504\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "115/409 [=======>......................] - ETA: 10s - loss: 0.2301 - dice_coefficient: 0.8518\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "117/409 [=======>......................] - ETA: 10s - loss: 0.2311 - dice_coefficient: 0.8506\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "119/409 [=======>......................] - ETA: 10s - loss: 0.2295 - dice_coefficient: 0.8517\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "121/409 [=======>......................] - ETA: 10s - loss: 0.2292 - dice_coefficient: 0.8526\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "123/409 [========>.....................] - ETA: 10s - loss: 0.2282 - dice_coefficient: 0.8532\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "125/409 [========>.....................] - ETA: 10s - loss: 0.2292 - dice_coefficient: 0.8537\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "127/409 [========>.....................] - ETA: 9s - loss: 0.2297 - dice_coefficient: 0.8531 \n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "129/409 [========>.....................] - ETA: 9s - loss: 0.2289 - dice_coefficient: 0.8539\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "131/409 [========>.....................] - ETA: 9s - loss: 0.2290 - dice_coefficient: 0.8534\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "133/409 [========>.....................] - ETA: 9s - loss: 0.2280 - dice_coefficient: 0.8541\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "135/409 [========>.....................] - ETA: 9s - loss: 0.2281 - dice_coefficient: 0.8534\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "137/409 [=========>....................] - ETA: 9s - loss: 0.2272 - dice_coefficient: 0.8545\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "139/409 [=========>....................] - ETA: 9s - loss: 0.2270 - dice_coefficient: 0.8547\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "141/409 [=========>....................] - ETA: 9s - loss: 0.2273 - dice_coefficient: 0.8542\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "143/409 [=========>....................] - ETA: 9s - loss: 0.2274 - dice_coefficient: 0.8537\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "145/409 [=========>....................] - ETA: 9s - loss: 0.2270 - dice_coefficient: 0.8536\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "147/409 [=========>....................] - ETA: 9s - loss: 0.2282 - dice_coefficient: 0.8523\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "149/409 [=========>....................] - ETA: 9s - loss: 0.2280 - dice_coefficient: 0.8522\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "151/409 [==========>...................] - ETA: 9s - loss: 0.2271 - dice_coefficient: 0.8529\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "153/409 [==========>...................] - ETA: 9s - loss: 0.2268 - dice_coefficient: 0.8536\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "155/409 [==========>...................] - ETA: 8s - loss: 0.2249 - dice_coefficient: 0.8549\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "157/409 [==========>...................] - ETA: 8s - loss: 0.2239 - dice_coefficient: 0.8558\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "159/409 [==========>...................] - ETA: 8s - loss: 0.2233 - dice_coefficient: 0.8559\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "161/409 [==========>...................] - ETA: 8s - loss: 0.2222 - dice_coefficient: 0.8567\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "163/409 [==========>...................] - ETA: 8s - loss: 0.2246 - dice_coefficient: 0.8544\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "165/409 [===========>..................] - ETA: 8s - loss: 0.2236 - dice_coefficient: 0.8551\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "167/409 [===========>..................] - ETA: 8s - loss: 0.2230 - dice_coefficient: 0.8555\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "169/409 [===========>..................] - ETA: 8s - loss: 0.2263 - dice_coefficient: 0.8531\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "171/409 [===========>..................] - ETA: 8s - loss: 0.2265 - dice_coefficient: 0.8529\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "173/409 [===========>..................] - ETA: 8s - loss: 0.2262 - dice_coefficient: 0.8533\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "175/409 [===========>..................] - ETA: 8s - loss: 0.2262 - dice_coefficient: 0.8535\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "177/409 [===========>..................] - ETA: 8s - loss: 0.2289 - dice_coefficient: 0.8513\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "179/409 [============>.................] - ETA: 8s - loss: 0.2282 - dice_coefficient: 0.8517\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "181/409 [============>.................] - ETA: 8s - loss: 0.2286 - dice_coefficient: 0.8515\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "183/409 [============>.................] - ETA: 7s - loss: 0.2283 - dice_coefficient: 0.8514\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "185/409 [============>.................] - ETA: 7s - loss: 0.2304 - dice_coefficient: 0.8498\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "187/409 [============>.................] - ETA: 7s - loss: 0.2304 - dice_coefficient: 0.8495\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "189/409 [============>.................] - ETA: 7s - loss: 0.2312 - dice_coefficient: 0.8488\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "191/409 [=============>................] - ETA: 7s - loss: 0.2319 - dice_coefficient: 0.8479\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "193/409 [=============>................] - ETA: 7s - loss: 0.2324 - dice_coefficient: 0.8473\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "195/409 [=============>................] - ETA: 7s - loss: 0.2318 - dice_coefficient: 0.8477\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "197/409 [=============>................] - ETA: 7s - loss: 0.2319 - dice_coefficient: 0.8474\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "199/409 [=============>................] - ETA: 7s - loss: 0.2331 - dice_coefficient: 0.8462\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "201/409 [=============>................] - ETA: 7s - loss: 0.2329 - dice_coefficient: 0.8467\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "203/409 [=============>................] - ETA: 7s - loss: 0.2355 - dice_coefficient: 0.8446\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "205/409 [==============>...............] - ETA: 7s - loss: 0.2350 - dice_coefficient: 0.8448\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "207/409 [==============>...............] - ETA: 7s - loss: 0.2351 - dice_coefficient: 0.8449\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "209/409 [==============>...............] - ETA: 7s - loss: 0.2353 - dice_coefficient: 0.8445\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "211/409 [==============>...............] - ETA: 7s - loss: 0.2349 - dice_coefficient: 0.8448\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "213/409 [==============>...............] - ETA: 6s - loss: 0.2350 - dice_coefficient: 0.8445\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "215/409 [==============>...............] - ETA: 6s - loss: 0.2353 - dice_coefficient: 0.8441\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "217/409 [==============>...............] - ETA: 6s - loss: 0.2352 - dice_coefficient: 0.8440\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "219/409 [===============>..............] - ETA: 6s - loss: 0.2361 - dice_coefficient: 0.8430\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "221/409 [===============>..............] - ETA: 6s - loss: 0.2351 - dice_coefficient: 0.8440\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "223/409 [===============>..............] - ETA: 6s - loss: 0.2345 - dice_coefficient: 0.8444\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "225/409 [===============>..............] - ETA: 6s - loss: 0.2336 - dice_coefficient: 0.8452\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "227/409 [===============>..............] - ETA: 6s - loss: 0.2337 - dice_coefficient: 0.8450\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "229/409 [===============>..............] - ETA: 6s - loss: 0.2333 - dice_coefficient: 0.8455\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "231/409 [===============>..............] - ETA: 6s - loss: 0.2345 - dice_coefficient: 0.8460\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "233/409 [================>.............] - ETA: 6s - loss: 0.2341 - dice_coefficient: 0.8462\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "235/409 [================>.............] - ETA: 6s - loss: 0.2349 - dice_coefficient: 0.8455\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "237/409 [================>.............] - ETA: 6s - loss: 0.2359 - dice_coefficient: 0.8445\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "239/409 [================>.............] - ETA: 6s - loss: 0.2373 - dice_coefficient: 0.8434\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "241/409 [================>.............] - ETA: 5s - loss: 0.2370 - dice_coefficient: 0.8434\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "243/409 [================>.............] - ETA: 5s - loss: 0.2364 - dice_coefficient: 0.8438\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "245/409 [================>.............] - ETA: 5s - loss: 0.2363 - dice_coefficient: 0.8437\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "247/409 [=================>............] - ETA: 5s - loss: 0.2373 - dice_coefficient: 0.8427\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "249/409 [=================>............] - ETA: 5s - loss: 0.2364 - dice_coefficient: 0.8435\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "251/409 [=================>............] - ETA: 5s - loss: 0.2363 - dice_coefficient: 0.8437\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "253/409 [=================>............] - ETA: 5s - loss: 0.2359 - dice_coefficient: 0.8438\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "255/409 [=================>............] - ETA: 5s - loss: 0.2357 - dice_coefficient: 0.8442\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "257/409 [=================>............] - ETA: 5s - loss: 0.2353 - dice_coefficient: 0.8445\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "259/409 [=================>............] - ETA: 5s - loss: 0.2357 - dice_coefficient: 0.8441\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "261/409 [==================>...........] - ETA: 5s - loss: 0.2355 - dice_coefficient: 0.8441\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "263/409 [==================>...........] - ETA: 5s - loss: 0.2359 - dice_coefficient: 0.8436\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "265/409 [==================>...........] - ETA: 5s - loss: 0.2363 - dice_coefficient: 0.8432\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "267/409 [==================>...........] - ETA: 5s - loss: 0.2358 - dice_coefficient: 0.8436\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "269/409 [==================>...........] - ETA: 4s - loss: 0.2358 - dice_coefficient: 0.8435\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "271/409 [==================>...........] - ETA: 4s - loss: 0.2353 - dice_coefficient: 0.8440\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "273/409 [===================>..........] - ETA: 4s - loss: 0.2371 - dice_coefficient: 0.8428\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "275/409 [===================>..........] - ETA: 4s - loss: 0.2369 - dice_coefficient: 0.8430\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "277/409 [===================>..........] - ETA: 4s - loss: 0.2379 - dice_coefficient: 0.8422\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "279/409 [===================>..........] - ETA: 4s - loss: 0.2377 - dice_coefficient: 0.8423\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "281/409 [===================>..........] - ETA: 4s - loss: 0.2380 - dice_coefficient: 0.8419\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "283/409 [===================>..........] - ETA: 4s - loss: 0.2373 - dice_coefficient: 0.8424\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "285/409 [===================>..........] - ETA: 4s - loss: 0.2372 - dice_coefficient: 0.8423\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "287/409 [====================>.........] - ETA: 4s - loss: 0.2369 - dice_coefficient: 0.8427\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "289/409 [====================>.........] - ETA: 4s - loss: 0.2367 - dice_coefficient: 0.8429\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "291/409 [====================>.........] - ETA: 4s - loss: 0.2362 - dice_coefficient: 0.8432\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "293/409 [====================>.........] - ETA: 4s - loss: 0.2357 - dice_coefficient: 0.8436\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "295/409 [====================>.........] - ETA: 4s - loss: 0.2355 - dice_coefficient: 0.8438\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "297/409 [====================>.........] - ETA: 3s - loss: 0.2361 - dice_coefficient: 0.8432\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "299/409 [====================>.........] - ETA: 3s - loss: 0.2356 - dice_coefficient: 0.8436\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "301/409 [=====================>........] - ETA: 3s - loss: 0.2352 - dice_coefficient: 0.8440\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "303/409 [=====================>........] - ETA: 3s - loss: 0.2352 - dice_coefficient: 0.8438\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "305/409 [=====================>........] - ETA: 3s - loss: 0.2348 - dice_coefficient: 0.8441\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "307/409 [=====================>........] - ETA: 3s - loss: 0.2345 - dice_coefficient: 0.8442\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "309/409 [=====================>........] - ETA: 3s - loss: 0.2340 - dice_coefficient: 0.8446\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "311/409 [=====================>........] - ETA: 3s - loss: 0.2341 - dice_coefficient: 0.8447\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "313/409 [=====================>........] - ETA: 3s - loss: 0.2344 - dice_coefficient: 0.8443\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "315/409 [======================>.......] - ETA: 3s - loss: 0.2348 - dice_coefficient: 0.8443\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "317/409 [======================>.......] - ETA: 3s - loss: 0.2349 - dice_coefficient: 0.8440\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "319/409 [======================>.......] - ETA: 3s - loss: 0.2346 - dice_coefficient: 0.8443\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "321/409 [======================>.......] - ETA: 3s - loss: 0.2377 - dice_coefficient: 0.8421\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "323/409 [======================>.......] - ETA: 3s - loss: 0.2384 - dice_coefficient: 0.8414\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "325/409 [======================>.......] - ETA: 2s - loss: 0.2392 - dice_coefficient: 0.8417\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "327/409 [======================>.......] - ETA: 2s - loss: 0.2395 - dice_coefficient: 0.8414\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "329/409 [=======================>......] - ETA: 2s - loss: 0.2394 - dice_coefficient: 0.8415\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "331/409 [=======================>......] - ETA: 2s - loss: 0.2389 - dice_coefficient: 0.8418\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "333/409 [=======================>......] - ETA: 2s - loss: 0.2387 - dice_coefficient: 0.8420\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "335/409 [=======================>......] - ETA: 2s - loss: 0.2396 - dice_coefficient: 0.8413\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "337/409 [=======================>......] - ETA: 2s - loss: 0.2394 - dice_coefficient: 0.8413\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "339/409 [=======================>......] - ETA: 2s - loss: 0.2405 - dice_coefficient: 0.8403\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "341/409 [========================>.....] - ETA: 2s - loss: 0.2403 - dice_coefficient: 0.8406\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "343/409 [========================>.....] - ETA: 2s - loss: 0.2395 - dice_coefficient: 0.8412\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "345/409 [========================>.....] - ETA: 2s - loss: 0.2391 - dice_coefficient: 0.8416\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "347/409 [========================>.....] - ETA: 2s - loss: 0.2391 - dice_coefficient: 0.8416\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "349/409 [========================>.....] - ETA: 2s - loss: 0.2390 - dice_coefficient: 0.8415\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "351/409 [========================>.....] - ETA: 2s - loss: 0.2391 - dice_coefficient: 0.8415\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "353/409 [========================>.....] - ETA: 1s - loss: 0.2400 - dice_coefficient: 0.8408\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "355/409 [=========================>....] - ETA: 1s - loss: 0.2401 - dice_coefficient: 0.8407\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "357/409 [=========================>....] - ETA: 1s - loss: 0.2396 - dice_coefficient: 0.8410\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "359/409 [=========================>....] - ETA: 1s - loss: 0.2392 - dice_coefficient: 0.8414\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "361/409 [=========================>....] - ETA: 1s - loss: 0.2397 - dice_coefficient: 0.8410\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "363/409 [=========================>....] - ETA: 1s - loss: 0.2395 - dice_coefficient: 0.8412\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "365/409 [=========================>....] - ETA: 1s - loss: 0.2392 - dice_coefficient: 0.8413\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "367/409 [=========================>....] - ETA: 1s - loss: 0.2388 - dice_coefficient: 0.8417\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "369/409 [==========================>...] - ETA: 1s - loss: 0.2390 - dice_coefficient: 0.8415\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "371/409 [==========================>...] - ETA: 1s - loss: 0.2398 - dice_coefficient: 0.8408\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "373/409 [==========================>...] - ETA: 1s - loss: 0.2393 - dice_coefficient: 0.8411\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "375/409 [==========================>...] - ETA: 1s - loss: 0.2395 - dice_coefficient: 0.8409\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "377/409 [==========================>...] - ETA: 1s - loss: 0.2393 - dice_coefficient: 0.8410\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "379/409 [==========================>...] - ETA: 1s - loss: 0.2392 - dice_coefficient: 0.8410\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "381/409 [==========================>...] - ETA: 0s - loss: 0.2393 - dice_coefficient: 0.8412\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "383/409 [===========================>..] - ETA: 0s - loss: 0.2392 - dice_coefficient: 0.8415\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "385/409 [===========================>..] - ETA: 0s - loss: 0.2401 - dice_coefficient: 0.8413\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "387/409 [===========================>..] - ETA: 0s - loss: 0.2398 - dice_coefficient: 0.8415\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "389/409 [===========================>..] - ETA: 0s - loss: 0.2407 - dice_coefficient: 0.8410\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "391/409 [===========================>..] - ETA: 0s - loss: 0.2404 - dice_coefficient: 0.8413\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "393/409 [===========================>..] - ETA: 0s - loss: 0.2400 - dice_coefficient: 0.8416\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "395/409 [===========================>..] - ETA: 0s - loss: 0.2394 - dice_coefficient: 0.8421\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "397/409 [============================>.] - ETA: 0s - loss: 0.2392 - dice_coefficient: 0.8424\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "399/409 [============================>.] - ETA: 0s - loss: 0.2790 - dice_coefficient: 0.8403\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "401/409 [============================>.] - ETA: 0s - loss: 0.2784 - dice_coefficient: 0.8406\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "403/409 [============================>.] - ETA: 0s - loss: 0.2793 - dice_coefficient: 0.8397\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "405/409 [============================>.] - ETA: 0s - loss: 0.2792 - dice_coefficient: 0.8398\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "407/409 [============================>.] - ETA: 0s - loss: 0.2786 - dice_coefficient: 0.8401\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.15336\n",
            "409/409 [==============================] - 15s 36ms/step - loss: 0.2782 - dice_coefficient: 0.8403 - lr: 1.0000e-04\n",
            "Epoch 130/130\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "  1/409 [..............................] - ETA: 0s - loss: 0.1665 - dice_coefficient: 0.9195\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "  3/409 [..............................] - ETA: 9s - loss: 0.2184 - dice_coefficient: 0.8559\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "  5/409 [..............................] - ETA: 11s - loss: 0.1882 - dice_coefficient: 0.8786\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "  7/409 [..............................] - ETA: 12s - loss: 0.1783 - dice_coefficient: 0.8842\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "  9/409 [..............................] - ETA: 12s - loss: 0.1776 - dice_coefficient: 0.8854\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 11/409 [..............................] - ETA: 12s - loss: 0.1774 - dice_coefficient: 0.8875\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 13/409 [..............................] - ETA: 12s - loss: 0.1739 - dice_coefficient: 0.8905\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 15/409 [>.............................] - ETA: 13s - loss: 0.1762 - dice_coefficient: 0.8859\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 17/409 [>.............................] - ETA: 13s - loss: 0.1849 - dice_coefficient: 0.8819\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 19/409 [>.............................] - ETA: 13s - loss: 0.1927 - dice_coefficient: 0.8752\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 21/409 [>.............................] - ETA: 13s - loss: 0.1926 - dice_coefficient: 0.8760\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 23/409 [>.............................] - ETA: 13s - loss: 0.2014 - dice_coefficient: 0.8671\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 25/409 [>.............................] - ETA: 13s - loss: 0.2112 - dice_coefficient: 0.8587\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 27/409 [>.............................] - ETA: 13s - loss: 0.2069 - dice_coefficient: 0.8612\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 29/409 [=>............................] - ETA: 13s - loss: 0.2126 - dice_coefficient: 0.8576\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 31/409 [=>............................] - ETA: 13s - loss: 0.2167 - dice_coefficient: 0.8532\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 33/409 [=>............................] - ETA: 13s - loss: 0.2220 - dice_coefficient: 0.8490\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 35/409 [=>............................] - ETA: 12s - loss: 0.2198 - dice_coefficient: 0.8513\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 37/409 [=>............................] - ETA: 12s - loss: 0.2162 - dice_coefficient: 0.8549\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 39/409 [=>............................] - ETA: 12s - loss: 0.2184 - dice_coefficient: 0.8567\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 41/409 [==>...........................] - ETA: 12s - loss: 0.2287 - dice_coefficient: 0.8545\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 43/409 [==>...........................] - ETA: 12s - loss: 0.2251 - dice_coefficient: 0.8576\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 45/409 [==>...........................] - ETA: 12s - loss: 0.2219 - dice_coefficient: 0.8599\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 47/409 [==>...........................] - ETA: 12s - loss: 0.2298 - dice_coefficient: 0.8537\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 49/409 [==>...........................] - ETA: 12s - loss: 0.2288 - dice_coefficient: 0.8547\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 51/409 [==>...........................] - ETA: 12s - loss: 0.2293 - dice_coefficient: 0.8531\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 53/409 [==>...........................] - ETA: 12s - loss: 0.2323 - dice_coefficient: 0.8518\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 55/409 [===>..........................] - ETA: 12s - loss: 0.2306 - dice_coefficient: 0.8530\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 57/409 [===>..........................] - ETA: 12s - loss: 0.2286 - dice_coefficient: 0.8543\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 59/409 [===>..........................] - ETA: 12s - loss: 0.2269 - dice_coefficient: 0.8546\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 61/409 [===>..........................] - ETA: 12s - loss: 0.2278 - dice_coefficient: 0.8532\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 63/409 [===>..........................] - ETA: 12s - loss: 0.2280 - dice_coefficient: 0.8530\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 65/409 [===>..........................] - ETA: 12s - loss: 0.2349 - dice_coefficient: 0.8488\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 67/409 [===>..........................] - ETA: 12s - loss: 0.2350 - dice_coefficient: 0.8489\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 69/409 [====>.........................] - ETA: 11s - loss: 0.2340 - dice_coefficient: 0.8488\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 71/409 [====>.........................] - ETA: 11s - loss: 0.2318 - dice_coefficient: 0.8501\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 73/409 [====>.........................] - ETA: 11s - loss: 0.2318 - dice_coefficient: 0.8497\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 75/409 [====>.........................] - ETA: 11s - loss: 0.2350 - dice_coefficient: 0.8476\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 77/409 [====>.........................] - ETA: 11s - loss: 0.2389 - dice_coefficient: 0.8449\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 79/409 [====>.........................] - ETA: 11s - loss: 0.2369 - dice_coefficient: 0.8460\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 81/409 [====>.........................] - ETA: 11s - loss: 0.2355 - dice_coefficient: 0.8465\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 83/409 [=====>........................] - ETA: 11s - loss: 0.2351 - dice_coefficient: 0.8468\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 85/409 [=====>........................] - ETA: 11s - loss: 0.2365 - dice_coefficient: 0.8458\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 87/409 [=====>........................] - ETA: 11s - loss: 0.4187 - dice_coefficient: 0.8364\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 89/409 [=====>........................] - ETA: 11s - loss: 0.4134 - dice_coefficient: 0.8378\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 91/409 [=====>........................] - ETA: 11s - loss: 0.4098 - dice_coefficient: 0.8376\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 93/409 [=====>........................] - ETA: 11s - loss: 0.4095 - dice_coefficient: 0.8346\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 95/409 [=====>........................] - ETA: 11s - loss: 0.4050 - dice_coefficient: 0.8360\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 97/409 [======>.......................] - ETA: 11s - loss: 0.4004 - dice_coefficient: 0.8368\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            " 99/409 [======>.......................] - ETA: 10s - loss: 0.3965 - dice_coefficient: 0.8381\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "101/409 [======>.......................] - ETA: 10s - loss: 0.3924 - dice_coefficient: 0.8389\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "103/409 [======>.......................] - ETA: 10s - loss: 0.3890 - dice_coefficient: 0.8392\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "105/409 [======>.......................] - ETA: 10s - loss: 0.3853 - dice_coefficient: 0.8398\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "107/409 [======>.......................] - ETA: 10s - loss: 0.3824 - dice_coefficient: 0.8394\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "109/409 [======>.......................] - ETA: 10s - loss: 0.3814 - dice_coefficient: 0.8377\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "111/409 [=======>......................] - ETA: 10s - loss: 0.3811 - dice_coefficient: 0.8364\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "113/409 [=======>......................] - ETA: 10s - loss: 0.3796 - dice_coefficient: 0.8355\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "115/409 [=======>......................] - ETA: 10s - loss: 0.3781 - dice_coefficient: 0.8349\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "117/409 [=======>......................] - ETA: 10s - loss: 0.3762 - dice_coefficient: 0.8344\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "119/409 [=======>......................] - ETA: 10s - loss: 0.3734 - dice_coefficient: 0.8348\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "121/409 [=======>......................] - ETA: 10s - loss: 0.3729 - dice_coefficient: 0.8334\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "123/409 [========>.....................] - ETA: 10s - loss: 0.3714 - dice_coefficient: 0.8329\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "125/409 [========>.....................] - ETA: 10s - loss: 0.3682 - dice_coefficient: 0.8341\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "127/409 [========>.....................] - ETA: 9s - loss: 0.3658 - dice_coefficient: 0.8344 \n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "129/409 [========>.....................] - ETA: 9s - loss: 0.3648 - dice_coefficient: 0.8336\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "131/409 [========>.....................] - ETA: 9s - loss: 0.3622 - dice_coefficient: 0.8345\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "133/409 [========>.....................] - ETA: 9s - loss: 0.3594 - dice_coefficient: 0.8354\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "135/409 [========>.....................] - ETA: 9s - loss: 0.3568 - dice_coefficient: 0.8358\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "137/409 [=========>....................] - ETA: 9s - loss: 0.3567 - dice_coefficient: 0.8342\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "139/409 [=========>....................] - ETA: 9s - loss: 0.3556 - dice_coefficient: 0.8335\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "141/409 [=========>....................] - ETA: 9s - loss: 0.3543 - dice_coefficient: 0.8329\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "143/409 [=========>....................] - ETA: 9s - loss: 0.3527 - dice_coefficient: 0.8328\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "145/409 [=========>....................] - ETA: 9s - loss: 0.3506 - dice_coefficient: 0.8334\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "147/409 [=========>....................] - ETA: 9s - loss: 0.3484 - dice_coefficient: 0.8341\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "149/409 [=========>....................] - ETA: 9s - loss: 0.3483 - dice_coefficient: 0.8341\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "151/409 [==========>...................] - ETA: 9s - loss: 0.3498 - dice_coefficient: 0.8318\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "153/409 [==========>...................] - ETA: 9s - loss: 0.3472 - dice_coefficient: 0.8327\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "155/409 [==========>...................] - ETA: 9s - loss: 0.3451 - dice_coefficient: 0.8338\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "157/409 [==========>...................] - ETA: 8s - loss: 0.3431 - dice_coefficient: 0.8345\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "159/409 [==========>...................] - ETA: 8s - loss: 0.3409 - dice_coefficient: 0.8350\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "161/409 [==========>...................] - ETA: 8s - loss: 0.3404 - dice_coefficient: 0.8343\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "163/409 [==========>...................] - ETA: 8s - loss: 0.3383 - dice_coefficient: 0.8353\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "165/409 [===========>..................] - ETA: 8s - loss: 0.3366 - dice_coefficient: 0.8355\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "167/409 [===========>..................] - ETA: 8s - loss: 0.3343 - dice_coefficient: 0.8364\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "169/409 [===========>..................] - ETA: 8s - loss: 0.3322 - dice_coefficient: 0.8372\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "171/409 [===========>..................] - ETA: 8s - loss: 0.3305 - dice_coefficient: 0.8378\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "173/409 [===========>..................] - ETA: 8s - loss: 0.3284 - dice_coefficient: 0.8386\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "175/409 [===========>..................] - ETA: 8s - loss: 0.3292 - dice_coefficient: 0.8372\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "177/409 [===========>..................] - ETA: 8s - loss: 0.3276 - dice_coefficient: 0.8381\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "179/409 [============>.................] - ETA: 8s - loss: 0.3283 - dice_coefficient: 0.8366\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "181/409 [============>.................] - ETA: 8s - loss: 0.3263 - dice_coefficient: 0.8374\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "183/409 [============>.................] - ETA: 8s - loss: 0.3267 - dice_coefficient: 0.8377\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "185/409 [============>.................] - ETA: 7s - loss: 0.3248 - dice_coefficient: 0.8385\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "187/409 [============>.................] - ETA: 7s - loss: 0.3246 - dice_coefficient: 0.8375\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "189/409 [============>.................] - ETA: 7s - loss: 0.3223 - dice_coefficient: 0.8387\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "191/409 [=============>................] - ETA: 7s - loss: 0.3209 - dice_coefficient: 0.8391\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "193/409 [=============>................] - ETA: 7s - loss: 0.3189 - dice_coefficient: 0.8400\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "195/409 [=============>................] - ETA: 7s - loss: 0.3184 - dice_coefficient: 0.8396\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "197/409 [=============>................] - ETA: 7s - loss: 0.3198 - dice_coefficient: 0.8380\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "199/409 [=============>................] - ETA: 7s - loss: 0.3180 - dice_coefficient: 0.8389\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "201/409 [=============>................] - ETA: 7s - loss: 0.3171 - dice_coefficient: 0.8396\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "203/409 [=============>................] - ETA: 7s - loss: 0.3154 - dice_coefficient: 0.8405\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "205/409 [==============>...............] - ETA: 7s - loss: 0.3171 - dice_coefficient: 0.8388\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "207/409 [==============>...............] - ETA: 7s - loss: 0.3159 - dice_coefficient: 0.8390\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "209/409 [==============>...............] - ETA: 7s - loss: 0.3145 - dice_coefficient: 0.8396\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "211/409 [==============>...............] - ETA: 7s - loss: 0.3134 - dice_coefficient: 0.8399\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "213/409 [==============>...............] - ETA: 6s - loss: 0.3133 - dice_coefficient: 0.8392\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "215/409 [==============>...............] - ETA: 6s - loss: 0.3128 - dice_coefficient: 0.8389\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "217/409 [==============>...............] - ETA: 6s - loss: 0.3124 - dice_coefficient: 0.8388\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "219/409 [===============>..............] - ETA: 6s - loss: 0.3111 - dice_coefficient: 0.8393\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "221/409 [===============>..............] - ETA: 6s - loss: 0.3122 - dice_coefficient: 0.8381\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "223/409 [===============>..............] - ETA: 6s - loss: 0.3118 - dice_coefficient: 0.8379\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "225/409 [===============>..............] - ETA: 6s - loss: 0.3109 - dice_coefficient: 0.8383\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "227/409 [===============>..............] - ETA: 6s - loss: 0.3102 - dice_coefficient: 0.8385\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "229/409 [===============>..............] - ETA: 6s - loss: 0.3087 - dice_coefficient: 0.8393\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "231/409 [===============>..............] - ETA: 6s - loss: 0.3083 - dice_coefficient: 0.8391\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "233/409 [================>.............] - ETA: 6s - loss: 0.3077 - dice_coefficient: 0.8394\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "235/409 [================>.............] - ETA: 6s - loss: 0.3078 - dice_coefficient: 0.8387\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "237/409 [================>.............] - ETA: 6s - loss: 0.3088 - dice_coefficient: 0.8388\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "239/409 [================>.............] - ETA: 6s - loss: 0.3077 - dice_coefficient: 0.8392\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "241/409 [================>.............] - ETA: 5s - loss: 0.3068 - dice_coefficient: 0.8396\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "243/409 [================>.............] - ETA: 5s - loss: 0.3060 - dice_coefficient: 0.8397\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "245/409 [================>.............] - ETA: 5s - loss: 0.3066 - dice_coefficient: 0.8391\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "247/409 [=================>............] - ETA: 5s - loss: 0.3059 - dice_coefficient: 0.8390\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "249/409 [=================>............] - ETA: 5s - loss: 0.3055 - dice_coefficient: 0.8390\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "251/409 [=================>............] - ETA: 5s - loss: 0.3046 - dice_coefficient: 0.8393\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "253/409 [=================>............] - ETA: 5s - loss: 0.3043 - dice_coefficient: 0.8391\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "255/409 [=================>............] - ETA: 5s - loss: 0.3034 - dice_coefficient: 0.8396\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "257/409 [=================>............] - ETA: 5s - loss: 0.3029 - dice_coefficient: 0.8394\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "259/409 [=================>............] - ETA: 5s - loss: 0.3021 - dice_coefficient: 0.8396\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "261/409 [==================>...........] - ETA: 5s - loss: 0.3025 - dice_coefficient: 0.8387\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "263/409 [==================>...........] - ETA: 5s - loss: 0.3021 - dice_coefficient: 0.8388\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "265/409 [==================>...........] - ETA: 5s - loss: 0.3008 - dice_coefficient: 0.8395\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "267/409 [==================>...........] - ETA: 5s - loss: 0.3002 - dice_coefficient: 0.8396\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "269/409 [==================>...........] - ETA: 4s - loss: 0.2998 - dice_coefficient: 0.8394\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "271/409 [==================>...........] - ETA: 4s - loss: 0.2989 - dice_coefficient: 0.8398\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "273/409 [===================>..........] - ETA: 4s - loss: 0.2978 - dice_coefficient: 0.8402\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "275/409 [===================>..........] - ETA: 4s - loss: 0.2973 - dice_coefficient: 0.8404\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "277/409 [===================>..........] - ETA: 4s - loss: 0.2985 - dice_coefficient: 0.8393\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "279/409 [===================>..........] - ETA: 4s - loss: 0.2978 - dice_coefficient: 0.8394\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "281/409 [===================>..........] - ETA: 4s - loss: 0.2972 - dice_coefficient: 0.8394\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "283/409 [===================>..........] - ETA: 4s - loss: 0.2964 - dice_coefficient: 0.8396\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "285/409 [===================>..........] - ETA: 4s - loss: 0.2960 - dice_coefficient: 0.8395\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "287/409 [====================>.........] - ETA: 4s - loss: 0.2967 - dice_coefficient: 0.8385\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "289/409 [====================>.........] - ETA: 4s - loss: 0.2958 - dice_coefficient: 0.8389\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "291/409 [====================>.........] - ETA: 4s - loss: 0.2952 - dice_coefficient: 0.8390\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "293/409 [====================>.........] - ETA: 4s - loss: 0.2946 - dice_coefficient: 0.8392\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "295/409 [====================>.........] - ETA: 4s - loss: 0.2935 - dice_coefficient: 0.8398\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "297/409 [====================>.........] - ETA: 3s - loss: 0.2929 - dice_coefficient: 0.8401\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "299/409 [====================>.........] - ETA: 3s - loss: 0.2926 - dice_coefficient: 0.8400\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "301/409 [=====================>........] - ETA: 3s - loss: 0.2926 - dice_coefficient: 0.8397\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "303/409 [=====================>........] - ETA: 3s - loss: 0.2923 - dice_coefficient: 0.8395\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "305/409 [=====================>........] - ETA: 3s - loss: 0.2945 - dice_coefficient: 0.8375\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "307/409 [=====================>........] - ETA: 3s - loss: 0.2940 - dice_coefficient: 0.8378\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "309/409 [=====================>........] - ETA: 3s - loss: 0.2938 - dice_coefficient: 0.8376\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "311/409 [=====================>........] - ETA: 3s - loss: 0.2931 - dice_coefficient: 0.8378\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "313/409 [=====================>........] - ETA: 3s - loss: 0.2928 - dice_coefficient: 0.8377\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "315/409 [======================>.......] - ETA: 3s - loss: 0.2925 - dice_coefficient: 0.8377\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "317/409 [======================>.......] - ETA: 3s - loss: 0.2917 - dice_coefficient: 0.8379\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "319/409 [======================>.......] - ETA: 3s - loss: 0.2915 - dice_coefficient: 0.8379\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "321/409 [======================>.......] - ETA: 3s - loss: 0.2910 - dice_coefficient: 0.8379\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "323/409 [======================>.......] - ETA: 3s - loss: 0.2902 - dice_coefficient: 0.8385\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "325/409 [======================>.......] - ETA: 2s - loss: 0.2895 - dice_coefficient: 0.8388\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "327/409 [======================>.......] - ETA: 2s - loss: 0.2888 - dice_coefficient: 0.8392\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "329/409 [=======================>......] - ETA: 2s - loss: 0.2879 - dice_coefficient: 0.8398\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "331/409 [=======================>......] - ETA: 2s - loss: 0.2875 - dice_coefficient: 0.8400\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "333/409 [=======================>......] - ETA: 2s - loss: 0.2871 - dice_coefficient: 0.8401\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "335/409 [=======================>......] - ETA: 2s - loss: 0.2873 - dice_coefficient: 0.8397\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "337/409 [=======================>......] - ETA: 2s - loss: 0.2870 - dice_coefficient: 0.8397\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "339/409 [=======================>......] - ETA: 2s - loss: 0.2864 - dice_coefficient: 0.8399\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "341/409 [========================>.....] - ETA: 2s - loss: 0.2863 - dice_coefficient: 0.8399\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "343/409 [========================>.....] - ETA: 2s - loss: 0.2856 - dice_coefficient: 0.8403\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "345/409 [========================>.....] - ETA: 2s - loss: 0.2851 - dice_coefficient: 0.8406\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "347/409 [========================>.....] - ETA: 2s - loss: 0.2846 - dice_coefficient: 0.8407\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "349/409 [========================>.....] - ETA: 2s - loss: 0.2839 - dice_coefficient: 0.8411\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "351/409 [========================>.....] - ETA: 2s - loss: 0.2847 - dice_coefficient: 0.8403\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "353/409 [========================>.....] - ETA: 1s - loss: 0.2843 - dice_coefficient: 0.8403\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "355/409 [=========================>....] - ETA: 1s - loss: 0.2840 - dice_coefficient: 0.8405\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "357/409 [=========================>....] - ETA: 1s - loss: 0.2840 - dice_coefficient: 0.8402\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "359/409 [=========================>....] - ETA: 1s - loss: 0.2830 - dice_coefficient: 0.8407\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "361/409 [=========================>....] - ETA: 1s - loss: 0.2835 - dice_coefficient: 0.8407\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "363/409 [=========================>....] - ETA: 1s - loss: 0.2829 - dice_coefficient: 0.8410\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "365/409 [=========================>....] - ETA: 1s - loss: 0.2824 - dice_coefficient: 0.8412\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "367/409 [=========================>....] - ETA: 1s - loss: 0.2821 - dice_coefficient: 0.8413\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "369/409 [==========================>...] - ETA: 1s - loss: 0.2817 - dice_coefficient: 0.8414\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "371/409 [==========================>...] - ETA: 1s - loss: 0.2823 - dice_coefficient: 0.8408\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "373/409 [==========================>...] - ETA: 1s - loss: 0.2816 - dice_coefficient: 0.8412\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "375/409 [==========================>...] - ETA: 1s - loss: 0.2812 - dice_coefficient: 0.8412\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "377/409 [==========================>...] - ETA: 1s - loss: 0.2808 - dice_coefficient: 0.8412\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "379/409 [==========================>...] - ETA: 1s - loss: 0.2801 - dice_coefficient: 0.8417\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "381/409 [==========================>...] - ETA: 0s - loss: 0.2810 - dice_coefficient: 0.8407\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "383/409 [===========================>..] - ETA: 0s - loss: 0.2810 - dice_coefficient: 0.8405\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "385/409 [===========================>..] - ETA: 0s - loss: 0.2811 - dice_coefficient: 0.8403\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "387/409 [===========================>..] - ETA: 0s - loss: 0.2800 - dice_coefficient: 0.8409\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "389/409 [===========================>..] - ETA: 0s - loss: 0.2794 - dice_coefficient: 0.8413\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "391/409 [===========================>..] - ETA: 0s - loss: 0.2791 - dice_coefficient: 0.8413\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "393/409 [===========================>..] - ETA: 0s - loss: 0.2784 - dice_coefficient: 0.8416\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "395/409 [===========================>..] - ETA: 0s - loss: 0.2779 - dice_coefficient: 0.8420\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "397/409 [============================>.] - ETA: 0s - loss: 0.2778 - dice_coefficient: 0.8418\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "399/409 [============================>.] - ETA: 0s - loss: 0.2778 - dice_coefficient: 0.8414\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "401/409 [============================>.] - ETA: 0s - loss: 0.2775 - dice_coefficient: 0.8414\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "403/409 [============================>.] - ETA: 0s - loss: 0.2772 - dice_coefficient: 0.8415\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "405/409 [============================>.] - ETA: 0s - loss: 0.2770 - dice_coefficient: 0.8416\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "407/409 [============================>.] - ETA: 0s - loss: 0.2765 - dice_coefficient: 0.8417\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.15336\n",
            "409/409 [==============================] - 15s 35ms/step - loss: 0.2759 - dice_coefficient: 0.8420 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f776c213be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5VtnuzlOf4uL"
      },
      "source": [
        "### Get the predicted mask for a sample image   (3 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-CBCMysrchu",
        "outputId": "ffe89685-75e0-49ea-b46e-5548c61d6d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n = 10\n",
        "sample_image = X_train[n]\n",
        "\n",
        "#### Add your code here ####\n",
        "print(sample_image)\n",
        "pyplot.imshow(sample_image)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  ...\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]]\n",
            "\n",
            " [[-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  ...\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]]\n",
            "\n",
            " [[-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  ...\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  ...\n",
            "  [-0.96862745 -0.96862745 -0.96862745]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]]\n",
            "\n",
            " [[-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  ...\n",
            "  [-0.96862745 -0.96862745 -0.96862745]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]\n",
            "  [-0.95294118 -0.95294118 -0.95294118]]\n",
            "\n",
            " [[-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  ...\n",
            "  [-0.97647059 -0.97647059 -0.97647059]\n",
            "  [-0.96862745 -0.96862745 -0.96862745]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f756dce3898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzbaY4stcADT",
        "colab_type": "code",
        "outputId": "e1a37e7f-121b-4f30-e550-6416bd9fd998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# To predict the box\n",
        "\n",
        "region = model.predict(x=np.array([sample_image]))[0] # Predict the BBox\n",
        "print(region.shape)\n",
        "\n",
        "pyplot.imshow(region)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f756dbbb940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO29e5xcV3Xn+137nFNV3dUvtd7W08ayseWAsYUxGAjBQMCZicPcXDCTgBOYGDLwmXBvMsHAvRM+CblDZgJkkjuXjDOQmAxj4uAAToCAbR6eYGyQHdmyZVuWJRtL1vvRr+qqOmfvdf84p1qlVrfU6oeqq87+9qc+dc4+r1VddX5nP9ZeS1QVj8eTX0yrDfB4PK3Fi4DHk3O8CHg8OceLgMeTc7wIeDw5x4uAx5NzFkwEROStIvK0iOwSkVsX6joej2duyEL4CYhIAOwE3gzsBX4CvEtVd8z7xTwez5xYqJrANcAuVd2tqnXgy8CNC3Qtj8czB8IFOu8a4IWm9b3Aq6bbuSBFLVFeIFM8Hg/ACMePqOryyeULJQJnRURuAW4BKNHNq+T6Vpni8eSCe/Urz09VvlDNgX3Auqb1tVnZBKp6m6puUdUtEcUFMsPj8ZyNhRKBnwCbRORCESkANwF3L9C1PB7PHFiQ5oCqJiLyIeDbQAB8QVWfWIhreTyeubFgfQKq+k3gmwt1fo/HMz94j0GPJ+d4EfB4co4XAY8n53gR8HhyjhcBjyfneBHweHKOFwGPJ+d4EfB4co4XAY8n57RsFqEnZ5gAADGCWgs+6c2iwYuAZ34QOXW9+SYXQaIQEQFjIE7QuH5+7fNMi28OeM4LEwIQBGDk7Ad4zhteBDznB2PSGkH28iwefHPAM3dECNeuSZcbT/nEpk2EQkS8qp+915WxBYj7lGXblL47Hpz95aICGEHjJC1w9vTtAOrStySZ9bXygBcBz7zglvYBoEEqAhJbMAZbLjD0ki76rj/A8q4xXj24m78wb6LvjtlfSwpRWrOw6c2f3esnt0fpz1qz7XgROCOzbg6IyDoR+Z6I7BCRJ0Tkt7LyT4jIPhHZlr1umD9zPYseERBBowBXCqkNFhhfLvzimu1cv+wpLiwewpXc9MdmowjN55p4ZVTeuJnRN1+O6e/D9PYiYYiETc+zIDi9o9IzLXOpCSTAb6vqIyLSCzwsIvdk2z6rqn88d/M8bUd286kRXGiIuw1xGbZ0757YRaNphgfFpEOIKidHF8Sc9qgf3hDiIugrFNL9KplwND/xje/umimzFgFV3Q/sz5ZHRORJ0lDjnjySZDdq1hwwVtEooLpE0AD+x+HXsLo4xLU9uxhYPczQr15LddBQG4Tq6pjy8gpdhZhCmDBSLWKtYXnvGFFgGY8jrAoHn12GJMKqH1pMAhrHoIoppoFqba2GhCHJ1wZwKuzZuxzGQi775MkguxrH2CNHz/u/ZzEzL30CIrIReAXwEHAd8CEReQ+wlbS2cHw+ruNZvEj25J54aLt0wRUERNk7NoBBcT2Gge5xDq0bpLrSEa6u8KaNz/ILg4+yKhii19R5IRlgzBW5qvgivUY45iBWw+/1/EtG4yLVey4gqDqwLr1g0NyEMPzlpjuIFf6/wdfx7OgyquWedJNTpHlfDzAPIiAiPcBdwIdVdVhEPgf8AaDZ+6eB905x3Cl5BzxtjnPpEKBNOwTry8rUBkOGLksoLRvnN9bdz4CpsDE6wTvXbOWuNzmWFCusKg3zmt5dXBodYmmgdEvABcFxLEpJQgyGitSJsLxl2Q5qLuLOwlokUcZeuwmAuDut+vd/fRtSKNBrApwq1/ftYFm0nu93Xw0OqMepfZ5TmJMIiEhEKgBfUtW/A1DVg03b/wL4h6mOVdXbgNsA+mTQ+5B2Ak1egi4SbEGQckxvd5X14TG6TUyvKOsKR7m07xB94Tj94TiDwShl4+iWkC4pUJT0PI60NmEABFaEw9Q1AAFEqPWlN39czjoBM2ekACEQYcBUWBKOZT4KeloHoydl1iIgqcfH54EnVfUzTeWrs/4CgLcDj8/NRM9ixxSLHP/MRDuA7ijm5rX30m1q/ExhPyVxXBAWgYCQAmWpE6uhO6izoXCE93//Zpb9MOLoG2pcsfFFLus7wGA4xrGkTOIMv7P8flYGXWwpHsABnxuzRCMx1SVdABy7JgZg6eOb0MhQlAiADeE4lr382VsGkATKBxzFIUv3sRMTtmu9jqtWz+N/a/Exl5rAdcC7ge0isi0r+xjwLhG5krQ58Bzw/jlZ6Fn8GMMrlp1MMNUbVvkX5T1EYug3Uzf1nBoMSsnEmOGQvufrHDte4PCKMsuLPTgVjtXL1Fz6EzUIJREcIFbT9r2CCgTd6aiALYW4SDAIDiUSoSQJSTdIAklRCErm1D4E30cwp9GBfyKtmE3G5xrIGyIMRmME4lhTOE7Z1NIq+ZQ/D7g4GuZ/W7qVblOjLHVctyPpDlj+E4i3r+D+S1aQ9FsGtocURpR7PvY4b+x+jjuHX0bVRXQ9cwgdHqUcbQQDB04UQOCFW6oYowRiCIB+U2JDWOXqt+zgSLXMsz9eT9fhgD4j4HwLtIH3GPTMC4E4DEpBEiJJMGdoewdASWIKWAIa/gAQ1BVxENQEWxeiMaUw6qhqAQdUXIGqiyCxaJIg1oETxAkI9HTXCMypN3ckhsHCGIkaNFRc2Og/yITAT2lGdBH8E/pkUH1W4vbiha9cAUB/eZxiYLln811AWm0HCOTMzjq2yQFoVGtUnCXIhCNCMCLU1GFVWRZ0EUlArGnP/s64jkUoS9oMGMwcg6Lsmj2mdMq1htw4TpUXrfCZA2/mwE2D6c1fj9FqDXs8HyPY9+pXHlbVLZPLfU3AMyu6inWMwJLSOAVjieTc2tbNItEvXfTPwMGvcY0N2dM8ktRJKCQ47ZzNlCTEogyaOuWwlo4QLIKH32LB+1Z6Zo1TsM6Q6Pz8jCquzpAbn3jiW3Wn1BgafOzA6/g/9l3PMVtjxJ09OElIQCQB3SagJ6ihUYhG/vnXwIuAZ1Ey1c3fINEAp3MY7/e+Aqfg5dAzKx646ksAmInnyOyH2mK1OBzPJwnHXIlLo3F6TWFiu1PFIBPV/ZeVXyDWkP5sn7P1P0yMFkgXH1j6AH/412XGbcSxWpldP3wpGz/+o1nb3gl4EfDMisbNb6YZBlwIrLqz3vAzIRAlyLwS51Kh6BS8CHjmxHzclABWlYqGjLguYq2csm3yiENvUCXWgBg7rS/CdBhSZ6ZQLCNB0TeI8SLgmSUNv/6zNQMabfuziYXDYQmwCBWFqKnDrzH0F2SP7TFXJNZgYlixZ4Y2p80OCHAYUULj0ppAI5CJulyOGngR8MyKf65l7fNCerM2hu8iCRh1Vf702MupuAJPjazkpb0H+eSK7Vh1JFgM5pQhxV1xjeeTJdx1dAu7hpdh/uMywu9vm9huSkUQwaxcjgYG99xe1Fq+sfwyAG790XcIcFwUpjWIFcFJV2WHsiepsqO+kt/+xq8Srq7w9Ou+OLH9I93H+Mbx14CCOFj5kyrB9x9ZoP/a4sSLgGdBCCSbASgzf7IacVPvP0VvvpiTUYsD3EnPw2mwasCBujM0H/JXCQC8CHhmSb+pAVCU1DtvcnU/EkvJxITiiCQd93cosVoigamaEVf3Ps/F3Yf4+77riaJwwr9fohDEoCadCiylIjiHWzkIwIawkrkim9PclR2OY7bEC/Eg/c8II8mpE5oCHGpALBibTk7KG14EPAtCdyYSvVGV7qA2UW6yv6mINaDmImq9Ab1rVp9sn1droIrt7wZjkP2k27Ib9kVbJEAZMGnTpGfSrzoSS0li4rJgu04NKhIZiy0pkghqwEXTWde5eBHwzIiJWP4ARnBnmCPQY0p8YCCdWmyX7JrYJ5JgSvfigjhKErN1eCM7TyznNz9+F1cWX+CE66KuAR/57G/Qs99y5F0VerpqLH93iBsfxxw4DMA7v/NvARhYNYIxjoevvnPi3AGGy6I6FwRPc+Q932V1dOKUa7+t9zF++pZBYhdQdwE7Ry9l5Xfn8I9qQ7wIeGaFmccGdCTprMLesEpPVJ9oPkDat2BLEHcL3aUafaVqOgNQTPoyAlk7v1qPMGZ6T8P+YJzeYHzKbQ0PxHPowugYvAh4zo0sw9DSYGZ3y0z8CFYHXSwzlvrgT3ixdwnroqMYUXpNFYswsrnO2NqQ37/kPlaFJ/hMzw2YOEF60vZ9dCINOeaO9mAD4NUnz23VUdOEkhje2beDCIGmmJZ1AsaSAk6FxAW57Bycj0CjzwEjgAUSVd0iIoPA3wAbSaMLvcNHHG5zGr78Lr2p//TotQD8+2U/BqDfdM3oNFN5/TkcMZYRV+Ko7eGxyjpGbXEiqlBhf0Q0Ivz9kZezrDDGiVetIaitJi6n50nWpH0OagWZFE8gEEMkBosSKad1HPZJjQ3dx3AqWAy7iy+Z6X+kY5ivmsDPqeqRpvVbgftU9VMicmu2/pF5upanBUzO5/fQh66GQPjef9+DwfGL5co0R6ZYdSdHBzjZN2DVUXExI+p4tLKBx0cuYMeXL2PJzjph1YJVLt61G63V+emeS9lTEL72x/+ZFUH3jL0VJ8cXaObKYpHNK7cCqRhtXv3KGZ2zk1io5sCNwBuy5duB7+NFoLMIJB2y46RPwMwOk0nr6bBepHBB4TiVcoGfrFXEFQiqaRzBZSeWYCpVxpcZbPH0c3jmxnyIgALfEREF/lsWSnxlU8ThA8DKyQf5vAPtjS0GqBEMMxOAxkw+q3LaE7xbCpQCxw3lPVS7dzP6piK7RpYzXCthVTiWrKR03HJiS42olNAtwbzNWYDmSVB5GxxMmQ8ReK2q7hORFcA9IvJU80ZV1UwgmFTu8w60MWOrItTA0mA089ab2VTiqW7e9CY0FMVgcGwsHcGpcCjqpW4Dtr1yOcF4wGUb99IT1ab1M5gtgRisuvM6I3IxMWcRUNV92fshEfkqcA1wsJF/QERWA4fmeh3P4uL45ek03A1hoy9gptN4Tqd5vr9Vx2u6n+Glxf08VVtNxRb53V/4R3pNnQsCxYjQPcNOyHO1AcjlGOFcMxCVAZMlJC0DbwF+H7gbuBn4VPb+9bka6llcSJwO09d0fivRgRhWBRXKWdTiWENWBuOUBKIsLZlnfplrTWAl8NVsIkcI/E9V/UcR+Qlwp4i8D3geeMccr+NZZAT11M12TMOzTt45V9YE3bhAuTiqYlWJJH3y57W6vtDMSQRUdTfw8inKjwI+hngHs/7nnseIsiqw8/5sDsSAOgwBRnTGYcxnSyPmgUNzGWrIewx6ZsUdm/4WgCVBeUHO37jhFzpJWEMAEixWNY9dAl4EPLOjmt08M40ctFg5OTJg0qgiOcSLgGdWxHTmqHoOWwNeBDyz41MH3wTAh1fcB8Al0cI0C84HDuW4q3LABjSFPsgNXgQ8s+LRoxcAcHhpVzo6ELXYoFnSaM6MOeWwLWOS/FUFOrFG5zkPjFaLVGoFnqpdwFP11a02Z07UNCYQ6DVV3AynSHcSvibgmRXWGZwoQ7b7lCAg7YZDsZmfw3z7O7QLXgQ8s+J/XvV5AC4IGgLQnn0CkQR0k05gWmaU1755O99dfg2FIwGFYWHtPx7DPfbU2U/UxngR8MyKlxWmn6PfbhgEQ0DRGDb3vMj2das5HPVjSyGuu3D2E7Q5vk/Ak3saPg5WHYPhKKt6RghKFg1BcxC7wIuAx9OEwRGKRURz4zPgmwMeD6nbcFUT3tj9HK9c/1N2XzDIgXiA//7QL9HX4ZnLvQh4PE0UROg1jqVmDBsaNAd1ZS8CHg9QlIiQgIiECjFGHC4nreV8fEqPxzMts64JiMilpLkFGlwE/AdgAPgN4HBW/jFV/easLfQsSn7v8GYArivvJBDH9V3t6zDUTOo3AMdsD7trKzBxqy1aeGYtAqr6NHAlgIgEwD7gq8CvA59V1T+eFws9ixKbh8ZyTpivPoHrgWdV9XnJwbiqJ830G4hjTTic5SVs/7DxjYCnBqHb1CiaOBcdg/P1EW8C7mha/5CIPCYiXxCRJfN0Dc8i4lwSjrQjLrv78xBpaD5yERaAXwQ+mhV9DvgD0qQkfwB8GnjvFMf55CNtzK/0p6m71obzH/67lcRqidXywW3vJnignzWPH5thepX2ZT5qAm8DHlHVgwCqelBVrao64C9I8xCchqrepqpbVHVLRHEezPB45o88tWrnQwTeRVNTIEs20uDtwOPzcA2P57zSVYiJy6DRQoc6bT3zkXzkzcD7m4r/k4hcSdoceG7SNk+HEOThSZmHz8jc8w6MAUsnlb17ThZ52oL14ezTji12AhF6ijVOlBWNOn94oPM/ocdzjlhVVAXUjw54PLmjpjEVtQxXi4QVgaTTxwa8CHhmyXGbZiM2WTd6j5w6wtOuyUhidYw4pRaHBDUQazs+8qAXAc+suH34cgBKEmNEuaG8M1sXAoQlQfv4flh1aR5C4Pkk4In6OqrP97LmqQRzfLTj/QS8CHjmhCVNHtogXWrPZ6fDYRGsCqIgFtD2/CznghcBz6xouNU6FISJp6VVbUtPG4ejqglj2sWQLSOxIIl6EfB4pmP76BoAQnEYcawKhwjEUZKYksSs6GqvSrTBEBEwYKqsKxxF11U5+jNddO3rg30vttq8BcWLgGdW/GDnpollEWXnqhUYUcpRneXFUd6w/p9aaN250Zg9GEnApVHMuuAQf/TKu3jsinXcu+e19DzWagsXlvbswvUsWkyb9gc0sJpmJLINd8E2bNqcK14EPHNCRDvKvdbhiLN+gHYXtJnimwOeWaH19PmhBsQob121A4CeoEqvGW+laXPioE14Nl7CAyObePLEKsJKe/VtzAYvAp7ZEWeVSAENHbcMPAqkzkMBArRnmrJ9toetlYt46NAGDh4c4KLRpNUmLTi+OeCZGx3WHKi4IkfjMtYZMPloDngR8MwNoaNEYMwVORaXsU4Q01kCNx2+OeCZFesuSiPKR4ElMpYe0xnRoTYVDvFzA0+ypnSC/cv72TmwueOD381IBETkC8C/AA6p6hVZ2SBp3oGNpMFD3qGqxyUNN/xfgBuACvBrqvrI/JvuaSVXLt0LgBElEksknRGBZ7lJ2Fx8kaXhKCe6yuzouqLVJi04M20O/BXw1klltwL3qeom4L5sHdKYg5uy1y2kgUc9HYpTwXVQ+l4LVDUk1pCqi1ptznlhRiKgqvcDxyYV3wjcni3fDvxSU/kXNeVBYGBS3EFPB+HUpJOIOgRHOimqrkE2OarVFi08c+kTWKmq+7PlA8DKbHkN8ELTfnuzsv14OobfXPaDieVAFCi3zph5JCKdHj1gKgQo2hmtnDMyLx2Dqqoi5xaIyecdaG8uijq3qhygFMRSMvVWm3JemEs97mCjmp+9H8rK9wHrmvZbm5Wdgs870BmY7K9TiEn7BMa0wJgr5qI5MJdv727g5mz5ZuDrTeXvkZRrgaGmZoPHs+ixGKyaiZgJnc5MhwjvAN4ALBORvcDvAZ8C7hSR9wHPA+/Idv8m6fDgLtIhwl+fZ5s954Fw9SoITjaIta8MImg2qy4kHfVt11iCkzluK7xoha8MXcP3D22imoQkNqDnaGekXD8TMxIBVX3XNJuun2JfBT44F6M8i4AggLBJBArpT0U7dGqtRYk1oOIKjNUL1OIQ6wy9rvPbA95j0HPudMbDHzgZZPTReh9/f+IV7BxeQZyk4hcYRwe5QExLB32dnvNCB/5iHA6rhroLO8rxaab4moBnSqqXrMKWTt7xQS2LIzwpCaFV19b9AtvqCbcfvY6/3/oK1v8DlPcMsXLXnontWu/8YUIvAp6pmTQ7sPGA7KQHpdU0xHiiATgwsYN6jNZqrTbtvNK+Eu45PyinjJXLFPn5rLZn9J0Ey/bqOr6z8zK6XgwxsSK2PT/LXPAi4JkxeUjOmUdEF0FyhT4Z1FfJaaONnhZiymUwJ58RbnT0ZCIOEf5h79ZT9m/XqcSN0YFRV2NEHW/60r/nwo/+qNVmLQj36lceVtUtk8t9TcDjyTm+Y9AzJRKFIAZMI/6+gQ5Nzek69HPNFC8CHgAkKiBBVjE0BunpSRNvGAERAqenJB71dA5eBDwAPPvJq4leMsKy3jGiwPLZi+9kuUkoicGIEJG2+Q/adNw8kp5Wmjuv2EXQL9ZKvAh4UiTNJtQIHBqgBCKYSXMFgg7yE2jG5mHO8DR4EfAAYLscS8rjvHPNVlaFJ7gwDChK8TRvwJUdOIGo0SdgIBchxifjRcADQHTCcOBoP9/vvZSBwjgn7C5KJqbPVAGoZ3G2Ki4NAHNT7/GW2Tqf7LcVHqpeQFUjRmyJaCh/KuBFwAPAxv87HRs/mr2eZS0AwaaL0o7CoREAkgMHAbjpxfYXgZrGvPvpX6H0O93IWBWGRlk/ti13YwVeBDynIpINB2YYA4HpyBTdE2HRRE4ZCckbZ3UWEpEviMghEXm8qew/i8hTIvKYiHxVRAay8o0iMi4i27LXny+k8Z75x3R1YbpKBH09BH09aCnCFSMoZK8Ow4iioYEwQIw5xUsyL8zkE/8VpyceuQe4QlVfBuwEPtq07VlVvTJ7fWB+zPScN4IgdRQKAgjD7AYx4BQ6cHJNbAPMWA0Zr6FxDLbzw4lN5qzNAVW9X0Q2Tir7TtPqg8Avz69ZnlZhyt0QRROegra7gAaCqddTIegQ0jkDjpFqke7de8BaNOn8NORTMR91n/cC32pav1BE/llEfiAir5vuIBG5RUS2isjWmHzN317M6NIB7Ir+dCWxhEPjRMfHoVZLXx2EVc1lJKHJzKljUEQ+DiTAl7Ki/cB6VT0qIlcDXxORzao6PPlYVb0NuA3SWYRzscMzf4xe3E+9x7D0/qE0uMaunwJgK5UWWzb/pPMHAadoB9VyzpVZi4CI/BpppuLrswjDqGoN0se6qj4sIs8ClwBbpzuPZ3HR/dMxSl0he395PbYIyx6NMbEjuu+Rk1OJgYdrqftwkHnaXVk8mUBmfzLKv3riZpZ3j/HJDV8jQInEcc/YS/ncU6/nTRue5k9Wt/YnEYghIuD1a3bzvz64BZOAJMrybWPw4GMtte18MysREJG3Ar8L/KyqVprKlwPHVNWKyEWkmYl3z4ulnvOC/vMTCPDOPx/n53u387/f/e8IqiEv+UGExifj7X116GqALC255cri0xPbdsT99H6yl4MXreDbH9lMJJZeU+W/PPpGNv3uUb71/lfyJ+9t/XOhKBH/YdV32fahRzjhujmW9PBnf30jax9stWXnl7OKwDSJRz4KFIF7JB1XfTAbCXg98PsiEpPOO/2Aqk7OZuxpA47GZQ7YPnp3G6KKopN6zRtt6Zipg4mIdRirODWNSje6CNvfVhWXdY0ZUe82PBXTJB75/DT73gXcNVejPK3nWFzmQDzA4FN1ouH4tGnEjXTkdoqmtFWDxBZpk9E2i6QTpshHnoHJeI9Bz5T8eN969lf6KO0bxYxWSCZNt/3qt189sexC5ZP/evvEekEscX+Jeo+wMhqi29RYEx5n6cAoyeolJOXF0wn33fEN/P62X8BZg00MK3d3ni/E2fAi4JmS8QM97KpFXHL4RdzQaYM7rPlePLFsuwz865PbjDiScoDtEpaHw5SlzrqwworyKCODS3Bdi+dG2za2nsLDPYgFSaDnhc4bBTkb+fOR9MwIUxXseAhJgk7hKdgIPS6TQpIDVF1E6eA4pWOOHdU1/DQexABLi2OMrAkJ+hZPQo9l0SjjKxz1PtK7IYdzB3xNwDMlkgjEqbvw5E7Bs+EwBCNVorEujsS9lCQhAMpBnbhPKBbjs57jfNETVLE9DkmyjMs5fCx6EfBMyRt/bhuv79/J//Xpt0MsXPrvHjslJVflwycmlgvBqSKxpXiMlX95gM2FXbxv8IeURFkWdPHB5d/jovcd5uVdz5+3z3E2big/SfkNNY4lPeyv9/NteTWrf9Bqq84vXgQ8U/K2Jdv5he4hfvgzjzNuIw6E4Ski8N4LH5hYDibNwF8WlPnL9f8rWytPlF9W6OaywcXlNrI27OKXe35KRS0jTvn60mtbbdJ5x4uAZ0peqC9lT+EgD+7fQD0JWad70jgDk4YKC5IQtctY4BQ4HFW1VFWpq8llliUvAp4pqWpIVQPGawXiePrsQqYD4vA4Un8Hl0dPIbwI5A+TxQuwNu3wmybc9n2HXspQ0o081kupnqXodief+I0mQEEsRhyxntxmkLZKVx4hlA2U1KLtmU1tTrTPN+WZF8QIIs1ZhaammkQMJyWCKoTjp28PxBHI1LUAt8jDd0+VRdkAQQ6HB8GLQG6Rri6Cvh5MuYwplU4bH9/Uf5gtPXsY22AZ3eBOEwyrJn210U+opjGx2tNqKRadaNQsbvlaGHxzIKdII6CoMVM2CSJjKYhFA8WF+XxC5gUvAnnABBx/9zXwjiNcPHCES3sO8o3P/CxLbp8+BfeFXYe5vLif616+k7oLGAkM2uTj88qu54A0nkCshuu2/SoAUWA5OlxmzX8roAKuYDj0iohH/+2fpdtbmMI8zGY8NvdffOrIy/nSt342dRu2sPaB/IUY8yLQ6WTVfBfB0tI4K0ojrC0cw53lm09n1SlFM/VN0QgmYrL3Wpye0DohiUOi4ToaCC4KCKsRDncyxPciItYAU5MJETBx+492nCteBDoVEUyxiPT3ocsHWfbwMPr4ID+4ej13X3o1Fz175niBGwpHuDAMWFkcpuZCjlKYcj+HYJGJtnQ9CXGJnJySm933sdoJwVgsowcTKclF0ZBUtHLY9Jlt3oFPiMi+pvwCNzRt+6iI7BKRp0Xk5xfKcM/MaIwEiCqSOMQq4mb2Q89rb3nemElN4K+A/xf44qTyz6rqHzcXiMjlwE3AZuAC4F4RuURV29elrM0wpRKy7gIkTtATQ7iRUfTIUcbfdhV7rzcs2Q4Xf7lCsOcAZ/pSSqZOUSL+n5VpvL27t3fjMHx029sB2FzYNrFvrJZXX/AcAE4N24ur4ce7UnuAwZ5XsisWIrGUpE6vEVYEZc4Xk4cEHQ6rSozlvv2XcNH/OJR2jqrC8aEz/l86kbPWBFT1fmCmIcJuBL6sqjVV3QPsAq6Zg/n5VsEAAAzVSURBVH2e2XC2J7jTc84hEIjD4JBO9KudxmEqL8ylYfahLA3ZF0RkSVa2BnihaZ+9Wdlp+LwD84wJCJYtRa+4mGfeu4IDb1mDPTGEGxtDk4Ran6G8cYihS+Hw1T3oyqXndPpeU6XPVCkVYkqF06cCB6IEmUBMFcvfSKM/IH1N5bCzUARiJl6QxhU8jRwLwWxF4HPAS4ArSXMNfPpcT6Cqt6nqFlXdElE8+wEeJCqc8poSVcTBZGc+UbDWpOUz+L3HGhKrZdRVGXVVRlyJYVcicYbEmYny9FVj3EYTr8RO+lkpVFxEVQMqGlBRZVzr1HRh4wrEaonVUtN4wlEomVTZN6IQBmnatSDIZVAR0RkoYJaG7B9U9YozbRORjwKo6n/Mtn0b+ISqTj8gTZp85FVy/bna3vGEq1edXAkCvvbQ3UDau/5UXOP/3PjqaY6cOwd+6zUkZVj/J9twUyUeadwsM/j9BMuXM3bthbhQsAXBJEpQV154s/Bv3vB93tizg6uL048axGpP9uSThgqfisb4/864zogr8CsP/BtcbOh7tIgtwfjmcVYsG+afXva3E8d8o9LDHz37VoRUEMbuWsWy2874c21b7tWvPKyqWyaXz6omICKrm1bfDjRGDu4GbhKRoohcSJp34MezuYantUyEDRMBM4WDj5gzzj0427nFKWKFiitQ1egUB57JuHOcqRiroU6Q2q+CBqAC6gTrWj80udiYbd6BN4jIlaT/5ueA9wOo6hMiciewgzQ92Qf9yMA8YEw67p9NdQ3ETIy5T4cUiwRLBtBaHTcycsYZg1NROuoIxwVeso4gtnD4GKhij6Z9xOGa9Dlg9x8AOHMyT3WIUxp+R4XhhMLhMZZvHeDO6mt55Np1/Pb6b3NpNMTyoDjhVNSoGQy5OnVVDtoCFuHqgiMQc1pzIlaLRbnjxKsZtxHBvhLGQOWqcWwtoPupEofXh2kjduKYkEqtQBg4CmHi4wlMxbnkHcj2/0PgD+dilCdFB9PEoBqa2bdV1aV59sSkiTXUzawKH4Org9hsJEFPHVFI1gyCU4Is2pA9eOgMNigmVlTSp7+pOyRxBHUlHDMcGOnl0fENRLKbWEc57IpUNaKABSxj2odVwwvxUmINuCLaQ0TAYZt2KFeyjsgAxSKMJUXGbZQ+ohw4K2AFY0Hs6f/HMHAEJn+egg28x+AipvLZGlFgWV8+jhGdk5dd0N+H9PeiI6O40TE0Tk6JDzCZgR/thTBARyugbqIG0ODLf/vnWJTrHvhNkjjg4l+dXgTs0WNE3zn1eAv07IAe0j6Deweu5C9vfCujFydc8ldV5OGnMD1lCAzjWy7CloSexw8jccLAdyqsi47ygUdvwTkh2dEHQLwhFQUxilqhfDQNHDoeFAlq0LPXkZQCEtIOw6palgYhr161h0O1Xg6M9VHNYWvBi8Aix6lQDJKzVv+nJJspKEaQUhE30INJLDJWOfvZGtX7ydX8rEZiREChp7tKtT51R92McRZJLNGYEg4HSM2mNZYsynE4niAuQOIEEssDIxezqrCC0RNd4IRCo49yLP05a8GlT/4E1IBJwCRCY1jEqmLRLKRYDqOITMKLwCKmZgMiFS7r3n/Ox0oYon09SBgitRqVl61l/2sKrHqoTPcDo4h16BlqAknW1p+M6ekBoN90AfBfN9/BAdvP57j4nG1sYI8PIaNjrP6WsrKvG/bswyUJdjhNemJ+cBxD2skE8MinXoULhYv3VhGFPf8yFaG196RqcOIlBVDoPpSmFQuqBnHZlGgDoxoz4pRn4yW8mCzBiM5OZDsELwKLmAN7loKBL8avAmBvfcnEthcqS4Dj0x9sLVKrZ2HBHNFITNfBAtFwnDYFZuuskz2dP3LwSpwKz4ysYCQuEvLT2Z2vgVOo1ZFKcNY8B4UTCRoawtG0P6L7YPdEOQJdhw0oFI9byGoCohBWHPWekI+/+BbGbcSRapmRepGjw2XiWogbi7jgWP76BmbkJ7DQeD8Bj2fhmVc/AY/H0zl4EfB4co4XAY8n53gR8HhyjhcBjyfneBHweHKOFwGPJ+d4EfB4co4XAY8n53gR8HhyzmzzDvxNU86B50RkW1a+UUTGm7b9+UIa7/F45s6s8g6o6jsbyyLyaWCoaf9nVbUpdovH41nMzCSy0P1ZMNHTkDS9zTuAN86vWR6P53wx1z6B1wEHVfWZprILReSfReQHIvK6OZ7f4/EsMHONJ/Au4I6m9f3AelU9KiJXA18Tkc2qOjz5QBG5BbgFoET3HM3wnG9MqQSAq1ZbbIlnrsy6JiAiIfCvgL9plGXpx45myw8DzwKXTHW8Tz7S5hiTvjxtz1xqAm8CnlLVvY0CEVkOHFNVKyIXkeYd2D1HGz2LEDc+3moTPPPETIYI7wB+BFwqIntF5H3Zpps4tSkA8HrgsWzI8CvAB1R1pslMPe1EI4uvp+2Zbd4BVPXXpii7C7hr7mZ5PJ7zhW/UeTw5x4uAx5NzvAh4PDnHi0CemW1+Q09H4UXA48k5XgTySpan0OPxvwKPJ+f4XIR5RRVoyrvX6B+YoQOQRIV097g+z4Z5zje+JuDx5BxfE8gzk5/6YkDPnBF44lBfA+gYfE3A48k5vibgSVGdcS3A01n4moDHk3O8CHg8OceLgMeTc2YSVGSdiHxPRHaIyBMi8ltZ+aCI3CMiz2TvS7JyEZE/FZFdIvKYiFy10B/C4/HMnpnUBBLgt1X1cuBa4IMicjlwK3Cfqm4C7svWAd5GGlZsE2kg0c/Nu9Uej2feOKsIqOp+VX0kWx4BngTWADcCt2e73Q78UrZ8I/BFTXkQGBCR1fNuucfjmRfOqU8gS0LyCuAhYKWq7s82HQBWZstrgBeaDtublXk8nkXIjEVARHpI4wd+eHIeAVVV4JyiTorILSKyVUS2xtTO5VCPxzOPzEgERCQiFYAvqerfZcUHG9X87P1QVr4PWNd0+Nqs7BR83gGPZ3Ewk9EBAT4PPKmqn2nadDdwc7Z8M/D1pvL3ZKME1wJDTc0Gj8ezyJiJ2/B1wLuB7Y0U5MDHgE8Bd2Z5CJ4nTUwK8E3gBmAXUAF+fV4t9ng888pM8g78EzBdMLrrp9hfgQ/O0S6Px3Oe8B6DHk/O8SLg8eQcLwIeT87xIuDx5BwvAh5PzvEi4PHkHC8CHk/O8SLg8eQcLwIeT87xIuDx5BwvAh5PzvEi4PHkHC8CHk/O8SLg8eQcLwIeT87xIuDx5BwvAh5PzvEi4PHkHEmjgbXYCJHDwBhwpNW2zIFltLf90P6fod3th4X9DBtUdfnkwkUhAgAislVVt7TajtnS7vZD+3+GdrcfWvMZfHPA48k5XgQ8npyzmETgtlYbMEfa3X5o/8/Q7vZDCz7DoukT8Hg8rWEx1QQ8Hk8LaLkIiMhbReRpEdklIre22p6ZIiLPich2EdkmIluzskERuUdEnsnel7TazmZE5AsickhEHm8qm9LmLJfkn2bfy2MiclXrLJ+wdSr7PyEi+7LvYZuI3NC07aOZ/U+LyM+3xuqTiMg6EfmeiOwQkSdE5Ley8tZ+B6rashcQAM8CFwEF4FHg8lbadA62Pwcsm1T2n4Bbs+VbgT9qtZ2T7Hs9cBXw+NlsJs0n+S3SFHTXAg8tUvs/AfzOFPtenv2eisCF2e8saLH9q4GrsuVeYGdmZ0u/g1bXBK4BdqnqblWtA18GbmyxTXPhRuD2bPl24JdaaMtpqOr9wLFJxdPZfCPwRU15EBhopKJvFdPYPx03Al9W1Zqq7iFNkHvNghk3A1R1v6o+ki2PAE8Ca2jxd9BqEVgDvNC0vjcrawcU+I6IPCwit2RlK/VkGvYDwMrWmHZOTGdzO303H8qqy19oaoItavtFZCPwCuAhWvwdtFoE2pnXqupVwNuAD4rI65s3alqfa6uhl3a0Gfgc8BLgSmA/8OnWmnN2RKQHuAv4sKoON29rxXfQahHYB6xrWl+blS16VHVf9n4I+CppVfNgo7qWvR9qnYUzZjqb2+K7UdWDqmpV1QF/wckq/6K0X0QiUgH4kqr+XVbc0u+g1SLwE2CTiFwoIgXgJuDuFtt0VkSkLCK9jWXgLcDjpLbfnO12M/D11lh4Tkxn893Ae7Ie6muBoaYq66JhUhv57aTfA6T23yQiRRG5ENgE/Ph829eMiAjweeBJVf1M06bWfget7C1t6gHdSdp7+/FW2zNDmy8i7Xl+FHiiYTewFLgPeAa4Fxhsta2T7L6DtMock7Yv3zedzaQ90v81+162A1sWqf1/ndn3WHbTrG7a/+OZ/U8Db1sE9r+WtKr/GLAte93Q6u/Aewx6PDmn1c0Bj8fTYrwIeDw5x4uAx5NzvAh4PDnHi4DHk3O8CHg8OceLgMeTc7wIeDw55/8Hr6RsXXz1Y98AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fDIetz0HgA4R"
      },
      "source": [
        "### Impose the mask on the image (3 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue6lcixgtn2U",
        "colab_type": "code",
        "outputId": "bb73a47c-bbc7-43bf-a919-b3274b935521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "regionReshaped = np.reshape(region, region.shape + (1,))\n",
        "print(regionReshaped.shape)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHi3vNFQuP_x",
        "colab_type": "code",
        "outputId": "551d2336-5152-4d8f-b975-3f837b84b695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "pyplot.imshow(X_train[n] * (1.0 - 0.6) + regionReshaped * 0.7)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f756d30c940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqy5H19edYtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}