{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "efNjNImfOIUC",
    "outputId": "8a3278d7-f331-4324-e70f-a8170db57f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l9C4aAIGOIUH",
    "outputId": "bb6888ab-b888-4b39-d96d-2542950abd31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ"
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XA1WsFSeOIUS",
    "outputId": "f18c6310-c432-436f-c7ba-fb781fcd5ddc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UbiHj5YPOIUc",
    "outputId": "f6afe228-0d6c-4756-bcf3-f372920545ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj"
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY)\n",
    "testY = tf.keras.utils.to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "RHV3b9mzOIUq",
    "outputId": "d530ba2e-b431-4f6e-f211-b00ded27a1f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvDML2OoOIUx",
    "outputId": "9dafc94e-61a8-4089-be03-d143163d68aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABSCAYAAABwglFkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXl8XFX5/z+ZmUwmyXRL6UqwKaVl\nL6UVLEsptGwqBVrAFlnlBS8papVNEHghqFihKpuILCqUCrzEsggUsGBRBKQgYqllh0ibUmi2Jk0y\nmUwmvz/m+3numXPvTCa5k5n0x/P+Z5KZO3fuuWe5z/M5z3lOSU9PDxRFURRFUZT+ESj2BSiKoiiK\nouzIqDGlKIqiKIriAzWmFEVRFEVRfKDGlKIoiqIoig/UmFIURVEURfGBGlOKoiiKoig+UGNKURRF\nURTFB2pMKYqiKIqi+ECNKUVRFEVRFB+oMaUoiqIoiuKDUCF/rKSkZIfeu6anp6ekt2NyKWNJSQmy\nbeOzxx57AAB+9atfAQAeeugh/Pvf/wYAxONxAEBXVxf22WcfAMD8+fMBAB988AEAYNmyZWhubu7t\nMjzprYx+6nD06NEAgLPPPhsAsHz5cgDAli1bsn5v2rRpAJz7snLlSnR1dfXrGvJVh17U1NTg8MMP\nBwCccMIJAICGhgYAwIoVK/D6668DcMpx0kknYe7cuQCA9vZ2OQ4A7rzzzv5cAoCBLaMfxo8fDwDY\nvHmz73P5LWNJSQnP4/k52+qcOXMAAOeeey4AoLm5GW+99RYApy8OHz4cBx98MADgn//8JwDgiiuu\nAAB0dHR4/nYu23gNZF8cDORzPDXOmfG42bNnA0iNk5s2bXJ9XlNTAwA44IADAKTGXb8M1r6YT7SM\nKUoKuTff5+KGepQx28BNQ2HRokU46aSTAADd3d0AgMrKSgBAeXk5Ro4cmfE33333XQBAMpkEAOy+\n++749NNPAQDPPPMMAODnP/851q9f39vlD9gAHo1GsWjRIgDAd7/7XQDOw6i+vl7+5uuQIUNQVlYG\nAKiurgYAPPbYYwCAl19+ud8DXT47/pe//GUAwIUXXggg9eAMh8MAgFgsBiBVDgDYZ599MGbMGABA\nbW0tACCRSOCTTz4BAGzbtg0ApMw777wznnvuOQDAkiVLcrkcYSAHt+eeew4jRowA4BiK5513HgCn\nXCbjx4/HmjVrAKTaMQD873//AwAce+yxaGtr689l5LUv7rTTTgCcdnnkkUdKPfD6+P8ee+whdUq6\nurrk4cz6ZFkbGxvx97//HQBw6623AgCamppyKKEaU0BuZQwEAjL2kerqapxzzjkAgIsvvhgAMHTo\n0Jyui+NvIpEAAFx22WW4+eabPX8XgOu3TdTQSPG5KKMaU7mTr0YzdOhQUWWmTp0KINUxW1tbATgP\nYqov3d3dKC0tBQAMGzYMQGqQZyf2qsNIJALAGdTD4TBeeOEFAMAZZ5yR8doGcgA/5ZRTADje+pVX\nXgkg9cClocGHVlNTE7Zv3w4AWL16NQDggQceAJAyzB599NF+XUO+6nDSpEm45pprAEAM14qKCtcA\nywF5l112ke/ys2QyKUYUj2OdNzY2YueddwYAURkvueSS3i4LwMAObs8//zwmTZoEwKkrtrHW1las\nXLkSAHD66acDAILBoLRnloP1v99++/XnEgDkz5iaNGkSHn/8cQBOPcZisbS+BwCdnZ0AUvUSjUZd\nn9GIHjVqFAAgFEqJ/uFwWD6j+vib3/wGjzzyiO8yft7HUy9jhurv5MmTZQzkfadhHIlExKBlmxw3\nbhwqKirSjme7jkajaGxsBAA8++yzAIDTTjst63Xkq4z9paSkxHVd5nPCVPPsz0youL700ksAUo46\nkHLg+Z1iGlO5liMT9913H2688UYATtvhuMY+/3/n7bWMGjOlKIqiKIrigx1emfKKPxgyZAgOPfRQ\nAMBTTz3lOj4YDAJw1IBM5yX5tsCfffZZTJgwAYAzVZJMJsWb5XWZ10Avg9NgLIP5WbZy9PT0YNy4\ncQCAY445BgDw9ttvu44fSG+Y3txnn30GwIlLWbJkiUwd0Stobm7Gv/71LwDA7373OwDAxIkTAQBb\nt27F008/3a9ryFcd/vrXvxbFhZ5fNBoVb5h1SC83kUiICsVjksmklJeYUww8P2Pjli9fjieffLK3\nSxtQT3HlypX44he/CMApW1VVFYCUKsO2yKmtqVOniuLD9s1pPsYj9Yd8lfGPf/yjTPNRfSgtLZU+\nT4WKddzZ2SkeK+unrKxMFGMqyF59lwpVaWkpTjzxRAAQ9bU/Zfy8KlNeU7Uvv/wyAEjb3LJli/Qt\nHscxs6enR1Qo1k17e7v0PdahGe/G99hWHnvsManDbNc1GJQplitXGPe57777YvLkyQCcGRSW8eij\nj5Z+MJBl9Hq+e93nbHFzrDszzpgK+pQpUyR8hPXJfspn7f+dU5UpRVEURVGUgaSgq/kGgkAgIJb3\nbrvtBiC18oZeBefJ6UWuXbvWpUiZVjwtXPMYUwXyw4wZMwAAEyZMQH19PQDHWw8Gg6JYMFbG9J7o\nIfP47u5uuVZa3rzm1tZWCYg1y8H7xJVJucbg5At64fTuqFBcdNFFEmTOmJOPPvpIVDsez7Lb8+TF\n4J577pHA861btwJIxdwwONlebRiPx6UcpKWlxXO1F4+n2rFx40YAyEmVGmg+/PBDzJw5E4DTtuih\nmvXCYPRZs2ahrq4OgBODwnZdTKjSjh07VhRDeqSJREKukYtAzPgT9iO+RiIROc4OXu7u7pZ2zzGo\nsrIS8+bNA+DEASq5YysP8+fPx5e+9CUAkHGvpKRExkU7Zqinp0fiU9lmA4GA/M06ZHtNJpNSnx9/\n/DGAlDLDBSic/SjkLA/JtLipp6fHU5E688wzATirTmfNmgUgNTvAVbZUod577z2JI/re974HAHjj\njTfyXYSs9PT0ZIyL8pqdCYVCMqbyPY7Fhx12GB5++OG0995++21861vfSjt/f1eKqzKlKIqiKIri\ngx1emQoGg2KBMwbjyCOPFA+F8+b0NI866ijcfffdAJzVO15WPFfsJJNJiQ3xyxFHHCHXxOui1xQM\nBsXDv+yyywA4+Xg2bdokOXq49DoQCMicLs/Fa54+fTq+853vAECaAsbfOvnkkwEUXpmyFUFTqeF1\nMudURUWFKHSsG9OzLDZr166VOI3jjz8eAPDKK6+Iesb2RnUtHo9LGalQVFRUyPEtLS0AHGXOPMfl\nl18+oGXpCxs2bHAptVR/4/G4eLWko6NDPEu7rMWEMXpjx46V9kVlqrKyUtqq3U9LSkpcnnIwGJT3\nzOOAVNtlnbL+w+EwjjrqKACqTPUFtjt7rH744Yfl3lIZbm5udqn5pqJB1cJrLOF75rhjzwJs27YN\nq1atAuConBy7QqFQ1njcQsO8dqFQSOKhGFvGfnDPPfdInCPVqBkzZkjOLT5rOPvz/vvvF+bikXm8\nN9sB/zZVJfZFrqR+8sknRSVmW7roootEOe8t91xv7PDGlBkkxoqvqamRm8VOw3xL+++/P2644QYA\nwGuvvQYAePPNNyUR34EHHph2rpdeekkemn6hEZNIJFwDQyQSkemGu+66C0BKSgZSxtHvf/97AMA3\nv/lNAMD69esl8JfnonF444034oILLgDgDCSRSESMQnauKVOmAHDyVA009gDGsgeDQQwfPjzj9+xG\nzjIVm1tuuQWAk5/o448/lik/Ghi855xWAJz6amtrk7JwkOZxw4YNk+mDwWB8kLq6OhmwWJ+89k8+\n+UQGYpajrq5Oyst6ZDsvJjT6gsEgxo4dC8ApTyAQEIOXDg0T4tbW1rpCB9ra2uSe0CDj+Y877jg5\njm08Go3KtKCSO7YRxcDh5uZmeUhyYU9zc7MrPQnJtmDHxHTezLEKSNU5p5NooDz44IOe1zmQZHrw\nV1RUSFoDGnktLS347W9/C8DJjcf2feONN8qCIJ7znXfekdAUGv9sy4U0prKlnmBKHRqFI0eOFEOR\nn3GMbWpqknvBEAoucsrLdebtTIqiKIqiKJ9DBoeL3w9MtYJWMy3S1tZW8fyovvD11VdfFaua02IH\nHXQQFixYAMCRCV999VUAqWBtM3mXH5ikcOPGjWJtm0vj7Qy9XP7f1taGvfbaC4AzNffII49IECst\nb1OepTdmBsbSsmcQ5UEHHQSgcMoU7zfLTC8nGAymTXcC3kvL+cpA/WJiSvlMw3HdddfJ52ZKBCAV\nzEpPlvUVCoWkbdneciAQkGSSg4nNmzdLH7GntmKxGDZs2ADAUasCgYAru/tgWEBAFeGFF16QlB1c\nNv3Tn/7UM20IkPL4GZjM18rKSmmTVK04ffeDH/xAxhJ6yu3t7dh1113zXqbPGxy/AEcRtIPIAe/w\ngFzaoPk9+7ylpaVS53zusE0VMgyB46UdZB+NRl2pVQ4//HCZ2Tj22GMBODM2gJOyhowePVrShTDk\nglnlX3zxxZx21MgHdhmZNPimm24StZdK+N577y3TdnvvvTeAVKJhIKWSs51w3O1tlqMvi89UmVIU\nRVEURfHBDqNMZfMkfvzjHwNwAgEBJ3iXygBjqw499FDxJGjpvv7666JW8Xgul9x1110l1qm/0DNg\nPI0ZM8VylZeXS7Cy/b3Ozk4pG9WPkpISl0JgemqcCzeDuFleKiRcFnvvvff6Kl+u2KkNvJYle73H\nOqF6k69UFX4w4zC4KOCDDz6QxKL0CukxJZNJeY/l2L59uwQn22Vk2ojBRn19vWwIS/WG5SopKXF5\nevF43OXV93fpcT5h3GQymZS9A7mZ+NChQ6VsvHbGrTU0NMgWJCyHqVwwFoNe8QcffCDKF+N6Ghoa\n8qZ295dsy81tlSNbQLXXvngmdtqWfKo2HMfC4bArTskcH82kjUCqPHbcZiAQyBjTaZ6D9RYOh0WF\nZP0WekEP4L1VDJC6NywPF2atWLEC559/fs7nHjlypMyWML6Y5S8rK8u6X2w+sccLxi+effbZrmem\nF3zuRiIRvPnmmwBSyXqB1HPSVr7MZ3NfFhLsMMZUtk7IfZZocHR0dMiUAgd3TjHFYrG0/CFAyqhg\nsB4bIIPx+ptp24Sr8/i727dvd+UyicViUnE09thYq6qqpDNzqqCrq0seYpQuKXkuXLhQAvI44Awb\nNixt8DF/p1CY2YYBpC0SyCbPk2I/gHojEAjIaiK2LbbDlpYW1ybI5uIJu9PakvtggQGcgDsA3Zyq\nZN2Vlpa6VlXlutHvQMLpjblz58oG41zwce+992Lx4sUAnD7FVUzRaNSV5yYcDktdst5XrFgBIGVM\ns//zmKamJgkr4LjD6ZRCkWk89co47fVA4f256qqrxGHzYiAMZ4ZLcDVwS0uLTLnxHkciEZfzYu6J\naRsh5ns2Zp4/jlMjRoyQ3yrmyr1M9dja2iqr8/gKpD9v7O/bC33GjRsn7ZJOIRfFjB8/XoL9i0VD\nQ4PLwfZqb3SWFixYIGPP7NmzAQDXX3+9yxA3/++LwajTfIqiKIqiKD7YYZSpbNj7LAUCAVE/GPxK\nObCmpkYsb3NKieegVWrnqPADd9zmEuzddttN5FMGiL/33nvy28xOa3pS9tLcUCjkUnNY/tbWVgkq\nZ7nM3CqcAnz00Ud9l60v2EHWprxqp7IwoaJBZYqqYbGxPd5NmzbJknh+ZuxfJQqOmQ6DaiE9RXrb\nDKIE4NqzsdjYCqG1FxkA5550d3dLee0ps2Lys5/9DEDKk2V/YHqUefPm4eqrr047nh5vZ2enK++Z\nOW3POqYS3tTUhLVr1wJwVL01a9bgvffeA1B4RcrGViO82tipp56K/fffHwBwyimnAHAU7/r6egm2\nP/XUU13fpRr7/e9/HwDwk5/8xPc1m7tG8NrtDPRmBnRznOf/dt/NpI7zM94Xc19XHsfdGwYb9vSV\nObbmsm/fqFGjZGqa94bnjEajRR+PTBXVVKTs8XL58uUAUm2X5abSbC4MIlzsddttt0m+ylxQZUpR\nFEVRFMUHO4wyZXsXtKij0ahkB6fH3NnZKbEqnNemUjV8+HBRqajahMPhtGSJALBu3To5v9/Yottv\nvz3tdcSIEbIbN2MPZs+eLV4ql5wy0LW0tDRr0LV9b2KxmKscDJIsFiNGjHAF3dOryJREjx4VPQ1z\nbzPGSPC9wUBtba2UhR45Y9dqa2vFU+I8fFNTk2t/O36/2F5fNjLFlpiB2GaAs13fDNwtJtyja+7c\nudK/GQ/y5z//WdRPphExlSe2PTPYnvXFcYbjztChQyW2hPubTZgwQRI9Mui9kHuemR69HXOz2267\nifrEeK6jjz5agn7pqVNdrKmpwVe+8pWMv7Vo0SIAkL3z8sH06dMBOCpgT0+P9Bve946ODlEHzdhE\nHm+3YVMdJ/zfaw+48vJyeWZQvWEZX3nlFT/FyxtesUBUYeyyesXKVVZW4qyzzgIAPPHEEwCA+++/\nH0CqzPnaGaS/ZIoXs+uW197Y2CjPRc5YzZkzR9o0xwQyYsQIfP3rXwcAnH766b1ejypTiqIoiqIo\nPthhlCl7BQ2t7oULF0osEpdAlpeXi3XKuXTGPsXjcVGtzFVGXOVA1eC2224DAEybNi3v25eYcRRU\nJObMmSNlNPcIY5lta9vcI8xeORaPx8V7ZrxWsens7EyLH7Kx3zPjGgjrftu2bYNKkSIdHR2eHi+Q\nunbWCd9ramqSGCmuAiT0ugcjmZTEkpISl8cbCARcS80HQ8wb4yI6OjoklomxiocccoikJfHaod5e\nCWb2RTtOZcuWLeLNU3368MMPsXHjRgD5T5hrxwKZKw2J2de4WpEpVxYuXCiKA1N+rF27Vtojx0mm\njqiurpbUNGT06NFYuHAhAOCXv/wlAGcLqxkzZvjewsNW4pPJpOcqLju1CsfH7u5uGdO94okI71NZ\nWZkoGeaYbJ+XyqNX7Fg+8buHHABXDK75HqmvrxfllOrtHXfcASCVOLNYzxav8puKeKb7smnTJhln\nuRXbE088IcdzBTXb0vPPPy99IBd2GGOKjd8eGNavXy8PaXZ4c/NjDtx8+DY0NMhxfLhVVlbKkklK\nfpT3li1bJoOsX8zNMlkOVmRLS4vLUMy2bDUbZgfhVKH5fqbcJANJT09Pv/NDmYPaYMI2nBKJhBj0\n5jJ4wr/5WXl5uXRg5pvilMFgxs5RZA5k9jSlmXuK7zFPVTFhBvJQKCQBxDSq2tvb5Vo5lWOWK9OG\nu4DzsOWAPGrUKDFOOJBXV1eLEUNH8MMPP/RVHq/pVcA9XgLp6SA4zjH0YcOGDVJ2LpIZOXKkTA+x\nLHy4btmyRc5x6aWXAkgZqMznwz7Lsdbco7K/2OcwN303UxjYBpJthPWGV14qlmfbtm2uRSaF2pkh\nn+O2VxueNm0aAOA///mPZHU/7rjjAADHHHMMgJSRToeg0GQrf7acZ/vtt5+EvTA0aNGiRdLOr732\nWgBOH169enWfrkun+RRFURRFUXxQNGXKlsXNZav0CEwrM1NA7qpVqySg1UxKSeuVSgF/JxKJuCTh\nrq4uV/ZTLnHP5w73Xss4GdjZ0tKSUX0zA3uz7S/F75lTROYy9FyWww4UXtMkXh5its/M68+2k3ih\nsK9hyJAhEnBOD55yMpCSzQFn4cOwYcNcdc06NRPiDbZgdLvdmX3X6xhbyRkMypS5WIPXRcWjoqLC\nNR6YiyfsvSJLSkpc7ZZT9cFgUOqdVFVVSV+nh+xXmfLK2k2WLFkCAJL9esyYMaLAU0Hi95gUGEhX\nsO22znHV3E+U0z7z58+X96666ioAwAUXXAAgFdCfSzBvNq644goAzjiaSCREMWJ/q6+v7/cekKxr\nMxErz8+xtbW1VaY8+dw58cQTAWSfahoseKmrTC7Le3j77bfjjDPOAOAol6tWrQKQGp+8VM9CYz8X\nQ6GQa2aHx3R2dsrz0KttXHnllQCce/PQQw/16VpUmVIURVEURfFBUZQpM6YpV6/7sMMOAwCZ6z/k\nkEMApBQAWs30Bk3r1N66pKysTOa2abmaSzx5DsauLFiwAI8//nify5iNQCAg10evxgyM5z0x97Kz\nrWzTQ+ZnnLuvqKhwBV8Wm0gk4lqObSbJy7bvnu199PT0uLZmKQa2KrZ161ZJa8F4AqpQsVhMvH56\ndLW1tXL9XLLLgEcqFoONKVOmyL23U1cAbpXKDM5mW2TQfTHxUpWYmsRcwGL3MfNvsx1TJbG3sQoE\nAhKLxbru7u6Wdm4vPOgP06dPx1FHHQUA2H333QE48Tvjx4+XFAGMn6yrq5P2xuPMMZHjoZn0kuOV\nHbjd0dEh5TrwwAMBpJIC8zepgDFJaUVFBc477zxf5WW8m7lPHO8797QsLy/3HajN78fjcSkPy2/G\ngPK92tpaX79XSGyV+JprrpHyUHU8+eSTpd5sJXUgtgkyn2mmcmQmr+6NZDLpuv+vvvoqgFSyXMZ8\nmZgqMuC0IVtR7o2iGFNeUjSlxfHjx0sOJlbcggULMGXKFADufDzt7e2yAo+ZjGOxmNwgBqDzAVZR\nUSFyNDvIYYcdJhXFaT02lpkzZ+ahxOmYlW1mirYHaXOqy552ANwBlWb26WwPgWJgPlRzmbLMdA6S\naxBpIZk1a5ZM17BD8kHT0tIiUyJ8kHV0dEi7NDfpBlKByWy7DFLvbVPZQrDnnnvKA9LeSBZInw4j\ndqAujcqDDz646KtNzZWyn376KQBnxZqJuXLWNJT4amfPNvupPR1iOlN+Nu3+9re/DSA1PvKaTQMA\nSNUNjSN+Fo1GpcwMkaChFQqF5DMaWCUlJWKs8Hr5e5FIROqfUyiJREIWW9CA5vF+jEfuAUgHxZw2\nt/dGNOvVa28+uw4Bp+7sHSU6Ozulz7LNx2Ix6c8sYz52y7DJttgh1++y3sPhsLQFrq5ctmwZgJSx\ny+u/+OKLAaSPzwxKpyH78ssv9/l6eC22M20+9/yGoJjj48qVKwE4U9nf+MY35DOzTbAtsF1xBWNf\nGXxPJEVRFEVRlB2IoihTM2fOlNwkXBLOpcKmBE5vKZFISHAoPRBatR0dHeLdfu1rXwMAvPbaa+IB\n0Rs2g1733XdfAI6XtHHjRrHY6UFRtSrUztg777yzeHPmnlNAuuebDVrbXV1drgD/YtPbddjeivm3\nnesnGAzmPfdXXzFVInp0e+21lyhTbM+c0nr//fdlye3EiRMBpNq3GcBrsn37dllyftNNNwEobrA9\nmTt3rks59VIazb/t9sxFF4sXLy6aMuWlirL/lZaWuvYYNKcqbdXXPBdVCvPecEzheGYuofeznP6+\n++4DkJrGYLZy5sfiuGUuimCfMafVOf7y1cwEboZN2EowwyDa2tpkTGbZw+GwKLI8BxWwzs5OPPnk\nkwCc/fpyZdasWWn/U8Uwc2nxd6uqqkRFsuuyr2p9PB6X54O52MTemWEgxlpTqbGfAb1du61+tre3\ni7pH9emvf/0rgNQzmZnvvbDH4P5mP8+0mMqGytk555wj6hmnH4k5Bps7YtC2oLLP0CATcyy1Z304\nPgG5zZjI9eR8pKIoiqIoiuKioO49Lb9bbrlFYkTseWqvYHBzTyHCOewJEybIDvA8ZvHixWnxUwDw\n3HPPAUgtQWZMFmOt4vG4zPub6g7gtobzgZdFbgaKm+UGMscb2RnQWYbOzk75DTOepdgxU5mWrJpe\nr5fX6JV8j/Vvpn4oJKZnw6DGDRs2iIdk7l0GpIJ+6W3xu5s2bZIUHIzXMfftoxfJHc7ff//9AStP\nrsycOVP6htdei16KIevP3k/xoIMOGvDr7Q+RSMSlSHkFxmYLSqdSEggERJli/U2bNs2lsPcHfnf9\n+vWu/eAY4zRx4kRpP2yL48ePT4uHMsuXTCYlFonqU0NDg6hq9mtHR4dLpQiHw65y8ZxtbW39Hofs\noGczfpa/R0U4EAjI8XbMVCAQcO3lZ44xtsIUj8elzfL4qqoqOa5Qi3z6ct/M2CRT3brmmmsAOPHF\n++23HwBIxvpM8BxU2vuaFsFczMB64H2jknTeeefJYg0yceJEnHDCCQCcxRUkmUxKvbN+dtllF5mh\nsveMLC8vFxvBbBNUbnld//jHP+Q7qkwpiqIoiqIUiIIqU2eeeSaAlJrEeUnGJvHVTHJIa3bYsGGy\n1JwWNSPvP/30U9x7770AnKRpjz/+uHhhPO+MGTMAAEcccYTLKykrKxM1iNASLy0tHZBVGjadnZ0u\nT8fc/sWes47H42mJygDvVA/01IpNaWmpp3fP/3PxukxlazBtLUN1ad26da54E/M6bY83mUyKN2R6\nVkBK2bLVrcGgTNXU1EhskdeKUTs+yoSfse+OHTtW7g9VhkLBGMzKykqX8lleXu7a7slUIr3SlNjl\n9trW5OOPPwaQ2oqF5fUTZ0N1qLKyUpR+u281Njbi+eefB+Aog6bC4xWfyePMtswxhp9xXB01apTE\n/XG87urqcq2Q4v3u6uqSla595W9/+1va/2bd2CvwEomE6x6b46W9Ss5Uzu1EreZ5Wa5QKCTj9EAq\n/qbqy7Gcq2HHjRsndWvjdU3XXnutXDPHLDPBKjHVZTtNT3/TmmRLpTB9+nQAqXLZsxGfffaZxPPN\nmzcPANJSFdnlvP/++/H0008DSI99AuCa3SK8n4zr628cZ0GNKS7x3rhxoytAnMZSNBqVBxE7aWNj\no3RAdmLemFgsJhX+yCOPAEgtheQDiMYZB8fm5ua0zLlAqjNyILDl/XA4LGkZBhKv4GKvQL1s0w3m\n8faSZPs8hSYUCrmC4nO9HltG7+rqGhSpEdjGmBsqEonI1Ii9H51ZD2a7s41CGsJjxoxBXV0dACc4\nuJhQCt9pp51kStLO1+Y1tWBOwbBf/+UvfwEAnHLKKeLkFCoQnddgDtr2VHFpaalr8Dc3ITcfwMQM\n7gbSg53tPESlpaVpzppf2tra5EFgU15eLr/B34xGo66M3iQYDLr2V+T7JjSONm/eLPeB5SwtLXU9\nhPl/e3u7OMR95atf/Wra/xzT4/G49BG2zXg87jKAzOklr7AJO12CGSphB5mbxtRA7ihhjpHcnNt0\nuGisZgsIZ7jAwQcfLH3WDub3+k0vB+ILX/hCn8sAOHkiv/CFL+BPf/oTAMeBNHPqMTURc751dHRI\n2+ZCHK+8j4899hiA1AIMiioBRjaLAAAKLklEQVS5QiPVy9jSaT5FURRFUZQCUVBlip52T0+PJP7j\ncnHKh83NzRKsyODvUCjk8qRoYQ8ZMkQ8CX5vzz33FGuWihenJsrKyuQ4U6Hi31QQuJv7tm3bJGHZ\nQOKltHgpN9mUKdOjotdEz6XYmNOotueTq8pkTqEMhnLRSzMzgbOcbJ925mjAUXkSiUTatAEAfPTR\nRwCAyZMni5fNYPuqqirx2AoN+4A5HWIrp+YUkZklnZ+zTTKQNBQKYc899wRQOGXKDhQPhUIyLpFg\nMOjpnQPei0HMaSZbde3u7hYV/t1335XftBXwgaKjo8PlcXMs3NE49thj0/7nmN3Z2Sn3ePHixQCA\nFStWSBukisZ7Ho/HPevLrnM+cyKRiPRBTjVOmDBBplltxowZI303F7KlCjA/628fufPOOwGkdi+w\n1T0vvJRXvsdFNH2FyT7vuOMOCTinik9lavv27VKnVN+qq6tddXXDDTcAAO6++25cf/31AFLhOwCw\nevVq2RElVzhF7rWYqS+zOapMKYqiKIqi+KCgytQbb7wBAHj44YdxzjnnAHACypnsMBaLSVwUVajy\n8nLX/jmMtTK3YeG88SeffOKK3TATrPH8ZhwVvQw7nmrixIl98jJyIZO1mykY1UyD4HWsfb58bVeR\nT8LhsEuhyNUrp3LFMnV1dclyb7apYsB7a25tRMWMbdfc5oLlZ/szg2QZ1/Daa68BSMUYMBaLbXfE\niBFFU6YY/FlfXy99xN4zKxqNSp2aCjI9Pn6Pqm8ikZAEuoXGVNNsZSoQCLhSi5h7R3qpVfZ4Y7Zt\nqhr//e9/5VyZFmMombGVJs5qmPXBuNlbb71Vkt5StTK3HbNjFc3+yT7L2ZLu7m5JPXHzzTcDAGbP\nnp1xz7jjjz8ed911V87lyqZ+eCWXXbVqFYDUmLF06VIAwAMPPOD67tVXXw3AUfRuvvlm2Tu0r5hj\nUH+45557AKTSH+y9995p52Kf2bJli9Qp45jq6+tdiW0vvfRSeeXsFdXXH/7wh3KcnRIjE/wtL6Wx\nL4mSi5JGeunSpfIQvOSSSwA4wbz19fVSKE7VBYPBtGy8fA9IH8g48JWWlsrxZn4Lwr9pJEWjUQlU\n583jgL9u3TqsWLECgJNx2C9eq9fi8XjGqSszK7FpiGTrhF7GVDED0M0gQ6+9BL2C0u3OYGah7usm\nlAMBB1u2ta1bt0oGajvfVDgclrrj4G5miubqGmaHbm5ulvPaGayLwaRJkwCkrp19g/VDA2/s2LFi\ndD3xxBMAUoOcvaKLVFZWysBaaExjiqvsSGdnpwzSvGYzGNs2mMwge76aU0R8QNBoM3PtFDuT/44E\n64z9J9M0GwBcfvnluPzyyz0/i0Qicg5zGs02pnrLYWcH3vOBPm/evD4ZU4cffrj8Ln+TU7Fm5niO\nFXydNGmSZDJnHkUu8jr66KOxZMkSAM7UZKb7kQmvsdjvxvK1tbWy3y1DcPiMHjNmjNxTlrusrMy1\nwIrjjbkCmM9y01jM9rxj/+zo6BBnxxZNIpFIn8qr03yKoiiKoig+KKhbZCoNTz31FADIKwPIli5d\nKvtK0WIMBAJpS1KB9OWotMZpidbV1YnVyiA3L4WG0w7t7e1ybatXrwYAvPXWWwAKFxgLuKezTM/X\n3KEeSM/+Srwyhg+Wab5YLCYeiJ0zyyvHCwBXpm1zOqm/uWryCZUp3u+GhgZps2ynnKoLh8Mub9Mr\n8J7ttampScrL48eNG4d33nlnQMrSG1Sa6EUDTn2YaR94/SSRSLiyJbOuY7GY7OheKGwFCXArEGVl\nZeK5sg1Sue7u7vacprYzifOclZWVosqa+9Wxfdj57ZTMnHvuuQCcvdaoeJphDbkQi8V8KywfffSR\npGOw91x88cUX+3QuzsrU1NTIOZkWiO2vsbFR+hsVnT/84Q9Yt24dgNSemQBkj8apU6fKdVC9isfj\n/c7rxhAapjXpL0uXLpXp1+rqagBO39m+fbtrD14zbZHXlDtDJk477TT5jVym98y+y3qjHWGfJ1dU\nmVIURVEURfFBQZWpbJbimjVrAEDmUwFnGeZOO+0k1j+tWSbA6+rqcmU6Hex4zeVu3rxZkoOaSR35\naicVNQMmvZbf2+pPpt8tFGvXrpXyeSVJM+OhAO9rNfdz5DLzYkKviF6bGZxJb4ceVigUEq+T8TiV\nlZXyHlUuxiYlk0mXh8U4j2LAGJA777xT6opxa147sJP6+npR6+hlsxxDhw6VgN5CYe4gAKTam+2B\nrly5UpQBeqt28knzPTNdgr3v2LZt22RRAUkkEvL5YEg+u6PAZwBnLqi8DBs2zDMA28ZU972y99tj\njjnW2ukLnnnmGVHK2J4Z78jl+rnC4GwvGDRfXV0t6qip6PBeUJHitaxatQr3338/AEfJAvq/0wCV\nvAsvvBCAs59eX1m/fr3cSwbG/+hHPwIAHHDAAdLvcuWFF14A4NgPuWKOU7x3djLZvj4vtScriqIo\niqL4YFAvJXn77bdd7/V3aedgZ/jw4bLqx94HyfSkvLafsOONNm7cKPEEVDp4HqBvyz3zRXt7O5Yv\nXw7AiY9j+SorKz13YLdjyJjQcs2aNVm3TygUkydPBuBcl7mEl9fOeojFYhJ/x5iBUCgkq3DsmLjh\nw4dLrJRZ7mKz7777uuKcTG939OjRaZ+NGTNGYqrYruk9H3PMMQWPfeO1mDFO9v6VXG4+UPT09KTV\ns9I3uPqS8T9DhgwRtYZUVla6ttjJlMogF+zx6Y033hCllQr1bbfd1ufz9gYTUPY1EWW+4UxQPsvI\nPfT4CkBmL7jN1NSpUyVtjJ2Woa6uDueff37ae+ZK2WyYYxaTgNrxqHasZ2+UFHLqp6SkpHjzTHmg\np6en16QwuZTRK63BsmXLZHCgnG0aThx8GeBr5p6ypwXj8bg0vLVr1wJwAoh7o7cy9rcOs6VyqKqq\nkuX2psy7ZcuWtFczaDRb1uBs5KsOAffUTyAQkDqgEUtjobq6WgakgSafZczGoYceCsDZM2zOnDky\nDcDA+2XLlomB9eCDDwJwFp34wW8Zf/GLXwBIGbucnmEf8dpdIJ9cd911khGaDobXPRmovjhY6G8d\nsn7OPPNMAKngbLY3Tqmae+flA3tj5Pnz5+Puu+8G4Dx0zzrrLADpQdqF6ovFRMuYQqf5FEVRFEVR\nfFBQZUpRFEVRFOX/N1SZUhRFURRF8YEaU4qiKIqiKD5QY0pRFEVRFMUHakwpiqIoiqL4QI0pRVEU\nRVEUH6gxpSiKoiiK4gM1phRFURRFUXygxpSiKIqiKIoP1JhSFEVRFEXxgRpTiqIoiqIoPlBjSlEU\nRVEUxQdqTCmKoiiKovhAjSlFURRFURQfqDGlKIqiKIriAzWmFEVRFEVRfKDGlKIoiqIoig/UmFIU\nRVEURfGBGlOKoiiKoig+UGNKURRFURTFB2pMKYqiKIqi+ECNKUVRFEVRFB+oMaUoiqIoiuIDNaYU\nRVEURVF88P8A0wyYl+ZpGWEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f60784a5950>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:\n",
      "9 0 0 3 0 2 7 2 5 5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4"
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [],
   "source": [
    "# Initializing Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "# Adding Dense Layer of 10 Outputs after applying softmax\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mH_asvYwi-t"
   },
   "outputs": [],
   "source": [
    "# Comile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_"
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "O59C_-IgOIVB",
    "outputId": "f9c18e35-0c65-4631-c552-b06189f15367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 8s 138us/sample - loss: 2012.9905 - accuracy: 0.7396 - val_loss: 1256.2563 - val_accuracy: 0.8003\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 1606.1333 - accuracy: 0.7798 - val_loss: 4129.9237 - val_accuracy: 0.5651\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 1547.5390 - accuracy: 0.7854 - val_loss: 3062.4778 - val_accuracy: 0.7795\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 1496.1868 - accuracy: 0.7891 - val_loss: 1213.6725 - val_accuracy: 0.8029\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1480.6683 - accuracy: 0.7944 - val_loss: 1731.3134 - val_accuracy: 0.7783\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1483.9951 - accuracy: 0.7943 - val_loss: 1095.9119 - val_accuracy: 0.7988\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 1466.7521 - accuracy: 0.7974 - val_loss: 2679.3484 - val_accuracy: 0.7401\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1451.7731 - accuracy: 0.7972 - val_loss: 1733.6259 - val_accuracy: 0.7875\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1405.3483 - accuracy: 0.7991 - val_loss: 1998.7142 - val_accuracy: 0.7400\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 1411.2264 - accuracy: 0.8010 - val_loss: 3280.8446 - val_accuracy: 0.6763\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 1411.9125 - accuracy: 0.8004 - val_loss: 2257.1860 - val_accuracy: 0.7702\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 1416.7052 - accuracy: 0.8007 - val_loss: 1765.6934 - val_accuracy: 0.7490\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 1414.1128 - accuracy: 0.8035 - val_loss: 2953.4120 - val_accuracy: 0.7444\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 1389.5609 - accuracy: 0.8038 - val_loss: 1193.9076 - val_accuracy: 0.7989\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 1403.4600 - accuracy: 0.8027 - val_loss: 978.3405 - val_accuracy: 0.8124\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1428.5047 - accuracy: 0.8025 - val_loss: 3347.5836 - val_accuracy: 0.6819\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 1441.0802 - accuracy: 0.8025 - val_loss: 1106.5407 - val_accuracy: 0.8166\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1438.4252 - accuracy: 0.8029 - val_loss: 1404.2240 - val_accuracy: 0.7973\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 1399.4244 - accuracy: 0.8043 - val_loss: 1259.2576 - val_accuracy: 0.8174\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 1399.1267 - accuracy: 0.8045 - val_loss: 2244.3025 - val_accuracy: 0.7585\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1362.7611 - accuracy: 0.8075 - val_loss: 1556.5669 - val_accuracy: 0.7973\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 1374.5850 - accuracy: 0.8075 - val_loss: 999.1779 - val_accuracy: 0.8255\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 1412.9607 - accuracy: 0.8042 - val_loss: 1525.1085 - val_accuracy: 0.7853\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 1429.7353 - accuracy: 0.8062 - val_loss: 2799.3753 - val_accuracy: 0.7516\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 1349.7632 - accuracy: 0.8079 - val_loss: 1155.2252 - val_accuracy: 0.7953\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 1361.0676 - accuracy: 0.8079 - val_loss: 1991.2958 - val_accuracy: 0.7724\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 1342.3221 - accuracy: 0.8080 - val_loss: 1365.1014 - val_accuracy: 0.7983\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1387.4834 - accuracy: 0.8054 - val_loss: 1309.9190 - val_accuracy: 0.8106\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 1388.0371 - accuracy: 0.8077 - val_loss: 1255.3550 - val_accuracy: 0.8041\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1384.1997 - accuracy: 0.8074 - val_loss: 1474.6321 - val_accuracy: 0.7537\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 1387.9072 - accuracy: 0.8070 - val_loss: 3154.5298 - val_accuracy: 0.7929\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 1363.6240 - accuracy: 0.8101 - val_loss: 1711.8072 - val_accuracy: 0.7915\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1365.7671 - accuracy: 0.8070 - val_loss: 1609.6491 - val_accuracy: 0.7868\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 1343.3169 - accuracy: 0.8100 - val_loss: 1103.6730 - val_accuracy: 0.8104\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1383.5160 - accuracy: 0.8069 - val_loss: 1551.1252 - val_accuracy: 0.7825\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 1360.0005 - accuracy: 0.8099 - val_loss: 1557.9254 - val_accuracy: 0.7912\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1366.8214 - accuracy: 0.8077 - val_loss: 1129.3734 - val_accuracy: 0.8178\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 1369.3478 - accuracy: 0.8097 - val_loss: 1749.1079 - val_accuracy: 0.7883\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 1385.9025 - accuracy: 0.8091 - val_loss: 1219.5834 - val_accuracy: 0.8047\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 1375.9332 - accuracy: 0.8081 - val_loss: 1266.4096 - val_accuracy: 0.7991\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 1336.9808 - accuracy: 0.8098 - val_loss: 2028.1132 - val_accuracy: 0.7650\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 1367.5107 - accuracy: 0.8095 - val_loss: 1488.3857 - val_accuracy: 0.8054\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 7s 108us/sample - loss: 1354.9280 - accuracy: 0.8108 - val_loss: 1271.1021 - val_accuracy: 0.8069\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 1361.3599 - accuracy: 0.8083 - val_loss: 1613.1258 - val_accuracy: 0.7745\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 1352.2607 - accuracy: 0.8098 - val_loss: 1740.3320 - val_accuracy: 0.7689\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 1351.6171 - accuracy: 0.8120 - val_loss: 1124.6653 - val_accuracy: 0.7955\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 1343.9550 - accuracy: 0.8113 - val_loss: 1527.8700 - val_accuracy: 0.7874\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 1390.9920 - accuracy: 0.8089 - val_loss: 2942.3999 - val_accuracy: 0.7523\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 1333.0142 - accuracy: 0.8121 - val_loss: 1397.1869 - val_accuracy: 0.8041\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 1343.4251 - accuracy: 0.8104 - val_loss: 2872.6095 - val_accuracy: 0.7373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdbd0338860>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
    "          batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF"
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "outputs": [],
   "source": [
    "# Initialize Sequential model\n",
    "model1 = tf.keras.models.Sequential()\n",
    "\n",
    "# Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model1.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "# Normalize the data\n",
    "model1.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "model1.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOcWXFQV1bW4"
   },
   "outputs": [],
   "source": [
    "# Comile the model\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN"
   },
   "source": [
    "]\\\n",
    "\\]### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JNLR8tcBOIVP",
    "outputId": "53193f3f-d6dc-44dd-9bf7-94049e147f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 8s 136us/sample - loss: 0.5993 - accuracy: 0.7939 - val_loss: 0.5249 - val_accuracy: 0.8204\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.4921 - accuracy: 0.8298 - val_loss: 0.5007 - val_accuracy: 0.8298\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.4687 - accuracy: 0.8377 - val_loss: 0.5031 - val_accuracy: 0.8337\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4569 - accuracy: 0.8420 - val_loss: 0.4878 - val_accuracy: 0.8338\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4510 - accuracy: 0.8442 - val_loss: 0.4816 - val_accuracy: 0.8382\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4450 - accuracy: 0.8446 - val_loss: 0.4647 - val_accuracy: 0.8393\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4407 - accuracy: 0.8465 - val_loss: 0.4833 - val_accuracy: 0.8381\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4373 - accuracy: 0.8475 - val_loss: 0.4725 - val_accuracy: 0.8379\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4336 - accuracy: 0.8504 - val_loss: 0.4781 - val_accuracy: 0.8397\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4315 - accuracy: 0.8506 - val_loss: 0.4799 - val_accuracy: 0.8400\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4287 - accuracy: 0.8517 - val_loss: 0.4728 - val_accuracy: 0.8399\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.4280 - accuracy: 0.8511 - val_loss: 0.4664 - val_accuracy: 0.8406\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.4234 - accuracy: 0.8522 - val_loss: 0.4890 - val_accuracy: 0.8390\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4227 - accuracy: 0.8534 - val_loss: 0.4854 - val_accuracy: 0.8430\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4208 - accuracy: 0.8525 - val_loss: 0.4702 - val_accuracy: 0.8401\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4218 - accuracy: 0.8528 - val_loss: 0.4770 - val_accuracy: 0.8392\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4187 - accuracy: 0.8525 - val_loss: 0.4997 - val_accuracy: 0.8417\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4186 - accuracy: 0.8543 - val_loss: 0.4936 - val_accuracy: 0.8395\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4172 - accuracy: 0.8538 - val_loss: 0.4738 - val_accuracy: 0.8404\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.4148 - accuracy: 0.8555 - val_loss: 0.4780 - val_accuracy: 0.8356\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.4165 - accuracy: 0.8543 - val_loss: 0.4682 - val_accuracy: 0.8386\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.4176 - accuracy: 0.8547 - val_loss: 0.4628 - val_accuracy: 0.8417\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.4135 - accuracy: 0.8557 - val_loss: 0.4645 - val_accuracy: 0.8396\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4133 - accuracy: 0.8551 - val_loss: 0.4764 - val_accuracy: 0.8399\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4150 - accuracy: 0.8551 - val_loss: 0.4713 - val_accuracy: 0.8426\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4146 - accuracy: 0.8549 - val_loss: 0.4872 - val_accuracy: 0.8376\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.4109 - accuracy: 0.8564 - val_loss: 0.4669 - val_accuracy: 0.8437\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4128 - accuracy: 0.8557 - val_loss: 0.4657 - val_accuracy: 0.8429\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4084 - accuracy: 0.8558 - val_loss: 0.4883 - val_accuracy: 0.8378\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4107 - accuracy: 0.8556 - val_loss: 0.4824 - val_accuracy: 0.8415\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.4110 - accuracy: 0.8545 - val_loss: 0.4811 - val_accuracy: 0.8431\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.4092 - accuracy: 0.8579 - val_loss: 0.4660 - val_accuracy: 0.8423\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4081 - accuracy: 0.8566 - val_loss: 0.4692 - val_accuracy: 0.8425\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.4101 - accuracy: 0.8571 - val_loss: 0.4871 - val_accuracy: 0.8408\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.4075 - accuracy: 0.8567 - val_loss: 0.4869 - val_accuracy: 0.8405\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4076 - accuracy: 0.8567 - val_loss: 0.4903 - val_accuracy: 0.8403\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.4080 - accuracy: 0.8558 - val_loss: 0.4781 - val_accuracy: 0.8417\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4074 - accuracy: 0.8572 - val_loss: 0.4785 - val_accuracy: 0.8400\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4075 - accuracy: 0.8554 - val_loss: 0.4811 - val_accuracy: 0.8412\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4092 - accuracy: 0.8561 - val_loss: 0.4722 - val_accuracy: 0.8380\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.4075 - accuracy: 0.8559 - val_loss: 0.4807 - val_accuracy: 0.8419\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.4084 - accuracy: 0.8566 - val_loss: 0.4809 - val_accuracy: 0.8401\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4077 - accuracy: 0.8567 - val_loss: 0.4748 - val_accuracy: 0.8407\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4061 - accuracy: 0.8576 - val_loss: 0.4823 - val_accuracy: 0.8401\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4062 - accuracy: 0.8570 - val_loss: 0.4813 - val_accuracy: 0.8387\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.4049 - accuracy: 0.8569 - val_loss: 0.4764 - val_accuracy: 0.8417\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4053 - accuracy: 0.8591 - val_loss: 0.4807 - val_accuracy: 0.8376\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4064 - accuracy: 0.8571 - val_loss: 0.4851 - val_accuracy: 0.8372\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4048 - accuracy: 0.8582 - val_loss: 0.4743 - val_accuracy: 0.8418\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4040 - accuracy: 0.8577 - val_loss: 0.4762 - val_accuracy: 0.8407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdb7cfb3c88>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
    "          batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [],
   "source": [
    "# Create optimizer with non-default learning rate\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJUqA5T4OIVc"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model1.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8uQeYs903gzy",
    "outputId": "a566c311-6836-4f08-db9c-2d829fa6b19d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 0.3942 - accuracy: 0.8614 - val_loss: 0.4741 - val_accuracy: 0.8420\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3929 - accuracy: 0.8615 - val_loss: 0.4728 - val_accuracy: 0.8438\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.3927 - accuracy: 0.8612 - val_loss: 0.4760 - val_accuracy: 0.8429\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3916 - accuracy: 0.8628 - val_loss: 0.4739 - val_accuracy: 0.8437\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3935 - accuracy: 0.8616 - val_loss: 0.4790 - val_accuracy: 0.8425\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 8s 134us/sample - loss: 0.3927 - accuracy: 0.8610 - val_loss: 0.4579 - val_accuracy: 0.8434\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.3930 - accuracy: 0.8614 - val_loss: 0.4855 - val_accuracy: 0.8431\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.3937 - accuracy: 0.8607 - val_loss: 0.4706 - val_accuracy: 0.8432\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.3923 - accuracy: 0.8627 - val_loss: 0.4731 - val_accuracy: 0.8426\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3932 - accuracy: 0.8622 - val_loss: 0.4810 - val_accuracy: 0.8435\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3923 - accuracy: 0.8622 - val_loss: 0.4666 - val_accuracy: 0.8437\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3934 - accuracy: 0.8614 - val_loss: 0.4665 - val_accuracy: 0.8413\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.3904 - accuracy: 0.8625 - val_loss: 0.4943 - val_accuracy: 0.8446\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.3917 - accuracy: 0.8617 - val_loss: 0.4925 - val_accuracy: 0.8432\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.3903 - accuracy: 0.8620 - val_loss: 0.4654 - val_accuracy: 0.8419\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3927 - accuracy: 0.8611 - val_loss: 0.4744 - val_accuracy: 0.8429\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.3903 - accuracy: 0.8620 - val_loss: 0.5036 - val_accuracy: 0.8419\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3915 - accuracy: 0.8629 - val_loss: 0.4885 - val_accuracy: 0.8431\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.3913 - accuracy: 0.8618 - val_loss: 0.4707 - val_accuracy: 0.8428\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3900 - accuracy: 0.8636 - val_loss: 0.4651 - val_accuracy: 0.8427\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3921 - accuracy: 0.8622 - val_loss: 0.4619 - val_accuracy: 0.8428\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.3935 - accuracy: 0.8624 - val_loss: 0.4627 - val_accuracy: 0.8425\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.3903 - accuracy: 0.8624 - val_loss: 0.4611 - val_accuracy: 0.8427\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.3905 - accuracy: 0.8624 - val_loss: 0.4727 - val_accuracy: 0.8416\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3931 - accuracy: 0.8621 - val_loss: 0.4685 - val_accuracy: 0.8431\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3934 - accuracy: 0.8612 - val_loss: 0.4805 - val_accuracy: 0.8419\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3901 - accuracy: 0.8621 - val_loss: 0.4614 - val_accuracy: 0.8425\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.3923 - accuracy: 0.8614 - val_loss: 0.4593 - val_accuracy: 0.8427\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3889 - accuracy: 0.8622 - val_loss: 0.4843 - val_accuracy: 0.8416\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3912 - accuracy: 0.8620 - val_loss: 0.4773 - val_accuracy: 0.8428\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.3916 - accuracy: 0.8614 - val_loss: 0.4823 - val_accuracy: 0.8423\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3907 - accuracy: 0.8640 - val_loss: 0.4631 - val_accuracy: 0.8440\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3896 - accuracy: 0.8637 - val_loss: 0.4627 - val_accuracy: 0.8432\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.3919 - accuracy: 0.8622 - val_loss: 0.4867 - val_accuracy: 0.8434\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3896 - accuracy: 0.8625 - val_loss: 0.4898 - val_accuracy: 0.8428\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3903 - accuracy: 0.8640 - val_loss: 0.4853 - val_accuracy: 0.8426\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3912 - accuracy: 0.8617 - val_loss: 0.4716 - val_accuracy: 0.8430\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3901 - accuracy: 0.8633 - val_loss: 0.4731 - val_accuracy: 0.8426\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3908 - accuracy: 0.8608 - val_loss: 0.4777 - val_accuracy: 0.8431\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.3923 - accuracy: 0.8613 - val_loss: 0.4653 - val_accuracy: 0.8411\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.3917 - accuracy: 0.8614 - val_loss: 0.4778 - val_accuracy: 0.8419\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.3923 - accuracy: 0.8616 - val_loss: 0.4696 - val_accuracy: 0.8425\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.3918 - accuracy: 0.8618 - val_loss: 0.4687 - val_accuracy: 0.8422\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3906 - accuracy: 0.8632 - val_loss: 0.4760 - val_accuracy: 0.8402\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3906 - accuracy: 0.8629 - val_loss: 0.4711 - val_accuracy: 0.8435\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3896 - accuracy: 0.8627 - val_loss: 0.4706 - val_accuracy: 0.8423\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.3903 - accuracy: 0.8641 - val_loss: 0.4738 - val_accuracy: 0.8412\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3911 - accuracy: 0.8627 - val_loss: 0.4810 - val_accuracy: 0.8420\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3899 - accuracy: 0.8636 - val_loss: 0.4684 - val_accuracy: 0.8420\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.3895 - accuracy: 0.8631 - val_loss: 0.4646 - val_accuracy: 0.8437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdbd0176588>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
    "          batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk"
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDg3_ubh4HD6"
   },
   "outputs": [],
   "source": [
    "# Initialize Sequential model\n",
    "model2 = tf.keras.models.Sequential()\n",
    "\n",
    "# Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model2.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "# Normalize the data\n",
    "model2.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "#Add 1st hidden layer\n",
    "model2.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "#Add 2nd hidden layer\n",
    "model2.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "#Add 3rd hidden layer\n",
    "model2.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "#Add OUTPUT layer\n",
    "model2.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7oIymROIVp"
   },
   "outputs": [],
   "source": [
    "# Create optimizer with non-default learning rate\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-O-fFxnOIVt"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model2.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0"
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "h4ojW6-oOIV2",
    "outputId": "82e1df76-104b-4d0f-b16c-d74fa509f977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_7 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 92,856\n",
      "Trainable params: 91,288\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5"
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bIkbMEN5OIV7",
    "outputId": "5d3727bd-351c-4195-c230-ef6aaf170544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 0.2634 - accuracy: 0.9070 - val_loss: 0.3430 - val_accuracy: 0.8820\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 0.2629 - accuracy: 0.9085 - val_loss: 0.3593 - val_accuracy: 0.8746\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.2592 - accuracy: 0.9101 - val_loss: 0.3485 - val_accuracy: 0.8800\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.2542 - accuracy: 0.9107 - val_loss: 0.3427 - val_accuracy: 0.8786\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.2522 - accuracy: 0.9117 - val_loss: 0.3467 - val_accuracy: 0.8800\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.2473 - accuracy: 0.9129 - val_loss: 0.3438 - val_accuracy: 0.8803\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.2425 - accuracy: 0.9147 - val_loss: 0.3637 - val_accuracy: 0.8760\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.2403 - accuracy: 0.9151 - val_loss: 0.3429 - val_accuracy: 0.8819\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 9s 147us/sample - loss: 0.2355 - accuracy: 0.9170 - val_loss: 0.3508 - val_accuracy: 0.8725\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 9s 146us/sample - loss: 0.2316 - accuracy: 0.9187 - val_loss: 0.3462 - val_accuracy: 0.8798\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.2332 - accuracy: 0.9180 - val_loss: 0.3438 - val_accuracy: 0.8807\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 8s 139us/sample - loss: 0.2260 - accuracy: 0.9206 - val_loss: 0.3443 - val_accuracy: 0.8817\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 0.2225 - accuracy: 0.9219 - val_loss: 0.3524 - val_accuracy: 0.8806\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.2179 - accuracy: 0.9246 - val_loss: 0.3503 - val_accuracy: 0.8829\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.2177 - accuracy: 0.9235 - val_loss: 0.3481 - val_accuracy: 0.8808\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.2159 - accuracy: 0.9240 - val_loss: 0.3674 - val_accuracy: 0.8740\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 9s 144us/sample - loss: 0.2127 - accuracy: 0.9251 - val_loss: 0.3744 - val_accuracy: 0.8749\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 0.2106 - accuracy: 0.9264 - val_loss: 0.3634 - val_accuracy: 0.8772\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.2055 - accuracy: 0.9286 - val_loss: 0.3531 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.2029 - accuracy: 0.9284 - val_loss: 0.3697 - val_accuracy: 0.8728\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.2013 - accuracy: 0.9288 - val_loss: 0.3620 - val_accuracy: 0.8768\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.2018 - accuracy: 0.9292 - val_loss: 0.3589 - val_accuracy: 0.8760\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1948 - accuracy: 0.9316 - val_loss: 0.3506 - val_accuracy: 0.8845\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1926 - accuracy: 0.9319 - val_loss: 0.3656 - val_accuracy: 0.8806\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1944 - accuracy: 0.9319 - val_loss: 0.3595 - val_accuracy: 0.8803\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 0.1899 - accuracy: 0.9332 - val_loss: 0.3611 - val_accuracy: 0.8824\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 9s 150us/sample - loss: 0.1884 - accuracy: 0.9345 - val_loss: 0.3539 - val_accuracy: 0.8806\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 0.1856 - accuracy: 0.9361 - val_loss: 0.3546 - val_accuracy: 0.8832\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1838 - accuracy: 0.9347 - val_loss: 0.3731 - val_accuracy: 0.8748\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1818 - accuracy: 0.9357 - val_loss: 0.3645 - val_accuracy: 0.8824\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1836 - accuracy: 0.9351 - val_loss: 0.3771 - val_accuracy: 0.8770\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.1783 - accuracy: 0.9362 - val_loss: 0.3702 - val_accuracy: 0.8786\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1775 - accuracy: 0.9379 - val_loss: 0.3631 - val_accuracy: 0.8779\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1775 - accuracy: 0.9377 - val_loss: 0.3702 - val_accuracy: 0.8790\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1738 - accuracy: 0.9382 - val_loss: 0.3676 - val_accuracy: 0.8805\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 0.1743 - accuracy: 0.9386 - val_loss: 0.3725 - val_accuracy: 0.8804\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1728 - accuracy: 0.9395 - val_loss: 0.3713 - val_accuracy: 0.8787\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.1688 - accuracy: 0.9399 - val_loss: 0.3751 - val_accuracy: 0.8783\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 8s 139us/sample - loss: 0.1665 - accuracy: 0.9412 - val_loss: 0.3841 - val_accuracy: 0.8767\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1674 - accuracy: 0.9400 - val_loss: 0.3757 - val_accuracy: 0.8779\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1672 - accuracy: 0.9410 - val_loss: 0.3717 - val_accuracy: 0.8795\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1647 - accuracy: 0.9420 - val_loss: 0.3773 - val_accuracy: 0.8813\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.1640 - accuracy: 0.9421 - val_loss: 0.3909 - val_accuracy: 0.8789\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.1612 - accuracy: 0.9430 - val_loss: 0.3846 - val_accuracy: 0.8783\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 9s 149us/sample - loss: 0.1615 - accuracy: 0.9429 - val_loss: 0.3839 - val_accuracy: 0.8780\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.1567 - accuracy: 0.9448 - val_loss: 0.3804 - val_accuracy: 0.8803\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1557 - accuracy: 0.9446 - val_loss: 0.3732 - val_accuracy: 0.8851\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.1551 - accuracy: 0.9456 - val_loss: 0.3920 - val_accuracy: 0.8776\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1554 - accuracy: 0.9448 - val_loss: 0.3942 - val_accuracy: 0.8770\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 0.1506 - accuracy: 0.9467 - val_loss: 0.3716 - val_accuracy: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdb7a6b4a90>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
    "          batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbWNfEmE6cvY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R6_ExternalLab_AIML (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
